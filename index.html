<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title></title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title">
<meta property="og:url" content="https://sillycross.github.io/index.html">
<meta property="og:site_name">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Haoran Xu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="" type="application/atom+xml">
  
  
  
    <!--<link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">-->
    <!--
<link rel="stylesheet" href="css/source_code_pro.css">
-->
    <link rel="stylesheet" href="/css/source_code_pro.css?ver=20230504">
  

  <!--<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">-->
<!--  
<link rel="stylesheet" href="css/bootstrap/bootstrap.min.css">
 -->

<link rel="stylesheet" href="/css/bootstrap/bootstrap.min.css?ver=20230504">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

<link rel="stylesheet" href="/css/styles.css?ver=20230504">

<!--  
<link rel="stylesheet" href="css/styles.css">
 -->

  

  
  <!--<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>-->
  
<script src="js/jquery.min.js"></script>


<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class="active"
                 href="">Home</a></li>
        
          <li><a class=""
                 href="archives/">Archives</a></li>
        
          <li><a class=""
                 href="about/">About</a></li>
        
          <li><a class=""
                 href="cnblog/">Chinese Blog</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title"></h1>
  
    <p class="blog-description">「こんなきれいな星も、やっぱりここまで来てから、見れたのだと思うから。だから・・もっと遠くへ・・」</p>
  
</div>

    <div class="row">
        <div class="col-sm-8 blog-main">
          
  
    <article id="post-2023-05-12" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2023/05/12/2023-05-12/">Building a baseline JIT for Lua automatically</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2023/05/12/2023-05-12/" class="article-date"><time datetime="2023-05-12T00:00:00.000Z" itemprop="datePublished">2023-05-12</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p><text style="font-size:15px;">This is the Part 2 of a series. Feel free to read the prequel for more context: <a href="/2022/11/22/2022-11-22/">Building the fastest Lua interpreter automatically</a></text></p>
</blockquote>
<p>Building a good VM for a dynamic language takes a ton of engineering. The best-performing VMs (e.g., <a href="https://github.com/WebKit/WebKit/tree/main/Source/JavaScriptCore" target="_blank" rel="noopener">JavaScriptCore</a>, <a href="https://v8.dev/" target="_blank" rel="noopener">V8</a>, <a href="https://firefox-source-docs.mozilla.org/js/index.html" target="_blank" rel="noopener">SpiderMonkey</a>) employ at least 3 VM tiers (interpreter, baseline JIT<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> and optimizing JIT), and pervasively use hand-coded assembly in every VM tier<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>. Optimizations such as inline caching and type speculation are required to get high performance, but they require high expertise and introduce additional engineering complexity.</p>
<!--The best interpreters are hand-coded in assembly. The baseline JIT compiler[^1] is more assembly, plus an assembler to assemble them to machine code at runtime. The optimizing JIT compiler is even more assembly among other things[^2]. -->
<!--### Deegen: High Performance VMs at Low Engineering Cost-->
<p><em>Deegen</em> is my research meta-compiler to make high-performance VMs easier to write. Deegen takes in a semantic description of the VM bytecodes in C++, and use it as the single source of truth to <em>automatically generate</em> a high-performance VM at build time, as illustrated below.</p>
<p><img src="/images/2023-05-12/deegen-arch.png" alt="Deegen: automatically generating a high-performance VM!"></p>
<p>In <a href="https://sillycross.github.io/2022/11/22/2022-11-22/">a prior post</a>, Deegen automatically generated the fastest Lua 5.1 interpreter to date, outperforming LuaJIT’s interpreter by an average of 34% across a variety of Lua benchmarks. The VM was named <a href="https://github.com/luajit-remake/luajit-remake" target="_blank" rel="noopener"><em>LuaJIT Remake</em></a>, even though it had no JIT tiers at that time.</p>
<p>Today, after months of additional work, <a href="https://github.com/luajit-remake/luajit-remake" target="_blank" rel="noopener"><em>LuaJIT Remake</em></a> is finally a JIT-capable VM. It is now equipped with a state-of-the-art baseline JIT compiler, also automatically generated by Deegen. The baseline JIT features:</p>
<ul>
<li>Extremely fast compilation speed.</li>
<li>High-quality machine code (under the design constraints of a baseline JIT).</li>
<li>Automatic call inline caching (IC) with two modes (direct/closure call).</li>
<li>Automatic generic inline caching (IC) <a href="/2022/11/22/2022-11-22/#deegen_generic_inline_caching_api">driven by Deegen API</a>.</li>
<li>Self-modifying-code-based IC implementation for best performance.</li>
<li>Hot-cold-splitted JIT code for less branches and better code locality.</li>
</ul>
<p>It is important to note that the baseline JIT is generated from the <em>same</em> bytecode semantic description that Deegen uses to generate the interpreter. Therefore, for a language implementer, the baseline JIT comes <em>for free</em>:</p>
<ul>
<li>No need to have any assembly knowledge.</li>
<li>No need to manually engineer the JIT.</li>
<li>No need to manually keep the JIT updated with new language features.</li>
</ul>
<p>Because Deegen does all the work automatically!</p>
<p>Of course, this is no easy feat. In order to generate the baseline JIT automatically, a sophiscated build-time pipeline is employed, as illustrated below.</p>
<p><img src="/images/2023-05-12/deegen-jit-pipeline.png" alt="The pipeline that automatically generates the baseline JIT from bytecode semantics"></p>
<p>As a side note, LLVM is only used at build time to generate the JIT. The generated baseline JIT is self-contained, and does not use LLVM at runtime.</p>
<p>At runtime, the generated baseline JIT generates machine code using <em>Copy-and-Patch</em> (we’ll cover it in a minute). Except that, it heavily follows the design of the <a href="https://webkit.org/blog/10308/speculation-in-javascriptcore/" target="_blank" rel="noopener">baseline JIT in JavaScriptCore</a>, and has employed most of their optimizations. As such, we claim that our baseline JIT qualifies as a state-of-the-art.</p>
<p>In the rest of the post, we will explore the internals of how Deegen generates the baseline JIT in more detail. It is organized as follows:</p>
<ul>
<li>A gentle introduction of the relavent backgrounds (VM, JIT, IC, etc.).</li>
<li>An overview of the Copy-and-Patch technique, the core tool employed by the generated JIT to generate machine code at runtime.</li>
<li>How Deegen further extends Copy-and-Patch to fully automate the process and fit it for the domain-specific use cases of dynamic languages.</li>
<li>An end-to-end example of the machine code generated by the baseline JIT.</li>
<li>Performance evaluation and conclusion thoughts.</li>
</ul>
<h3 id="Background-a-name-deegen-baseline-jit-background-section-a">Background<a name="deegen_baseline_jit_background_section"></a></h3>
<div id="folded_modern_dynamic_language_vm_background_section">
<p>Not everyone is familiar with topics like modern dynamic language VM, multi-tier JIT compilers, baseline JIT, speculative compilation, inline caching, OSR exit…  Therefore, I prepared a background section to gently introduce the background contexts for this post.</p>
<p>Due to its length, I folded this section by default. <a style="cursor:pointer" onclick="document.getElementById('modern_dynamic_language_vm_background_section').style.display='inline'; document.getElementById('folded_modern_dynamic_language_vm_background_section').style.display = 'none';">To unfold, click here</a>.</p>
</div><div id="modern_dynamic_language_vm_background_section" style="display:none">
<p>Before we start, let’s cover some backgrounds about dynamic languages, VM and JIT compilation. It might be a bit lengthy, but IMO this topic is really a piece of little known gemstone and worth elaboration. If you are already familiar, feel free to <a href="#after_background_section">skip to the next section</a>.</p>
<h4 id="AOT-Compiler-JIT-Compiler-and-Multi-tier-JIT-Compiler">AOT Compiler, JIT Compiler and Multi-tier JIT Compiler</h4>
<p>Unlike static languages such as C/C++, which are ahead-of-time (AOT) compiled to a native executable, programs written in a dynamic language have to execute in a virtual machine (VM). You might ask: why can’t we AOT compile them to native code like C/C++? The main reason<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> is that it is impossible to statically generate efficient native code from a dynamic language program. As shown by <a href="https://en.wikipedia.org/wiki/HipHop_for_PHP" target="_blank" rel="noopener">HPHPc</a> and the early days of <a href="https://github.com/facebook/hhvm" target="_blank" rel="noopener">HHVM</a>, forcefully doing so is simply not worthy: one could get a small performance gain, but it comes at a huge memory overhead<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>.</p>
<p>Nevertheless, interpreters are intrinsically (much) slower than native code. That’s where Just-in-Time (JIT) compilers come in, which identifies the hot part of the dynamic lanugage program, and dynamically compile it to native code at runtime. By doing compilation at runtime and for hot code only, performance is improved without sacrificing the advantages of dynamic languages.</p>
<p>However, since JIT compilation happens at runtime, the time spent by the JIT compiler to generate the code (startup delay) is directly reflected in the total execution time. And there is no free lunch: in order to generate even slightly better code, one must spend a lot more time in compilation.</p>
<p>The result of this game is the multi-tier JIT strategy. A <em>baseline JIT compiler</em>, which excels at fast compilation but only generates mediocre code, is used to compile functions as soon as they reach a low hotness threshold. Then, for functions that eventually gets really hot, the <em>optimizing JIT compiler</em> kicks in to generate better code for these function at a much higher compilation cost.</p>
<p>Orthogonal to the multi-tier JIT strategy, another equally important concept in modern dynamic language VM is <em>speculative compilation</em>. Recall that dynamic language programs cannot be AOT-compiled to efficient native code. Speculative compilation is exactly how JIT compilers made it possible.</p>
<p>There are two forms of speculations: <em>inline caching</em> and <em>type speculation</em>.</p>
<h4 id="Inline-Caching">Inline Caching</h4>
<p>Inline caching (IC) works by predicting the <em>value</em> of certain operands. For example, for the code <code>f()</code> which calls <code>f</code>, it’s likely that every time this line of code is run, the function object <code>f</code> always holds the same function<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>. So the JIT, after having seen the value of <code>f</code> once, may predict that future executions will see that value again, and speculatively devirtualize the call to a direct call.</p>
<p>Every VM tier can benefit from IC, including the interpreter. However, IC is most powerful at the JIT tiers, as the ability to JIT code allows one to produce the most specialized code without any unnecessary overhead.</p>
<p>At machine code level, the most efficient implementation of IC requires the use of self-modifying code. The idea is like below:</p>
<p><img src="/images/2023-05-12/ic-idea.png" alt="How inline caching (IC) works at machine code level"></p>
<p>The blue region indicates the self-modifying code, where in this example it is simply a patchable <code>jmp</code> instruction. Initially, there are not any IC cases, and the patchable jump simply jumps to the IC-miss slow path.</p>
<p>When the code is executed for the first time, the patchable jump will bring control to the IC-miss slow path. The IC-miss slow path will JIT compile a piece of code stub containing the specialized logic based on the IC key it sees (the “IC case #1” in figure), and repatch the <code>jmp</code> instruction to jump to the code stub instead. So next time, if the code is executed with the same IC key, control will reach the JIT’ed code stub and the specialized fast path will be executed.</p>
<p>This process can be repeated. All the JIT’ed IC code stubs are chained together, so that if the first code stub misses, control will be transferred to the next one<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>, and the last one transfers control to the IC miss slow path, which will JIT-compile a new code stub and chain it into the stub chain.</p>
<p>Inline caching allows one to speculatively generate optimized code based on the prior executions, largely alleviating the overhead from the dynamic nature of dynamic languages.</p>
<p>Inline caching is especially powerful when combined with <a href="https://dl.acm.org/doi/10.1145/74878.74884" target="_blank" rel="noopener"><em>hidden class</em></a>, which uses a hash-consed meta-object (the hidden class) to identify objects with the same layouts. With IC and HC, object property access can often be speculatively simplified down to a few instructions.</p>
<h4 id="Type-Speculation-and-OSR-Exit">Type Speculation and OSR-Exit</h4>
<p>Type speculation is another important speculative optimization. Unlike inline caching, which only speeds up the internal execution of a bytecode and has no global effects, type speculation works across bytecodes, and can drastically simplify the logic of a function.</p>
<p>As the name suggests, type speculation works by predicting the <em>type</em> of certain operands. It relies on the following observation: in most practical programs, the operand types at a given program site are predictable. For example, it’s rare that an <code>a + b</code> is executed in a loop where <code>a</code> is sometimes a number, sometimes a string, and sometimes an object.</p>
<p>Now, if we speculate that an <code>a + b</code> at a program site is likely a numeric add, we will check at runtime that <code>a</code> and <code>b</code> are numbers. However, crucially, if the check fails at runtime (which is unlikely), we will <em>not</em> branch to a slow path. Instead, we <em>bail out</em> from the optimized JIT’ed code, and continue execution in an unoptimized lower VM tier – this is called an <em>OSR exit</em><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>.</p>
<p>It is important to understand the difference between an OSR exit and a slow path: in an OSR exit, we bail out from the optimized function and never return to it, whereas a slow path would return control back to the optimized function. Thanks to OSR-exit, the compiler is safe to do optimizations after <code>a + b</code> based on the assumption that <code>a + b</code> is a numeric add (so that it knows <code>a</code> and <code>b</code> must be numeric, and <code>a + b</code> has no side effects, for example): if the assumption turns out to be false at runtime, since we will bail out from the code, none of the later code relying on the false assumption will be executed.</p>
<p>Type speculation and OSR exit open up opportunities for more optimizations. For example, consider <code>c = a + b; d = a + c</code>. If <code>a + b</code> is speculated to be a numeric add, we know for sure <code>a</code>, <code>b</code> and <code>c</code> must be numbers after the operation (as otherwise we would have OSR-exited). So now we know for sure the expression <code>a + c</code> is also a numeric add, so it needs no type check at all.</p>
<p>Nevertheless, as one can see, type speculation requires expensive analysis of the function, and introduces the complexity of OSR exit. Therefore, type speculation is typically only performed at the optimizing JIT level. Since the focus of this post is the baseline JIT, we will leave the details of type speculation, OSR exit, and the many different optimizations that they enabled to a future post.</p>
<h4 id="Modern-Dynamic-Language-VM-Architecture">Modern Dynamic Language VM Architecture</h4>
<p>Finally, we have gathered enough background to understand how the architecture of modern dynamic language VMs are reached.</p>
<p>First of all, we need an interpreter – there is no reason to afford the startup delay and high memory overhead to compile everything to native code.</p>
<p>Next, we need a baseline JIT tier. The baseline JIT tier is designed to compile fast, so we must not perform expensive optimizations such as type speculation. As a side result, the baseline JIT’ed code is <em>generic</em>: it will never need to OSR exit to the interpreter. This not only eliminates a major complexity, but also allows the optimizing JIT tier to OSR exit to the baseline JIT tier, instead of the interpreter.</p>
<p>The baseline JIT <em>will</em> perform inline caching (IC) optimization, though. As a local optimization that only affects internally how a bytecode is implemented, IC does not slow down compilation speed, while bringing significant performance benefits on its own.</p>
<p>Furthermore, IC collects accurate information about the prior executions, which can be used by the optimizing JIT to do further optimizations. For example, if the optimizing JIT noticed that a call IC only has one entry, which means the call site has only ever seen one target, the optimizing JIT can speculatively inline the call target, which would then expose lots of further optimization opportunities.</p>
<p>Then comes the optimizing JIT tier. Type speculation and OSR-exit form the foundation of optimizing JIT. With type speculation, the compiler can safely assume that certain values have certain type. This allows the compiler to eliminate unnecessary type checks, and without the dynamism factor from dynamic typing, many traditional optimizations designed for static-typed languages can apply.</p>
<p>Modern VMs also <a href="https://sillycross.github.io/2022/04/30/2022-04-30/">employ an optimization</a> called <em>watchpoints</em>, which are external speculative assumptions that the optimizing JIT may assume to be true. When a speculation failure or watchpoint invalidation happens, the JIT’ed code will OSR exit to the baseline JIT tier. This is a lot harder to do than said. However, to keep this post focused, we will leave the details to a future post.</p>
<p>Most of the state-of-the-art VMs, such as <a href="https://github.com/WebKit/WebKit/tree/main/Source/JavaScriptCore" target="_blank" rel="noopener">JavaScriptCore</a>, <a href="https://v8.dev/" target="_blank" rel="noopener">V8</a>, <a href="https://firefox-source-docs.mozilla.org/js/index.html" target="_blank" rel="noopener">SpiderMonkey</a>, and <a href="https://github.com/microsoft/ChakraCore-wiki/blob/master/Architecture-Overview.md" target="_blank" rel="noopener">ChakraCore</a> (RIP), have converged to a high-level architecture similar to what is described above, as illustrated in the figure below.</p>
<p><img src="/images/2023-05-12/vm-archs.png" alt="High level architecture of modern dynamic language VMs"></p>
<p>Specifically, the input program starts executing at the <em>interpreter</em> tier, and hot code eventually gets tiered-up to the <em>baseline JIT</em> tier.</p>
<p>The baseline JIT’ed code is generic, and will never OSR exit to the interpreter. Apart from the JIT’ed code (which gets rid of the overhead of decoding bytecode operands and the indirect dispatch), the baseline JIT tier employs inline caching as the only main optimization.</p>
<p>For the code that gets even hotter, the <em>optimizing JIT</em> tier kicks in. The optimizing JIT does more aggressive optimizations, and generates speculatively optimized code that could OSR-exit into the baseline JIT tier.</p>
<h4 id="Deegen-Motivation-Vision-and-Current-State">Deegen: Motivation, Vision and Current State</h4>
<p>While the multi-tier architecture explained above is undeniably elegant and achieves high performance, it comes at a very high engineering cost.</p>
<p>Under current implementation techniques, hand-coded assembly is ubiquitous in each VM tier. There is little code sharing across tiers or across target hardware platforms, but all of them must be kept in perfect sync and must faithfully implement the semantics of the language in every edge case. As a result, for developer groups not backed by tech giants, the engineering cost from such a complex architecture is unaffordable.</p>
<p><code>Deegen</code> is designed to reduce the high engineering cost via a more systematic approach. The ultimate goal of <code>Deegen</code> is to automatically generate all the VM tiers from a single source of truth – a semantical description of the VM bytecodes written in C++, as illustrated in the figure below.</p>
<p><img src="/images/2023-05-12/deegen-arch.png" alt="The ultimate vision and current state of Deegen"></p>
<p>By generating the VM automatically, <code>Deegen</code> allows any language developer to enjoy the benefits of the high-performance modern multi-tier VM architecture, at an engineering cost similar to writing a naive interpreter.</p>
<p>To evaluate <code>Deegen</code>’s capability in practice, we implemented <a href="https://github.com/luajit-remake/luajit-remake" target="_blank" rel="noopener">LuaJIT Remake</a>, a standard-compliant experimental VM for Lua 5.1.</p>
<p>In <a href="https://sillycross.github.io/2022/11/22/2022-11-22/">a prior post</a>, we demonstrated how we used <code>Deegen</code> to automatically generate a highly-optimized interpreter for LuaJIT Remake, which significantly outperforms LuaJIT’s hand-coded-in-assembly interpreter across a variety of benchmarks.</p>
<p>In this post, we will step further and demonstrate how <code>Deegen</code> could be used to automatically generate a highly-optimized baseline JIT tier for LuaJIT Remake from the same bytecode semantical description.</p>
</div> <!-- background section -->
<h3 id="How-to-Generate-Machine-Code-a-name-after-background-section-a">How to Generate Machine Code?<a name="after_background_section"></a></h3>
<p>For every JIT, this is an unavoidable problem: how do you generate machine code?</p>
<p>A typical solution used by many (<a href="https://github.com/WebKit/WebKit/tree/main/Source/JavaScriptCore" target="_blank" rel="noopener">JSC</a>, <a href="https://v8.dev/" target="_blank" rel="noopener">V8</a>, <a href="https://luajit.org/" target="_blank" rel="noopener">LuaJIT</a>, etc) is a <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/assembler/AbstractMacroAssembler.h.html">hand-coded assembler</a>. The assembler provides APIs (e.g., <code>EmitMovRegReg64</code>) to the JIT, which the JIT uses to emit assembly instructions as machine code one by one.</p>
<p>However, such an approach is clearly infeasible for a meta-compiler like Deegen, as our input is expressed as C++ bytecode semantics.</p>
<p>So can we use LLVM directly at runtime to generate code? Unfortunately this is also impractical, as LLVM’s compilation speed is <a href="https://webkit.org/blog/5852/introducing-the-b3-jit-compiler/" target="_blank" rel="noopener">too slow even for a heavyweight optimizing JIT</a>, not to mention a baseline JIT where fast compilation is a top concern.</p>
<h3 id="Copy-and-Patch-the-Art-of-Repurposing-Existing-Tools">Copy-and-Patch: the Art of Repurposing Existing Tools</h3>
<p>The solution is a paper I wrote years ago: <a href="/assets/copy-and-patch.pdf">Copy-and-Patch Compilation</a>.</p>
<p>In one sentence, Copy-and-Patch is a trick that allows one to generate code without knowing anything about how to generate code.</p>
<p>How is that even possible? While the paper is long, the trick is actually extremely simple, which I will explain here.</p>
<p>Consider the following C++ function:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">evaluate_lhs</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">evaluate_rhs</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">evaluate_add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> evaluate_lhs() + evaluate_rhs();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>When the C++ compiler compiles the above code, it knows nothing about the definition of <code>evaluate_lhs</code> and <code>evaluate_rhs</code>. But it can somehow produce an object file, and the linker can link the object file to <em>any</em> definition of <code>evaluate_lhs</code> and <code>evaluate_rhs</code>, and the final executable would just work.</p>
<h4 id="Relocation-Code-Generation">Relocation = Code Generation</h4>
<p>What does it mean? The object file must contain structured information on how to link <code>evaluate_add</code> against <em>any</em> definition of <code>evaluate_lhs</code> and <code>evaluate_rhs</code>. So if we parse the object file to get that info, at runtime, we can act as the linker, and “link” <code>evaluate_add</code> against any runtime-known <code>evaluate_lhs</code> and <code>evaluate_rhs</code> of our choice to perform an <code>add</code>. This is effectively a JIT<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>!</p>
<p>Of course, the “structured information” has its formal name: <em>linker relocation records</em>. But the name is not important. The important thing is as long as we parsed out those information, we can use them at runtime to emit executable code. And this process is extremely cheap: all it takes is a <code>memcpy</code> followed by a few scalar additions, thus the name “Copy-and-Patch”.</p>
<p>For example, the <code>evaluate_add</code> we just saw will produce an object file with the following contents:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">evaluate_add:</span><br><span class="line">  53 e8 00 00 00 00 89 c3 e8 00 00 00 00 01 d8 5b c3 </span><br></pre></td></tr></table></figure>
<p>with the following linker relocation record:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">offset &#x3D; 2, type &#x3D; R_X86_64_PLT32, sym &#x3D; evaluate_lhs, addend &#x3D; -4</span><br><span class="line">offset &#x3D; 9, type &#x3D; R_X86_64_PLT32, sym &#x3D; evaluate_rhs, addend &#x3D; -4</span><br></pre></td></tr></table></figure>
<p>Then, the following copy-and-patch logic would allow one to JIT this function at any address with any desired <code>evaluate_lhs</code> and <code>evaluate_rhs</code> targets:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">codegen</span><span class="params">(<span class="keyword">uint8_t</span>* dst, <span class="keyword">uint8_t</span>* lhsFn, <span class="keyword">uint8_t</span>* rhsFn)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The contents in the object file</span></span><br><span class="line">  <span class="keyword">constexpr</span> <span class="keyword">uint8_t</span> code[] = &#123; </span><br><span class="line">    <span class="number">0x53</span>, <span class="number">0xe8</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x89</span>, <span class="number">0xc3</span>, </span><br><span class="line">    <span class="number">0xe8</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x00</span>, <span class="number">0x01</span>, <span class="number">0xd8</span>, <span class="number">0x5b</span>, <span class="number">0xc3</span> &#125;;</span><br><span class="line">  <span class="comment">// The "copy" logic</span></span><br><span class="line">  <span class="built_in">memcpy</span>(dst, code, <span class="keyword">sizeof</span>(code));</span><br><span class="line">  <span class="comment">// The "patch" logic based on the relocation records</span></span><br><span class="line">  *(<span class="keyword">uint32_t</span>*)(dst + <span class="number">2</span>) = (<span class="keyword">uint32_t</span>)(lhsFn - (dst + <span class="number">2</span>) - <span class="number">4</span>);</span><br><span class="line">  *(<span class="keyword">uint32_t</span>*)(dst + <span class="number">9</span>) = (<span class="keyword">uint32_t</span>)(rhsFn - (dst + <span class="number">9</span>) - <span class="number">4</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Yes, that’s all of the core trick of Copy-and-Patch: at build time, compile the logic pieces we want to JIT into object file, and parse the object file to obtain the unrelocated code and relocation records (a <em>stencil</em> in the paper’s terminology). At runtime, code generation is simply wiring up the stencils and materializing them into executable code by a <em>copy</em> (<code>memcpy</code>) and a few <em>patches</em> (scalar additions).</p>
<h4 id="Continuation-Passing-Style-Branch">Continuation-Passing Style = Branch</h4>
<p>The generated code above works, but the code quality is miserable. Everything is executed by a <code>call</code> to another function, which is a lot of overhead.</p>
<p>However, what if one rewrites the code to <a href="https://dl.acm.org/doi/10.1145/800179.810196" target="_blank" rel="noopener">continuation-passing style</a>?</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">continuation</span><span class="params">(<span class="keyword">int</span> result)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">evaluate_add</span><span class="params">(<span class="keyword">int</span> lhs, <span class="keyword">int</span> rhs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> result = lhs + rhs;</span><br><span class="line">  [[clang::musttail]] <span class="keyword">return</span> continuation(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Now, the calls are gone. Furthermore, the function will end with a <code>jmp</code> instruction to function <code>continuation</code> (since the call is a <a href="https://en.wikipedia.org/wiki/Tail_call" target="_blank" rel="noopener">tail call</a>). Since we have control over where to put each function at, if we put <code>continuation</code> right after <code>evaluate_add</code>, then we can even eliminate the <code>jmp</code> to a fallthrough altogether<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>.</p>
<p>After employing this trick, it’s fairly easy to prove that the generated code will not contain unnecessary <code>jmp</code> instructions: all the branches must correspond to actual control flow edges in the generated logic.</p>
<p>One of the main reasons that interpreters are slow is the unpredictable indirect dispatch. At this stage, our generated code has no indirect dispatch, in fact, no unnecessary branches at all. This is already a big speedup over an interpreter.</p>
<h4 id="Address-of-External-Symbol-Runtime-Constant">Address of External Symbol = Runtime Constant</h4>
<p>Another important reason that JITs are faster than interpreters is the ability of JIT to burn runtime constants (bytecode operands, etc) into the instruction stream. Can we support it as well?</p>
<p>Of course! The trick is simple:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">char</span> x;  <span class="comment">// define an external variable</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">continuation</span><span class="params">(<span class="keyword">uint64_t</span> value)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">pointer_dereference_at_fixed_offset</span><span class="params">(<span class="keyword">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// "(uint64_t)&amp;x" is the important part</span></span><br><span class="line">  <span class="keyword">uint64_t</span> result = *(<span class="keyword">uint64_t</span>*)((<span class="keyword">uint64_t</span>)ptr + (<span class="keyword">uint64_t</span>)&amp;x);</span><br><span class="line">  [[clang::musttail]] <span class="keyword">return</span> continuation(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>All it takes is to define an external symbol, and use its <em>address</em> as the runtime constant we want to use. Since by definition an external symbol is external, the compiler cannot assume anything about where it resides at<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>. This gives us a way to represent an opaque constant value.</p>
<p>Of course, the linker knows how to patch the code to make the external symbol point to the right location. Thus, we can patch it at runtime to make it represent any runtime constant as well :)</p>
<h4 id="Function-Prototype-Register-Allocation-Combinatorial-Explosion-Instruction-Selection">Function Prototype = Register Allocation / Combinatorial Explosion = Instruction Selection</h4>
<p>Finally, there are <a href="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project#lightweight_jit_compiler_project_goals" target="_blank" rel="noopener">two most important codegen-level optimizations</a>: register allocation and instruction selection<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>. Can we support them as well? The answer is yes. However, these optimizations are primarily only useful for the static language use cases where each bytecode only implements very simple logic<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>. So to keep this post focused, I will not go into details.</p>
<h4 id="Copy-and-Patch-Wrapping-up">Copy-and-Patch: Wrapping up</h4>
<p>I wouldn’t mind at all if you view Copy-and-Patch as a big hack: because it is! But it works! And it works nicely!</p>
<p>As shown <a href="/assets/copy-and-patch.pdf">in the paper</a>, one can use Copy-and-Patch to construct extremely fast baseline JIT that <em>significantly</em> outperforms the existing state-of-the-arts:</p>
<ul>
<li>For WebAssembly, we <a href="https://github.com/sillycross/WasmNow" target="_blank" rel="noopener">implemented a baseline JIT</a> that compiles 4.9x-6.5x faster than Google Chrome’s <a href="https://v8.dev/blog/liftoff" target="_blank" rel="noopener">Liftoff baseline compiler</a>, while also generating 39%-63% faster code.</li>
<li>For SQL database, we implemented a prototype <a href="https://github.com/sillycross/PochiVM" target="_blank" rel="noopener">SQL query baseline JIT</a> that on TPC-H queries, compiles &gt;1000x faster than LLVM -O3, while only generating 24% slower code.</li>
</ul>
<p>Furthermore, Copy-and-Patch perfectly suits Deegen’s needs for a JIT:</p>
<ol>
<li>It does not know or care about what is being JIT’ed. The logic we want to JIT is directly compiled by a C++ compiler into an object file at build time. C&amp;P merely parses the object file to produce the <em>stencils</em>, which can then be used to JIT code at runtime.</li>
<li>The code generation at runtime is extremely fast, which perfectly matches the requirement of a baseline JIT. Note that we are doing a lot of expensive preprocessing work, but all of them happen at build time.</li>
</ol>
<h3 id="Deegen-the-Art-of-Repurposing-Existing-Tools-Continued">Deegen: the Art of Repurposing Existing Tools, Continued</h3>
<p>While Copy-and-Patch is a nice technique, its vanilla form as described above is still not enough to fulfill Deegen’s use case. Specifically, the vanilla Copy-and-Patch still requires quite a bit of manual work to implement the stencils and the runtime logic, whereas in Deegen, all must be fully automatic.</p>
<p>As it turns out, fully automating Copy-and-Patch requires significant design-level improvements to the original technique, which we will cover in this section.</p>
<!-- The vanilla Copy-and-Patch does not support the important domain-specific optimizations required to make dynamic languages fast, e.g., inline caching and hot-cold code splitting. -->
<p>To make things easier to understand, we will use the following hypothetical <code>Add</code> bytecode as example (see <a href="https://sillycross.github.io/2022/11/22/2022-11-22/">prior post</a> for a detailed explanation of the code):</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Add</span><span class="params">(TValue lhs, TValue rhs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!lhs.Is&lt;tDouble&gt;() || !rhs.Is&lt;tDouble&gt;()) &#123;</span><br><span class="line">    ThrowError(<span class="string">"Can't add!"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">double</span> res = lhs.As&lt;tDouble&gt;() + rhs.As&lt;tDouble&gt;();</span><br><span class="line">    Return(TValue::Create&lt;tDouble&gt;(res));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Identifying-the-Runtime-Constants">Identifying the Runtime Constants</h4>
<p>To get good performance, it is almost mandetory for a JIT to be able to burn runtime constants (bytecode operands, etc.) into the instruction flow. In vanilla Copy-and-Patch, the programmer is required to declare the runtime constants by special macros. So our first improvement is to make this step automatic.</p>
<p>Fortunately this is fairly easy. In our case, the runtime constants are the bytecode operands, and for the IC, everything in the IC state. Since Deegen is already responsible for generating the bytecode decoding logic and the encoding / decoding of the IC state, all we need to do is to not emit the decoding logic, but a magic function call, so that the later processing stages knows that the value is a runtime constant.</p>
<p>For example, for <code>Add</code>, we know that the bytecode slot ordinal of <code>lhs</code>, <code>rhs</code> and the output slot are runtime constants. So the bytecode semantic function will be lowered to LLVM IR that conceptually resembles the following C logic:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">size_t</span> lhs_slot = __runtime_constant_lhs_slot();</span><br><span class="line"><span class="keyword">size_t</span> rhs_slot = __runtime_constant_rhs_slot();</span><br><span class="line">TValue lhs = <span class="built_in">stack</span>[lhs_slot];</span><br><span class="line">TValue rhs = <span class="built_in">stack</span>[rhs_slot];</span><br><span class="line"><span class="keyword">if</span> (!lhs.Is&lt;tDouble&gt;() || !rhs.Is&lt;tDouble&gt;()) &#123;</span><br><span class="line">  ThrowError(<span class="string">"Can't add!"</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">double</span> res = lhs.As&lt;tDouble&gt;() + rhs.As&lt;tDouble&gt;();</span><br><span class="line">  <span class="comment">// Lowered from the Return() API</span></span><br><span class="line">  <span class="keyword">size_t</span> output_slot = __runtime_constant_output_slot();</span><br><span class="line">  <span class="built_in">stack</span>[output_slot] = TValue::Create&lt;tDouble&gt;(res);</span><br><span class="line">  __dispatch_to_next_bytecode();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Correspondingly, at runtime, in order for the generated JIT to generate code, it needs to decode the bytecode struct to retrieve all the operand values and use these values to materialize the copy-and-patch stencils: we will showcase the concrete generated implementation of the <code>__codegen_Add</code> function (which emits machine code for <code>Add</code> at runtime) later in the post.</p>
<h4 id="Propagating-the-Runtime-Constants">Propagating the Runtime Constants</h4>
<p>Acute readers may have noticed that the C logic above cannot result in optimal code. Consider line 3: <code>TValue lhs = stack[lhs_slot]</code>. What actually happens in this line is that we are decoding address <code>(uint64_t)stack + lhs_slot * 8</code> (since each <code>TValue</code> is 8 bytes). If we only make <code>lhs_slot</code> a runtime constant (as we are doing right now), there is no way for LLVM to fold <code>lhs_slot * 8</code> into a constant (recall that at LLVM level, a runtime constant is really the address of an external symbol). As a result, it will generate less-optimal code like <code>mov $XXXX, %rax; shl 3, %rax</code>.</p>
<p>Therefore, we need a customized LLVM constant propagation pass to identify all the constant expressions derived from the “root” runtime constants. Then, we should make each constant expression a runtime constant. Of course, this also means that at runtime, in order to populate these derived runtime constants with concrete values, the codegen function needs to replay the computation of the expression using the concrete values of the root runtime constants.</p>
<p>After this transform, the LLVM IR of our <code>Add</code> example would resemble the following C logic:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">size_t</span> tmp1 = __derived_runtime_constant_1();</span><br><span class="line"><span class="keyword">size_t</span> tmp2 = __derived_runtime_constant_2();</span><br><span class="line">TValue lhs = *(TValue*)((<span class="keyword">uint64_t</span>)<span class="built_in">stack</span> + tmp1);</span><br><span class="line">TValue rhs = *(TValue*)((<span class="keyword">uint64_t</span>)<span class="built_in">stack</span> + tmp2);</span><br><span class="line"><span class="keyword">if</span> (!lhs.Is&lt;tDouble&gt;() || !rhs.Is&lt;tDouble&gt;()) &#123;</span><br><span class="line">  ThrowError(<span class="string">"Can't add!"</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">double</span> res = lhs.As&lt;tDouble&gt;() + rhs.As&lt;tDouble&gt;();</span><br><span class="line">  <span class="comment">// Lowered from the Return() API</span></span><br><span class="line">  <span class="keyword">size_t</span> tmp3 = __derived_runtime_constant_3();</span><br><span class="line">  *(TValue*)((<span class="keyword">uint64_t</span>)<span class="built_in">stack</span>+tmp3) = TValue::Create&lt;tDouble&gt;(res);</span><br><span class="line">  __dispatch_to_next_bytecode();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>where the derived runtime constants <code>__derived_runtime_constant_1/2/3</code> are defined as follow:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__derived_runtime_constant_1 :&#x3D; lhs_slot * 8</span><br><span class="line">__derived_runtime_constant_2 :&#x3D; rhs_slot * 8</span><br><span class="line">__derived_runtime_constant_3 :&#x3D; output_slot * 8</span><br></pre></td></tr></table></figure>
<h4 id="Fixing-the-Symbol-Range-Assumption">Fixing the Symbol Range Assumption</h4>
<p>As we already explained, in Copy-and-Patch, a runtime constant is expressed by the address of an external symbol.</p>
<p>While it is a neat trick that is crucial for high-quality code, it could break down and cause miscompilation in edge cases. For example, consider the code below:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">char</span> x;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">uint64_t</span> val = (<span class="keyword">uint64_t</span>)&amp;x;</span><br><span class="line">  <span class="keyword">if</span> (val == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">/* do something */</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>LLVM would deduce that the <code>val == 0</code> check is trivially false, and “optimize away” the whole if-clause. Why? Because <code>val</code> is the address of variable <code>x</code>, and of course the address of a variable is never <code>0</code>, good game.</p>
<p>In vanilla Copy-and-Patch, the programmer is responsible for avoiding such corner cases. But in Deegen, where stencils are automatically generated, we must find a systematic and provably-correct solution.</p>
<p>So what’s the issue? You might think the issue is “symbol must not be null”. That’s what I initially believed as well<sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup>, but I later realized it is only the symptom of a much larger issue.</p>
<p>As it turns out, according to <a href="https://refspecs.linuxbase.org/elf/x86_64-abi-0.99.pdf" target="_blank" rel="noopener">x86-64 ABI</a>, every symbol will reside in address range <code>[1, 2^31 - 2^24)</code><sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup>. This is also exactly the assumption held by LLVM, and used by LLVM to do optimizations (e.g., in the example above, it deduces that the address of a symbol must not equal <code>0</code>). So the “<code>val == 0</code> check” example is not the only buggy case. LLVM can, for example, do a zero extension instead of a sign extension, as it believes that the address of the symbol must have bit <code>31</code> being <code>0</code> thus a <code>ZExt</code> is equivalent to a <code>SExt</code>, causing buggy code if the runtime constant were to represent a negative value.</p>
<p>One might think the <code>[1, 2^31 - 2^24)</code> range assumption is artificial, but it isn’t. This range assumption is actually important to generate correct code. For a simple example, the code <code>movq sym+100(%rax), %rax</code> would not work correctly due to an <code>int32_t</code> overflow in the imm32 addressing mode field of the instruction, if <code>sym</code> were to have value <code>2^31 - 50</code>.</p>
<p>Therefore, for a provably correct solution, we must make sure that whenever we use an external symbol to represent a runtime constant, the runtime constant we want to express must fit in <code>[1, 2^31 - 2^24)</code>.</p>
<p>In Deegen, this is accomplished by a customized Constant Range Analysis pass to track the range of every constant expression based on the runtime constants. Of course, we also need to know the possible range for the “root” runtime constants – the bytecode operands, and the values captured by the IC state. Fortunately, for most of them, the range is implicit (for example, a bytecode slot is known to be a small non-negative integer, and an operand with type <code>uint16_t</code> obviously fits in <code>[0, 65535]</code>) and requires no user intervention. For the rest, a new Deegen API is added so the user can tell us the range assumption of the value.</p>
<p>Once we figured out the proven range of each runtime constant expression, we can retrofit it into our target range <code>[1, 2^31 - 2^24)</code> by simple transformation. To explain how it works, let’s revisit our <code>Add</code> example:</p>
<ul>
<li><code>lhs_slot</code> is a root runtime constant. Since it represents a bytecode slot ordinal, it is known to be a small non-negative integer, say <code>[0, 10000]</code>.</li>
<li>And we have a derived runtime constant <code>lhs_slot * 8</code>, which is known to fit in <code>[0, 80000]</code> by range analysis.</li>
<li>The range <code>[0, 80000]</code> does not fit in <code>[1, 2^31 - 2^24)</code>.</li>
<li>However, if we define a new expression <code>new_expr := lhs_slot * 8 + 1</code>, the new expression would have range <code>[1, 80001]</code> and fit the assumption.</li>
<li>Therefore, we use an external symbol <code>sym</code> to represent <code>lhs_slot * 8 + 1</code>, and rewrite the LLVM IR to substitute <code>lhs * 8</code> with <code>sym - 1</code>.</li>
</ul>
<p>Now, we are guaranteed correct code as the symbol range assumption is met.</p>
<p>Lastly, if the range of an expression is too large to fit in <code>[1, 2^31 - 2^24)</code>, we simply give up. This means the expression will be evaluated at runtime, but this is rare, and is only a minor performance issue, not a correctness issue.</p>
<p>After this transformation, the conceptual logic of the <code>Add</code> example would look like something below:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">size_t</span> tmp1 = __derived_runtime_constant_1() - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">size_t</span> tmp2 = __derived_runtime_constant_2() - <span class="number">1</span>;</span><br><span class="line">TValue lhs = *(TValue*)((<span class="keyword">uint64_t</span>)<span class="built_in">stack</span> + tmp1);</span><br><span class="line">TValue rhs = *(TValue*)((<span class="keyword">uint64_t</span>)<span class="built_in">stack</span> + tmp2);</span><br><span class="line"><span class="keyword">if</span> (!lhs.Is&lt;tDouble&gt;() || !rhs.Is&lt;tDouble&gt;()) &#123;</span><br><span class="line">  ThrowError(<span class="string">"Can't add!"</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">double</span> res = lhs.As&lt;tDouble&gt;() + rhs.As&lt;tDouble&gt;();</span><br><span class="line">  <span class="comment">// Lowered from the Return() API</span></span><br><span class="line">  <span class="keyword">size_t</span> tmp3 = __derived_runtime_constant_3() - <span class="number">1</span>;</span><br><span class="line">  *(TValue*)((<span class="keyword">uint64_t</span>)<span class="built_in">stack</span>+tmp3) = TValue::Create&lt;tDouble&gt;(res);</span><br><span class="line">  __dispatch_to_next_bytecode();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>where the derived runtime constants <code>__derived_runtime_constant_1/2/3</code> are defined as follow:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__derived_runtime_constant_1 :&#x3D; lhs_slot * 8 + 1</span><br><span class="line">__derived_runtime_constant_2 :&#x3D; rhs_slot * 8 + 1</span><br><span class="line">__derived_runtime_constant_3 :&#x3D; output_slot * 8 + 1</span><br></pre></td></tr></table></figure>
<p>Note that in normal cases, those <code>+1 / -1</code> adjustments will not end up as machine instructions in the resulting JIT code, as normally all of those computation ends up being an imm32 field of an instruction, as we’ll see in the example below.</p>
<h4 id="Example-Generated-Code-for-the-AddVV-Bytecode">Example: Generated Code for the <code>AddVV</code> Bytecode</h4>
<p>For a concrete example, the figure below demonstrates the disassembly of the actual JIT code generated for the Lua <code>AddVV</code> bytecode, which performs a Lua <code>add</code> on the given two bytecode values. The C++ bytecode semantic that Deegen takes as input is <a href="https://github.com/luajit-remake/luajit-remake/blob/f8fb972ec91c28b849bd263f164832f0ff434d1f/annotated/bytecodes/arithmetic_bytecodes.cpp" target="_blank" rel="noopener">here</a>.</p>
<p><img src="/images/2023-05-12/add-generated-code.png" alt="Disassembly of the JIT'ed machine code for the Lua AddVV bytecode"></p>
<p>The blue boxes indicates the runtime constants that gets burnt into the instruction stream, with their value definitions shown on the right.</p>
<p>Note that the code contains two separated parts: <code>fast_path</code> and <code>slow_path</code>. We will explain this in detail in the next section: for now focus on <code>fast_path</code> only.</p>
<p>As one can see, the code quality has no problem rivalling a hand-written baseline JIT. It loads the two operands from the stack frame, and checks if any of them is <code>NaN</code>, which means either double <code>NaN</code> or a non-double value (which will exhibit as <code>NaN</code> in our NaN-boxing scheme). If so, it branches to <code>slow_path</code>. Otherwise, it performs a <code>double</code> addition and stores the result back to the <code>output_slot</code> in the stack frame. Finally, the control implicitly fallthroughs to the next bytecode.</p>
<p>The implementation of the JIT compiler logic that generates the above code at runtime will be showcased in the next section.</p>
<h3 id="Design-of-the-Baseline-JIT">Design of the Baseline JIT</h3>
<p>Having covered the core of the JIT code generation system, we are finally ready to explore the design of the JIT itself and the supporting components.</p>
<p>For a quick overview, the following figure illustrates the high-level architecture of the baseline JIT (except inline caching, which is complex enough that deserves its own section):</p>
<p><img src="/images/2023-05-12/baseline-jit-arch.png" alt="A summary of the high-level architecture of Deegen's baseline JIT (except IC)"></p>
<h4 id="The-AOT-Slow-Path">The AOT Slow Path</h4>
<p>A distinctive “feature” of dynamic languages is the pervasive existence of slow paths. For example, if you call a boolean value like <code>true</code> (why would anyone do that?), it could trigger some complicated metamethod lookup in Lua, ending up with a function to call or an error. In Deegen, a slow path can be created by both automatic type-based quickening and explicit user annotation (the <code>EnterSlowPath</code> API). But for the JIT, there are some extra complexity in implementing them.</p>
<p>Obviously, the slow path logic should be AOT-compiled, not JIT’ed. However, this introduces two problems:</p>
<ol>
<li>How the JIT’ed code could transfer control to the AOT slow path.</li>
<li>How the AOT slow path could transfer control back to the JIT’ed code.</li>
</ol>
<p>Let’s look at the second problem first. The bytecode stream does not contain any information about the JIT’ed code. Also, the slow path could make branches to other bytecodes and calls to other functions, so it’s not as easy as letting the JIT’ed code pass the JIT address of the next bytecode to the slow path.</p>
<p>Deegen’s solution is a dedicated <code>SlowPathData</code> stream. The <code>SlowPathData</code> stream is similar to the bytecode stream, except that it is intended to be used by the AOT slow path of the JIT tier, instead of the interpreter. A <code>SlowPathData</code> contains all the information needed by the slow path, such as bytecode operands, JIT address for this bytecode, JIT address of the conditional branch target of this bytecode, etc. When the JIT’ed code wants to transfer control to the slow path, it would pass the <code>SlowPathData</code> pointer corresponding to the current bytecode to the AOT slow path. The AOT slow path can then have access to all the data it needs to complete the execution and transfer control back to JIT’ed code.</p>
<p>Of course, the <code>SlowPathData</code> stream has to be generated. Fortunately, since Deegen understands the bytecode stream, it is not hard to generate logic that transcribes the bytecode stream to the <code>SlowPathData</code> stream. Specifically, the generated JIT compiler will generate the <code>SlowPathData</code> stream alongside the executable code.</p>
<p>Now let’s look at the first problem. Transferring control from JIT’ed code to the AOT slow path requires some set up logic, for example, to correctly set up the <code>SlowPathData</code> pointer. However, these logic are rarely executed, as slow paths are, of course, rarely used. If no special handling is taken, the resulted code would have cold logic and hot logic mixed together, resulting in unnecessary additional branches and worse code locality. Of course, this is not a correctness problem, but ideally we want to handle it without sacrificing compilation time.</p>
<p>Deegen employs the solution used in JavaScriptCore: <em>hot-cold code splitting</em>, except that Deegen must accomplish it automatically. Specifically, every stencil will be split into a hot part and a cold part. The JIT will generate two streams of executable code, one holding all the hot path logic, and one holding all the slow path logic. The hot-cold splitting is accomplished by an ASM transformation pass, which we will elaborate in the next section.</p>
<h4 id="The-Baseline-JIT-Algorithm">The Baseline JIT Algorithm</h4>
<p>We now have all the pretexts to understand how the baseline JIT itself works.</p>
<p>In addition to the logic that actually generates machine code, Deegen also generates a <em>bytecode trait table</em> that contains various info about the generated code for each bytecode, e.g., the length of the JIT’ed code’s hot part and cold part, the length and alignment of the data section accompanying the JIT’ed code, the length of the <code>SlowPathData</code> for this bytecode, etc. This allows the baseline JIT to precompute all the buffer sizes in advance.</p>
<p>The baseline JIT compiler works in two passes.</p>
<p>In the first pass, we iterates through the bytecode stream, and use the bytecode trait table to compute various buffer sizes of the generated code and data. All the buffers are then allocated in advance, knowing that a buffer overrun will never happen when we actually fill contents (code, data, etc.) into the buffers. This pass is very cheap because no indirect dispatch is needed.</p>
<p>In the second pass, we iterates through the bytecode stream again, and generate everything (executable code, the accompanying data, the <code>SlowPathData</code>, etc.) for each bytecode by populating the pre-allocated buffers. This step conceptually works similar to an interpreter. We have a pre-built dispatch table storing the codegen functions for each bytecode kind. Control is first transferred to the codegen function for the first bytecode. The function would generate everything needed for the first bytecode, advance buffer pointers accordingly, and then transfer control to the codegen function for the next bytecode. This process repeats until the end of the bytecode stream is reached.</p>
<p>Thanks to Copy-and-Patch, each codegen function is completely branchless, except the tail dispatch that transfers control to the next codegen function, as we shall see in the <code>Add</code> example below. This allows a modern CPU to utilize its Instruction-Level Paralleism (ILP) capabilities to the utmost, yielding an extremely fast compilation process.</p>
<p>Finally, due to the nature of one-pass code generation, bytecodes that can branch to other bytecodes would not know their branch destination address at the time their own code is being generated. To solve this issue, those bytecodes would push information about how the branch destination address shall be fixed up into a late-patch buffer. After all code generation is done, we need to iterate through the late-patch buffer and fix up all the branch targets.</p>
<h4 id="Example-Code-Generation-Function-for-the-AddVV-Bytecode">Example: Code Generation Function for the <code>AddVV</code> Bytecode</h4>
<p>Below is the actual code-generation logic generated by Deegen that generates code for the Lua <code>AddVV</code> bytecode. The machine code generated by the logic is demonstrated in the right half of the figure for cross-reference.</p>
<p><img src="/images/2023-05-12/add-code-gen.png" alt="Generated JIT logic that generates code for AddVV (left) and the generated code (right)"></p>
<p>As one can see, the code-generation logic is just what we have explained in the previous subsection. It first decodes the bytecode, then performs a copy-and-patch to generate the JIT fast path and the JIT slow path logic. The expression that defines each runtime constant is replayed to compute the patch value in the instruction stream. Besides the machine code, it also generates the <code>SlowPathData</code> stream and other minor support data. Finally, it advances pointers and dispatch to the next codegen function to codegen the next bytecode. The whole process is completely branchless (except the tail dispatch) by design.</p>
<h3 id="Supporting-Inline-Caching-the-Art-of-Repurposing-Existing-Tools-Evermore">Supporting Inline Caching: the Art of Repurposing Existing Tools, Evermore</h3>
<p>Due to inherent design constraints of a baseline JIT (e.g., compilation must be fast, no OSR-exit is allowed), inline caching (IC) is the only high-level optimization tool available to the baseline JIT.</p>
<p>And inline caching is powerful: on benchmarks that extensively work with Lua tables, a baseline JIT with IC can often be more than 100% faster than the same baseline JIT without IC<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup>.</p>
<p>In this section, we will elaborate how Deegen supports inline caching.</p>
<h4 id="How-IC-works-in-Deegen-a-Step-by-Step-Example-of-Call-IC">How IC works in Deegen: a Step-by-Step Example of Call IC</h4>
<p>For a beginner’s introduction to what IC is, please read the <a href="#deegen_baseline_jit_background_section">background section</a>. However, to understand how IC actually works in Deegen’s baseline JIT, the easiest way is to walk through an assembly example. Here, we will use a simplified <code>Call</code> bytecode, which performs a call with no arguments and discards all return values, to demonstrate how <em>call IC</em> works.</p>
<p>The C++ bytecode semantic description is very simple:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReturnContinuation</span><span class="params">(TValue* <span class="comment">/*base*/</span>)</span> </span>&#123; Return(); &#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Call</span><span class="params">(TValue* base)</span> </span>&#123;</span><br><span class="line">  TValue func = *base;</span><br><span class="line">  <span class="keyword">if</span> (likely(func.Is&lt;tFunction&gt;())) &#123;</span><br><span class="line">    TValue* newStackFrame = base + x_numSlotsForStackFrameHeader;</span><br><span class="line">    MakeInPlaceCall(func.As&lt;tFunction&gt;(), </span><br><span class="line">                    newStackFrame, </span><br><span class="line">                    <span class="number">0</span> <span class="comment">/*numArgs*/</span>, </span><br><span class="line">                    ReturnContinuation);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    EnterSlowPath&lt;CheckMetatableSlowPath&gt;();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>It checks if the callee is a function object. If so, it uses Deegen’s <code>MakeInPlaceCall</code> API to make a call, and the return continuation simply discards all return values and transfer control to the next bytecode. Otherwise, it enters the outlined slow path function (omitted) that checks for a metatable call.</p>
<p>Deegen would generate the following JIT code for this bytecode:</p>
<p><img src="/images/2023-05-12/call-bytecode-main-logic.png" alt="JIT code generated for the example Call bytecode"></p>
<p>Note that runtime constants are marked in purple in the form of <code>${X}</code>.</p>
<p>Let’s pretend for now that the <code>codegen_call_ic</code> thing doesn’t exist, and look at the naive implementation. If you stare at the assembly code a little bit, you will notice that the logic involves:</p>
<ol>
<li>Two branches to check that <code>func</code> is a function object.</li>
<li>Two dependent memory loads: one loads the function prototype <code>proto</code> from <code>func</code>, and one loads the actual entry point address from <code>proto</code>.</li>
<li>One indirect branch to branch to the entry point.</li>
</ol>
<p>Unfortunately, dependent memory loads and unpredictable indirect branchs are <em>exactly</em> the two things modern CPUs hate the most. Even predictable branches can be slow, if there are too many of them so that the BTB is overwhelmed.</p>
<p>So how does IC speeds up this code?</p>
<p>As one might have expected, <code>codegen_call_ic</code> will be called on the first time this code is executed. What <code>codegen_call_ic</code> does is that it will emit a piece of IC code snippet, and chain it to the main logic by repatching the self-modifying-code (SMC) region, as shown below:</p>
<p><img src="/images/2023-05-12/call-bytecode-direct-call-ic-1.png" alt="The JIT code after one IC entry is created"></p>
<p>As one can see, the next time the same function is called, thanks to the SMC region, the IC will hit, and the optimized logic will be executed. The optimized logic does not check that <code>func</code> is a function object (because we already checked it last time), has no memory loads, and the branch is direct.</p>
<p>This process can be repeated to chain any number of IC entries into a chain:</p>
<ul>
<li>SMC region branches to IC <code>#N</code></li>
<li>IC <code>#N</code> branches to IC <code>#(N-1)</code> if the cached value does not hit</li>
<li>… etc …</li>
<li>IC <code>#1</code> branches to the IC miss slow path, which will create a new IC snippet <code>#(N+1)</code> and chain it at the head of the chain.</li>
</ul>
<p>Of course, at a certain point the overhead from the check chain would cancel out the benefit of the optimized code, and we will stop chaining more cases.</p>
<h4 id="Call-IC’s-Direct-Call-Mode-vs-Closure-Call-Mode">Call IC’s Direct Call Mode vs Closure Call Mode</h4>
<p>While the above approach works well if a Lua function is used like a C function (monomorphism) or a C++ virtual method (class-like polymorphism), it would work very poorly for the <em>function factory</em> design pattern. For example, consider the following Lua snippet:</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">createCounter = <span class="function"><span class="keyword">function</span><span class="params">()</span></span> </span><br><span class="line">  <span class="keyword">local</span> value = <span class="number">0</span></span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span><span class="params">()</span></span> </span><br><span class="line">    value = value + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">incrementCounter = <span class="function"><span class="keyword">function</span><span class="params">(counter)</span></span></span><br><span class="line">  <span class="keyword">return</span> counter()</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>In this example, the call in line <code>9</code> is likely to see a lot of different function objects, even though all of them share the same prototype (the counter lambda in line <code>3</code>). Since our current call IC strategy caches on the function object, not the function prototype, it is completely ineffective for this use pattern.</p>
<p>Again, we employ the solution used in JavaScriptCore. Our call IC supports two modes: <em>direct call</em> mode and <em>closure call</em> mode. A call IC site always starts in direct call mode, in which it caches on function objects, as we have shown above.</p>
<p>But when a call IC site first sees a IC miss that has the same function prototype as one of the already-cached function objects, it will transition the IC to closure-call mode. To do this, it rewrites the self-modifying code region and invalidates all existing ICs at this site, and from now on, this IC site will instead cache on the function prototypes. This is demonstrated by the figure below:</p>
<p><img src="/images/2023-05-12/call-bytecode-closure-call-ic-1.png" alt="The JIT code after the Call IC transitions to Closure Call Mode"></p>
<p>As one can see, the SMC region is repatched to completely different logic: it checks if <code>func</code> is a heap object (which is required for us to load its hidden class), then load the hidden class of the heap object and branch to the first IC case.</p>
<p>Each closure call IC case caches on a function prototype. So it compares if the hidden class matches the cached prototype. If yes, it knows that <code>func</code> must be a function object with the cached prototype, so it can perform an optimized call similar to before.</p>
<p>Of course, one can also chain up as many IC cases in closure call as desired, until the chained check overhead overwhelms the perf gain from the optimized code.</p>
<p>As one can see, closure call mode is less efficient than direct call mode as it performs one extra check and one extra memory load, but it works effectively for the function factory design pattern. This is why a call IC site always starts in direct call mode, and only transitions to closure call mode when it actually observes a closure call pattern.</p>
<h4 id="So-How-to-Automatically-Generate-All-of-These">So, How to Automatically Generate All of These?</h4>
<p>Having understood how IC works in Deegen (we only demonstrated Call IC, but the case for Deegen’s Generic IC API is similar), the next question is: how could Deegen generate all of these automatically?</p>
<p>However, as you can already see, what we want to do is something totally outside the operating envelope of LLVM. LLVM is simply not designed to generate a function that can dynamically patch itself at runtime to append a dynamic chain of parametrizable code snippets.</p>
<p>As before, our solution is to repurpose existing tools to trick LLVM into helping us without its knowledge. And as it turns out, the core of the trick is to repurpose a completely-irrelevant little-known GCC feature in the dark corner.</p>
<h4 id="Thank-you-GCC-ASM-goto">Thank you, GCC ASM-goto!</h4>
<p>GCC supports a little-known extension feature called <a href="https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html#:~:text=6.47.2.7%20Goto%20Labels" target="_blank" rel="noopener">ASM-goto</a>, which basically allows one to write inline assembly that branches from assembler code to C labels. And LLVM, aiming for compatibility with GCC, <a href="https://lists.llvm.org/pipermail/llvm-dev/2018-October/127239.html" target="_blank" rel="noopener">has also supported this feature a few years ago</a> by a special <code>CallBr</code> IR instruction.</p>
<p>I just want to say a big thank you to the GCC developers who designed this feature and the LLVM developers who added support for it! Without this feature, it’s very likely Deegen couldn’t support inline caching at all.</p>
<p>So how does ASM-goto have anything to do with inline caching?</p>
<p>As you might have seen from the assembly example above, the hard part of IC is that each IC case is a piece of machine code that directly “clings” to the main logic. It cannot be implemented by a separate function due to the call overhead and the requirements of Lua’s stackful coroutine. It must work directly using the context (e.g., which register holds which value) of the main logic, and could transfer control to different destinations in the main logic.</p>
<p>ASM-goto (and its underlying <code>CallBr</code> LLVM IR) provided <em>exactly</em> the semantics we want. Since it is an <code>InlineAsm</code>, LLVM is <em>required</em> to treat its contents as opaque. All LLVM knows is that after executing the <code>InlineAsm</code>, control will be transferred to one of the destinations specified in the <code>CallBr</code>.</p>
<p>In other words, we repurpose <code>CallBr</code> as a way to model “a control flow transfer in an unspecified manner”. At runtime, we are building up a dynamic chain of IC cases; but if one views the chain-check logic as a black box, then it can be characterized as: after the black box is executed, control is transferred to either an IC hit case specialized to the cached values, or the IC miss slowpath. This is exactly the semantics <code>CallBr</code> provided, so we can safely model it using <code>CallBr</code>.</p>
<p>But this is still far from enough. Now we have a way to model the control flow of the dynamic IC chain in LLVM IR, but it’s still unclear how we can extract the IC logic from the main function, implement the IC check chain, and do all the self-modifying code stuff.</p>
<p>This is where the last piece of the puzzle comes in: ASM transformation.</p>
<h4 id="ASM-Transformation-the-Last-Piece-of-the-Puzzle">ASM Transformation: the Last Piece of the Puzzle</h4>
<p>I know this might scare off people, as directly messing with assembly sounds like an extremely fragile approach.</p>
<p>But it really isn’t. Deegen treats most of the assembly instructions as opaque and will not modify any of them. The ASM transformation is limited to reordering and extracting ASM blocks.</p>
<p>As a result, Deegen’s assembly knowledge is extremely limited. All it knows is that:</p>
<ul>
<li>A <code>jmp</code> does a direct jump.</li>
<li>A <code>jmpq</code> does an indirect jump.</li>
<li>Any other instruction starting with <code>j</code> does a conditional jump.</li>
</ul>
<p>However, as it turns out, with some clever tricks and cooperation from LLVM IR, doing only ASM block rearrangements is already sufficient to achieve a lot: we can support all the inline caching stuffs, among other things.</p>
<p>The full trick is the following. Recall that we are only using <code>CallBr</code> as a device to express an opaque control flow, and the <code>InlineAsm</code> inside <code>CallBr</code> does not matter. So we will use this <code>InlineAsm</code> to carry down information to the textual assembly level, as shown below.</p>
<p><img src="/images/2023-05-12/callbr-example.png" alt="The CallBr trick at LLVM IR level and the resulting assembly"></p>
<p>As one can see, the previledged instruction <code>hlt</code> is used as a magic to allows us to identify the <code>CallBr</code> in the textual assembly. Then, the fake branches following the <code>hlt</code> allows us to know the assembly labels that implements each logic case.</p>
<p>Having parsed these information, we no longer need the <code>CallBr</code> payload, so we remove it from assembly, and make it branch to the slow path directly.</p>
<p>Next, we perform a CFG analysis of the assembly. The only hard part about the CFG analysis is to know the possible destinations of the indirect branches. This ideally should be implemented as a LLVM backend pass, but I haven’t figured out how to do it due to limited documentation about LLVM backend. So currently, the indirect branch target analysis is done via some hacks that map the indirect branch back to LLVM IR by debug info.</p>
<p>Now we have the CFG of the assembly, we can then figure out the ASM blocks only reachable from the function entry, and only reachable from each IC logic kind, as shown below.</p>
<p><img src="/images/2023-05-12/ic-extraction.png" alt="ASM CFG Analysis and IC Extraction"></p>
<p>Note that the logic entry of each IC kind must not be reachable from the function entry, because they are only reachable by the <code>CallBr</code>, but we have removed those control flow edges as the <code>CallBr</code> has been removed by us.</p>
<p>Finally, we can separate out the IC logic from the main function logic. For the main function, we only retain ASM blocks reachable from the function entry. And for each IC kind, we only retain ASM blocks reachable from its logic entry but not the main function entry. Each piece of extracted assembly is then compiled to object file and extracted to a Copy-and-Patch stencil, so we can JIT it at runtime.</p>
<p>There are still some minor issues that we haven’t covered, such as how we build up the dynamic IC check chain, and how exactly the self-modifying code region is constructed. But the idea is similar to how we supported inline caching: most of the heavy-lifting of actually building up the logic is done at LLVM, and <code>InlineAsm</code> is repurposed as a tool to pass down information to assembly. Then at assembly level, Deegen can piece everything together by very simple transformations that requires little to no assembly knowledge.</p>
<h4 id="The-Inline-Slab-Optimization">The Inline Slab Optimization</h4>
<p>Deegen employed one additional optimization for IC: the <em>Inline Slab</em> optimization (again, the terminology is a JavaScriptCore jargon).</p>
<p>Conceptually, the idea is very simple: currently, each IC case is an outlined piece of JIT code. As a result, control has to branch from main logic to the IC case, and then from the IC case back to the main logic in the end. So why not use the SMC region to hold one IC case? Now, the “blessed” IC case sitting directly inside the SMC region can be executed directly, saving one or two jumps<sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>.</p>
<p>Of course, it is harder to do than said. One has to decide a good size for the inline slab (i.e., the SMC region), as only IC whose size is less than the inline slab size can sit in the inline slab. And updating the patchable jump in the SMC region is more complicated, as the location of the jump is different depending on whether the inline slab exists. Finally, the inline slab version of the IC has slightly different logic from the normal version: the tail branch could potentially be eliminated, and one must pad NOPs to exactly the size of the inline slab.</p>
<p>As a result, even in JavaScriptCore, the inline slab optimization requires quite some engineering efforts, e.g., more hand-rolled assembly, <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/bytecode/InlineAccess.h.html">manual book-keeping of the inline slab sizes</a> that has to be updated whenever the generated assembly changes, etc.</p>
<p>Fortunately, in Deegen, the inline slab optimization is employed fully automatically. So for a language implementer, the additional ~4% performance on average (and occasionally 10+% on IC intensive workloads) from inline slab comes for free!</p>
<h4 id="Runtime-Support-and-IC-Design-Summary">Runtime Support, and IC Design Summary</h4>
<p>Finally, the VM runtime needs to manage the IC. For example, it needs to reclaim the JIT code memory when the IC is invalidated, and upon tiering-up, it needs to update all the call IC cases to point to the new entry point.</p>
<p>Therefore, in additional to the actual JIT’ed code, we also need to allocate a piece of metadata to manage each IC. The metadata are chained into a linked list at the use site of the IC (the <code>ICSite</code>), which resides in the <code>SlowPathData</code> stream.</p>
<p>Putting everything about Deegen’s IC design together into one figure:</p>
<p><img src="/images/2023-05-12/deegen-ic-design-detail.png" alt="An overview of Deegen's design of Inline Caching in more detail"></p>
<h4 id="Full-Example-for-Deegen’s-Generic-IC-TableGetById-Bytecode">Full Example for Deegen’s Generic IC: <code>TableGetById</code> Bytecode</h4>
<p>To conclude our discussions on inline caching, we will present a full example for the <code>TableGetById</code> (aka., <code>TGETS</code> in LuaJIT) bytecode.</p>
<p>The bytecode takes two operands: <code>base</code> and <code>index</code>, where <code>index</code> is a constant string, and returns <code>base[index]</code>. Any Lua string property access, for example, <code>employee.name</code> or <code>animal.weight</code>, would generate this bytecode.</p>
<p>In <em>LuaJIT Remake</em>, a Lua table is not implemented by a plain hash table with an array part, but employs <a href="https://github.com/luajit-remake/luajit-remake/blob/b9b5274d15373a24f9297cf551621506f87b375f/runtime/structure.h" target="_blank" rel="noopener">hidden class</a> for better performance, using a design <a href="https://webkit.org/blog/10308/speculation-in-javascriptcore/" target="_blank" rel="noopener">mostly mirroring JavaScriptCore’s</a>. Deegen supports <a href="/2022/11/22/2022-11-22/#deegen_generic_inline_caching_api">generic IC API</a> to allow easy deployment of IC via clever use of C++ lambdas. The actual implementation of the C++ bytecode semantic for <code>TableGetById</code> can be <a href="https://github.com/luajit-remake/luajit-remake/blob/b9b5274d15373a24f9297cf551621506f87b375f/annotated/bytecodes/table_get_by_id.cpp#L91" target="_blank" rel="noopener">found here</a>.</p>
<p>The figure below is the disassembly of the actual machine code generated by the baseline JIT, alongside the JIT’ed code for all 6 kinds of IC stubs, as well as their inline-slab versions. As before, the runtime constants burnt into the instruction stream are shown in purple text.</p>
<p><img src="/images/2023-05-12/getbyid_ic.png" alt="Disassembly of the main logic and all IC logic generated for the TableGetById bytecode"></p>
<p>As you can see above, in the good case of an inline-slab IC hit for a table without metatable (which is very common), a <code>TableGetById</code> can be accomplished with no taken branches and in less than 10 instructions. This is why IC could drastically speed up table operations.</p>
<p>On the other hand, as you can also see above, implementing IC by hand requires a deep understanding of assembly and a significant amount of engineering. This is exactly where Deegen comes in. With Deegen’s generic IC API that makes all of these happen automatically, a language implementer can enjoy the benefits of IC without the high engineering cost.</p>
<h4 id="The-Hot-Cold-Splitting-Pass-and-Jump-to-Fallthrough-Pass">The Hot-Cold Splitting Pass and Jump-to-Fallthrough Pass</h4>
<p>Finally, since we already have an ASM transformation infrastructure, why not use it for more good?</p>
<p>The Hot-Cold Splitting Pass works by reordering ASM blocks and move cold blocks to a separated text section, which reduces some unnecessary branches and improves code locality. Of course, the stencil extraction logic that generates the copy-and-patch stencil from the object file needs to be made aware of this and extract both sections, but this is not hard to do. To figure out which blocks are cold, ideally, one should write a LLVM backend pass. However, as explained before, I still haven’t figured out how to write a LLVM backend pass, so currently this is accomplished by injecting debug info to map assembly blocks back to LLVM IR blocks, and use LLVM IR’s block frequency infrastructure to determine the cold blocks.</p>
<p>The Jump-to-Fallthrough transformation pass attempts to move the dispatch to the next bytecode to the last instruction, so that the jump could be eliminated to a fallthrough, reducing an unnecessary branch. This is needed because at LLVM IR level, a dispatch is a tail call, and LLVM is not aware of the fact that a dispatch to the next bytecode could potentially<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup> be implemented by a fallthrough if it were the last instruction. Deegen implemented a simple pass to address this issue, which attempts to make the fallthrough possible by reordering ASM blocks and doing very limited rewrites like flipping branch conditions.</p>
<h3 id="An-End-to-End-Example">An End-to-End Example</h3>
<p>To demonstrate how the actual end-to-end JIT’ed code generated by the baseline JIT looks like, we will use the following Lua example that computes a factorial:</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- Intentionally written without 'local' so that 'fact' </span></span><br><span class="line"><span class="comment">-- is a global variable lookup, to demonstrate the JIT</span></span><br><span class="line"><span class="comment">-- code generated from Deegen's generic inline caching API</span></span><br><span class="line">fact = <span class="function"><span class="keyword">function</span><span class="params">(n)</span></span></span><br><span class="line">  <span class="keyword">if</span> (n &lt; <span class="number">1</span>) <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">  <span class="keyword">end</span> </span><br><span class="line">  <span class="keyword">return</span> fact(n<span class="number">-1</span>) * n</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>While it is a simple example, it demonstrates almost all the important things in a baseline JIT: basic operations such as arithmetic and comparison, control flow, function calls, call inline caching (automatically provided as part of Deegen) and table inline caching (implement using Deegen’s generic IC API).</p>
<p>The above Lua function results in 8 bytecodes:</p>
<ul>
<li>(Bytecode #0) BranchIfNotLessThan {<code>Slot(0)</code>, <code>Double(1)</code>} → #3</li>
<li>(Bytecode #1) ConstInt16  {<code>1</code>} → <code>Slot(1)</code></li>
<li>(Bytecode #2) Return {<code>SlotRange [1, 2)</code>}</li>
<li>(Bytecode #3) GlobalGet {<code>String(&quot;fact&quot;)</code>} → <code>Slot(1)</code></li>
<li>(Bytecode #4) ArithmeticSub {<code>Slot(0)</code>, <code>Double(1)</code>} → <code>Slot(5)</code></li>
<li>(Bytecode #5) Call { Frame: <code>Slot(1)</code>, #arg: <code>1</code>, #ret: <code>1</code> }</li>
<li>(Bytecode #6) ArithmeticMul {<code>Slot(1)</code>,<code>Slot(0)</code>} → <code>Slot(1)</code></li>
<li>(Bytecode #7) Return {<code>SlotRange [1, 2)</code>}</li>
</ul>
<p>For clarity, we demonstrate the code <em>after</em> the function has been executed, so all the self-modifying code regions (including inline slabs) have been repatched, and outlined IC stubs have been created.</p>
<p>I manually grabbed the JIT’ed code using GDB and hand-remapped all the labels, so please pardon me if I made an mistake. The disassembly is as follows:</p>
<p><img src="/images/2023-05-12/factorial-jit-code.png" alt="Disassembly of the JIT'ed code for the factorial function"></p>
<p>Note that under normal circumstances (i.e., a number is passed in as parameter to <code>fact</code>), the <code>GlobalGet</code> and <code>Call</code> slow path will be executed once to create the IC. After that, none of the slow path logic will ever be executed, and none of the self-modifying code region in the fast path will get repatched further.</p>
<h3 id="Tiering-up-Logic">Tiering-up Logic</h3>
<p>The last bit of complexity is the tiering-up logic. In a multi-tier VM, the user program starts execution in the interpreter tier, and hot functions are eventually tiered up to the baseline JIT tier (and potentially further to the optimizing JIT tier, but that’s future work).</p>
<p>To support tiering-up, we have two problems to solve. First, how hot functions could be identified. Second, how future calls to the tiered-up function could get redirected to the JIT’ed version.</p>
<p>Let’s look at the second problem first. While seemingly trivial (just change the entry point stored in the function prototype), it is actually not that trivial due to the existence of call IC. When a function gets tiered-up, every call IC that caches on the function must be updated and redirected to the new entry point. To achieve this, all the call IC are chained into a circular doubly-linked list on the function prototype that it caches on. In addition, Deegen generates information on how one can update the JIT’ed code of a call IC to change the function entry point it branches to. Then, whenever a function is tiered up, one can iterate through all the call ICs caching on the function using the doubly-linked list, and update each of them to point to the new entry.</p>
<p>For the first problem, the idea is to increment a per-function counter whenever the interpreter reaches a loop bytecode or a function return bytecode. When the counter reaches a threshold, we trigger JIT compilation and redirect control to the JIT’ed code. Unfortunately, the engineering of this part has not been finished. I have to publish this post now, because this post is used as the reading material for a talk a couple of days later :(</p>
<p>This also means that currently we cannot tier-up from interpreter to baseline JIT, so for the benchmarks, everything is directly compiled by the baseline JIT and executed in baseline JIT tier.</p>
<h3 id="Performance-Evaluation">Performance Evaluation</h3>
<p>In this section, we will analyze the performance of <a href="https://github.com/luajit-remake/luajit-remake" target="_blank" rel="noopener">LuaJIT Remake</a> (LJR)'s baseline JIT on 44 synthetic benchmarks from <a href="https://github.com/smarr/are-we-fast-yet" target="_blank" rel="noopener">Are-we-fast-yet</a>, <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/" target="_blank" rel="noopener">CLBG</a>, <a href="https://github.com/LuaJIT/LuaJIT-test-cleanup/tree/master/bench" target="_blank" rel="noopener">LuaJIT Benchmarks</a> and <a href="https://github.com/gligneul/Lua-Benchmarks" target="_blank" rel="noopener">Lua Benchmarks</a>.</p>
<p>Disclaimer: synthetic benchmarks are well-known to be misleading and unable to reflect real workloads (see [<a href="https://blog.mozilla.org/nnethercote/2014/06/16/a-browser-benchmarking-manifesto/" target="_blank" rel="noopener">1</a>,<a href="https://v8.dev/blog/retiring-octane" target="_blank" rel="noopener">2</a>,<a href="https://www.microsoft.com/en-us/research/publication/jsmeter-characterizing-real-world-behavior-of-javascript-programs/" target="_blank" rel="noopener">3</a>,<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/why-measure-toy-benchmark-programs.html" target="_blank" rel="noopener">4</a>]). The sole purpose of this section is to put our results within the context of the existing works, to give a <em>rough sense</em> on the performance of our baseline JIT.</p>
<h4 id="Compilation-Throughput">Compilation Throughput</h4>
<p>The top priority of a baseline JIT is to generate machine code as fast as possible. Therefore, our first evaluation is the compilation throughput.</p>
<p>We measured the compilation throughput of our baseline JIT by timing the main compilation function, which performs the end-to-end work of compiling a input Lua bytecode stream to machine code. We also recorded the total number of Lua bytecodes processed by the baseline JIT, and the total size of the generated machine code.</p>
<p>The average result over all 44 benchmarks is as follows:</p>
<ul>
<li>In terms of Lua bytecodes processed per second, LJR’s baseline JIT can compile 19.1 million Lua bytecodes per second.</li>
<li>In terms of machine code generated per second, LJR’s baseline JIT can generate 1.62GB of machine code per second.</li>
</ul>
<p>To demonstrate what 19.1 million Lua bytecodes means, the 44 Lua benchmark programs (254KB total) contains 17197 Lua bytecodes in total. So our baseline JIT generated machine code for all 44 benchmarks in less than one millisecond total.</p>
<p>As such, we claim that the compilation throughput of our baseline JIT is extremely fast, to the point that the start delay can be considered negligible<sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup>.</p>
<h4 id="Generated-Code-Performance">Generated Code Performance</h4>
<p>While the baseline JIT is designed to generate code fast, generating fast code is still a second priority.</p>
<p>In this section, we will evaluate the execution performance of the machine code generated by LJR’s baseline JIT by comparing with LuaJIT and PUC Lua.</p>
<p>LJR and LuaJIT have drastically different high-level architecture, mid-level design and low-level implementation choices. For the most obvious part, a baseline JIT performs few optimizations <em>by design</em>, while the tracing JIT in LuaJIT does a lot of optimizations. Therefore, the sole purpose of the benchmark is to put the end performance of LJR’s baseline JIT within the context of the existing works, as shown in the figure below:</p>
<p><img src="/images/2023-05-12/perf-numbers.png" alt="Performance comparison of LJR's baseline JIT, LuaJIT's tracing JIT and PUC Lua"></p>
<p>As one can see, LuaJIT’s optimizing tracing JIT generally works better than our baseline JIT, which is no surprise.</p>
<p>However, it’s worth noting that with IC as the only high-level optimization, we are already outperforming LuaJIT on 13 of the 44 benchmarks. On geometric average, we are about 34% slower than LuaJIT, and 4.6x faster than PUC Lua.</p>
<p>In my opinion, it is fair to say that Deegen is now on a very stable ground. With its excellent interpreter and baseline JIT that can already achieve pretty good execution performance at a negligble startup delay, the optimizing JIT (to come in the future) would have much less pressure in doing expensive optimizations.</p>
<h3 id="Conclusion-Thoughts-and-Future-Works">Conclusion Thoughts and Future Works</h3>
<p>This post demonstrated the second phase of the Deegen project – to build a high-performance baseline JIT compiler automatically from the bytecode semantic.</p>
<p>Of course, this is far from the end. Our next step is to automatically generate an optimizing compiler, which will likely follow the design of JavaScriptCore’s DFG lightweight JIT compiler. If you have any comments, suggestions or thoughts, please do not hesitate to <a href="https://sillycross.github.io/about/">shoot me an email</a> :)</p>
<h4 id="Acknowledgements">Acknowledgements</h4>
<p>I thank <a href="https://fredrikbk.com/" target="_blank" rel="noopener">Fredrik Kjolstad</a> and <a href="https://saambarati.org/" target="_blank" rel="noopener">Saam Barati</a> for their comments and discussions on the draft version of this post. Fredrik also did the image editing work for the <code>Add</code> bytecode figure.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Since a JIT compiler works at runtime, the overall latency experienced by the user is the sum of the compilation time to generate the code (startup delay) and the execution time of the generated code. So for maximum throughput, one wants a multi-tier architecture. The <em>baseline JIT</em> is a JIT compiler that specializes at fast compilation, and is used to compile not-so-hot code. For a small set of hot functions identified by the baseline JIT, the <em>optimizing JIT</em> kicks in to generate better code at a much higher compilation cost. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>And even worse, due to the nature of assembly, there is little code sharing across the VM tiers or across hardware architectures, despite that all the VM tiers must stay in sync and exhibit identical behavior, or you get a VM bug. <!--This is another reason one might want to use `Deegen`: by automatically generating all the VM tiers from a single source of truth, `Deegen` removed all the code duplications, and all the generated VM tiers are automatically in sync.--> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>There are other reasons from the usability and engineering side as well. For example, by removing the “compile” step in the edit-compile-run cycle, dynamic languages have faster iterative development cycle. And libraries written in dynamic languages can be distributed as source code. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Directly translating a dynamic language program to native code will result in a huge amount of native code. This is mainly due to the dynamic typed nature: every innocent operation in dynamic language is actually a huge switch depending on the input types, and can have drastically complex slow paths. The statically-generated logic must deal with all such cases for correctness, even though most of the slow paths are never hit at runtime. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Recall that in most dynamic languages, functions are first-class value. So the function held by <code>f</code> can always be changed (and in fact, <code>f</code> is not even necessarily a function object), even though in the majority of use cases, the function is used like a C function so <code>f</code> always just hold the same value. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>This is the simplest strategy, but one can clearly do some fancier stuffs here. For example, JavaScriptCore will generate a binary search tree to reduce the number of jump instructions executed, so that they can support a higher number of IC entries. However, based on words from JSC developer, this optimization has very limited effect in practice. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>OSR stands for On-Stack Replacement. OSR-Exit is also more widely known as <a href="https://dl.acm.org/doi/10.1145/143103.143114" target="_blank" rel="noopener"><em>deoptimization</em></a>, a technique originally used to enhance the debuggability of optimized code. However, we will stick to the term “OSR-Exit” as it better reflects the nature of this technique in the VM use case: exiting to a lower tier using an exotic method (on-stack replacement). <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>Being an acute reader like you, I’m sure you can already imagine a primitive JIT that works by wiring up different functions that implement basic functionalities like constant, addition, pointer dereference, etc. <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>While seemingly scary to mess up with assembly code directly, one can easily prove the correctness from the semantics of <code>jmp</code>. <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>Acute readers might have noticed that this statement is not 100% true. We will revisit it later. <a href="#fnref10" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>Note that here, by saying register allocation and instruction selection, we meant those that work <em>across stencils</em>. Inside a stencil, since the code is compiled by LLVM, we already have good RA and ISel. <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>The decision to give up non-local RA/ISel is justified by designs of existing state-of-the-art VMs. For example, in JavaScriptCore, only the fourth-tier heavyweight optimizing JIT (FTL) employs codegen-level optimizations (RA, ISel, etc.) that works across bytecode or DFG IR nodes. <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>Unfortunately, I never realized the larger picture until after the Copy-and-Patch paper was already published, so this wrong belief is also published with the paper… <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p>Under small code model, and not considering complications like position-independent code (PIC) and position-independent executable (PIE). <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p>This is in fact an exaggregated statement. Hidden class <em>without</em> inline caching is much slower than a naive implementation (i.e., no hidden class at all). Therefore, if one were to actually seriously implement a baseline JIT without inline caching, he/she wouldn’t employ hidden class either. So IC is only responsible for a portion of the “&gt;100% speedup on IC-intensive benchmarks”: the rest are the slowdown from the overhead of hidden class that could be avoided. <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p>One jump is clearly saved by not branching to the outlined JIT stub. If the IC happens to fallthrough to the logic directly after the SMC region (which is quite common), an additional jump can be saved. <a href="#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p>Note that the JIT code for a bytecode may consist of multiple stencils, for example, a <code>Call</code> needs both the main logic and the return continuation. Clearly, the jump-to-fallthrough transform is only valid for the last instruction of the last stencil for the bytecode. <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>However, note that the memory overhead is not negligble at all: each Lua bytecode (which is usually a few bytes) expands to an average of 91 bytes of machine code in baseline JIT. This is why even with a baseline JIT, we still want programs to start executing in the interpreter. <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2023/05/12/2023-05-12/" data-id="clhkntog3000jdsp0gfzt5sil" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-11-22" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/11/22/2022-11-22/">Building the fastest Lua interpreter.. automatically!</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/11/22/2022-11-22/" class="article-date"><time datetime="2022-11-22T00:00:00.000Z" itemprop="datePublished">2022-11-22</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p><text style="font-size:15px;">This is Part 1 of a series of posts.<br> Part 2 is available here: <a href="/2023/05/12/2023-05-12/">Building a baseline JIT for Lua automatically</a></text></p>
</blockquote>
<p>It is well-known that writing a good VM for a dynamic language is never an easy job. High-performance interpreters, such as the <a href="https://webkit.org/blog/10308/speculation-in-javascriptcore/" target="_blank" rel="noopener">JavaScript interpreter in Safari</a>, or <a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html" target="_blank" rel="noopener">the Lua interpreter in LuaJIT</a>, are often hand-coded in assembly. If you want a JIT compiler for better performance, well, you’ve got some more assembly to write. And if you want the best possible performance with multiple-tier JIT compilation… Well, that’s assembly all the way down.</p>
<p>I have been working on a research project to make writing VMs easier. The idea arises from the following observation: writing a naive interpreter is not hard (just write a big switch-case), but writing a good interpreter (or JIT compiler) is hard, as it unavoidably involves hand-coding assembly. So why can’t we implement a special compiler to automatically <em>generate</em> a high-performance interpreter (and even the JIT) from “the big switch-case”, or more formally, a semantical description of what each bytecode does?</p>
<h3 id="The-LuaJIT-Remake-Project">The LuaJIT Remake Project</h3>
<p>I chose <a href="https://www.lua.org/" target="_blank" rel="noopener">Lua</a> as the experiment target for my idea, mainly because Lua is concise yet supports almost every language feature one can find in dynamic languages, including exotic ones like stackful coroutines. I named my project <a href="https://github.com/luajit-remake/luajit-remake" target="_blank" rel="noopener">LuaJIT Remake</a> (LJR) because in the long term, it will be a multi-tier method-based JIT compiler for Lua.</p>
<p>After months of work on the project, I’ve finally got some early results to share. LJR now has a feature-complete Lua 5.1 interpreter that is automatically generated at build time using a meta-compiler called <code>Deegen</code> (for “Dynamic language Execution Engine Generator”). More importantly, it is the world’s fastest Lua interpreter to date, outperforming LuaJIT’s interpreter by 28% and the official Lua interpreter by 171% on average on a variety of benchmarks<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p>
<p>The figure below illustrates the performance of our interpreter, the LuaJIT interpreter, and the official PUC Lua interpreter. PUC Lua’s performance is normalized to 1 as a baseline.</p>
<p><img src="/images/2022-11-22/interpreter-perf-comparison-2.png" alt=""></p>
<p>As the figure shows, our interpreter performs better than LuaJIT’s hand-coded-in-assembly interpreter on 31 out of the 34 benchmarks<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>, and on geometric average, we run 28% faster than LuaJIT interpreter, and almost 3x the speed of official PUC Lua.</p>
<p>Enough of the numbers, now I will dive a bit into how my approach works.</p>
<h3 id="Why-Assembly-After-All">Why Assembly After All?</h3>
<p>To explain how I built the fastest Lua interpreter, one needs to understand why (previously) the best interpreters have been hand-coded in assembly. This section is all about background. If you are already familiar with interpreters, feel free to skip to the next section.</p>
<p>Mike Pall, the author of LuaJIT, has explained this matter clearly in <a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html" target="_blank" rel="noopener">this great email thread</a> back in 2011. The problem with the “big switch-case” approach is that C/C++ compilers simply cannot handle such code well. Although eleven years have passed, the situtation didn’t change much. Based on my experience, even if a function only has one fast path and one cold path, and the cold path has been nicely annotated with <code>unlikely</code>, LLVM backend will still pour a bunch of unnecessary register moves and stack spills into the fast path<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>. And for the “big switch-case” interpreter loop with hundreds of fast-paths and cold-paths, it’s unsurprising that compilers fail to work well.</p>
<p><a href="https://en.wikipedia.org/wiki/Tail_call" target="_blank" rel="noopener">Tail call</a>, also known as <a href="https://dl.acm.org/doi/10.1145/800179.810196" target="_blank" rel="noopener">continuation-passing style</a>, is an alternative to switch-case-based interpreter loop. Basically each bytecode gets its own function that does the job, and when the job is done, control is transferred to the next function via a tail call dispatch (i.e., a jump instruction at machine code level). So despite that conceptually, the bytecode functions are calling each other, they are really jumping to each other at machine code level, and there will be no unbounded stack growth. An alternate way to look at it is that each “case” clause in the switch-case interpreter loop becomes a function. The “switch” will jump (i.e., tail call) to the corresponding “case” clause, and at the end of the case a jump (i.e., tail call) is executed to jump back to the switch dispatcher<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>.</p>
<p>With the tail-call approach, each bytecode now gets its own function, and the pathological case for the C/C++ compiler is gone. And as shown by <a href="https://blog.reverberate.org/2021/04/21/musttail-efficient-interpreters.html" target="_blank" rel="noopener">the experience</a> of the Google protobuf developers, the tail-call approach can indeed be used to build very good interpreters. But can it push to the limit of hand-written assembly interpreters? Unfortunately, the answer is still no, at least at its current state.</p>
<p>The main blockade to the tail-call approach is the callee-saved registers. Since each bytecode function is still a function, it is required to abide to the calling convention, specifically, every callee-saved register must retain its old value at function exit. So if a bytecode function needs to use a callee-saved register, it needs to save the old value on the stack and restore it at the end<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>. The only way to solve this problem is to use a calling convention with no callee-saved registers. Unfortunately, Clang is (to-date) the only compiler that offers guaranteed-tail-call intrinsic (<code>[[clang::musttail]]</code> annotation), but it has no such user-exposed calling convention with no callee-saved registers. So you lose 6 (or 8, depending on cconv) of the 15 registers for no reason on x86-64, which is clearly bad.</p>
<p>Another blockade to the tail-call approach is, again, the calling convention. No unbounded stack growth is a requirement, but tricky problems can arise when the caller and callee function prototype does not match, and some parameters are being passed in the stack. So Clang makes the compromise and requires the caller and callee to have <em>identical</em> function prototypes if <code>musttail</code> is used. This is extremely annoying in practice once you have tried to write anything serious under such limitation (for POC purpose I had hand-written a naive Lua interpreter using <code>musttail</code>, so I have first-hand experience on how annoying it is).</p>
<h3 id="Generating-the-Interpreter-Another-Level-Of-Indirection-Solves-Everything">Generating the Interpreter: Another Level Of Indirection Solves Everything</h3>
<p>As you might have seen, the root of all the difficulties is that our tool (C/C++) is not ideal for the problem we want to solve. So what’s the solution?</p>
<p>Of course, throwing the tool away and resort to sheer force (hand-coding assembly) is one solution, but doing so also results in high engineering cost. Can we do it more swiftly?</p>
<p>It is <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering" target="_blank" rel="noopener">well-known</a> that all problems in computer science can be solved by another level of indirection. In our case, C/C++ is a very good tool to describe the semantics of each bytecode (i.e., what each bytecode should do), but C/C++ is not a good tool to write the most efficient interpreter. So what if we add one level of indirection: we write the bytecode semantical description in C++, <em>compile it to LLVM IR</em>, and feed the IR into a special-purpose compiler. The special-purpose compiler will take care of all the dirty work, doing proper transformation to the IR and finally generate a nice tail-call-based interpreter.</p>
<p>For example, at LLVM IR level, it is trivial to make a function use <code>GHC</code> calling convention (a convention with no callee-saved registers) and properly transform the function to unify all the function prototype, thus solving the two major problems with <code>musttail</code> tail calls that is unsolvable at C/C++ level. In fact, <code>Deegen</code> (our meta-compiler that generates the interpreter) does a <em>lot</em> more than producing the tail calls, which we will cover in the rest of this post.</p>
<h3 id="Hide-All-the-Ugliness-Behind-Nice-APIs">Hide All the Ugliness Behind Nice APIs</h3>
<p>In Deegen framework, the semantics of each bytecode is described by a C++ function. One of the most important design philosophy of Deegen is to abstract away all the nasty parts of an interpreter. I will demonstrate with a simplified example for the <code>Add</code> bytecode:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Add</span><span class="params">(TValue lhs, TValue rhs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!lhs.Is&lt;tDouble&gt;() || !rhs.Is&lt;tDouble&gt;()) &#123;</span><br><span class="line">    ThrowError(<span class="string">"Can't add!"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">double</span> res = lhs.As&lt;tDouble&gt;() + rhs.As&lt;tDouble&gt;();</span><br><span class="line">    Return(TValue::Create&lt;tDouble&gt;(res));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The function <code>Add</code> takes two boxed values (a value along with its type) <code>lhs</code> and <code>rhs</code> as input. It first checks if both <code>lhs</code> and <code>rhs</code> are <code>double</code> (the <code>Is&lt;tDouble&gt;()</code> check). If not, we throw out an error. Otherwise, we add them together by casting the two boxed value to its actual type (<code>double</code>) and do a normal <code>double</code> addition. Finally, we create a new boxed value of <code>double</code> type using <code>TValue::Create&lt;tDouble&gt;()</code>, return it as the result of the bytecode and dispatch to the next bytecode, through the <code>Return()</code> API call (note that this is not the C keyword <code>return</code>).</p>
<p>Notice how much nasty work we have abstracted away: decoding the bytecode, loading the operands and constants, throwing out errors, storing results to the stack frame, and dispatching to the next bytecode. All of these interpreter details either happen automatically, or happen with a simple API call (e.g., <code>ThrowError</code> or <code>Return</code>).</p>
<p>Now let’s extend our <code>Add</code> to add support for the Lua <code>__add</code> metamethod semantics:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">AddContinuation</span><span class="params">(TValue <span class="comment">/*lhs*/</span>, TValue <span class="comment">/*rhs*/</span>)</span> </span>&#123;</span><br><span class="line">  Return(GetReturnValueAtOrd(<span class="number">0</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Add</span><span class="params">(TValue lhs, TValue rhs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!lhs.Is&lt;tDouble&gt;() || !rhs.Is&lt;tDouble&gt;()) &#123;</span><br><span class="line">    <span class="comment">/* we want to call metamethod now */</span></span><br><span class="line">    HeapPtr&lt;FunctionObject&gt; mm = GetMMForAdd(lhs, rhs);</span><br><span class="line">    MakeCall(mm, lhs, rhs, AddContinuation);</span><br><span class="line">    <span class="comment">/* MakeCall never returns */</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">double</span> res = lhs.As&lt;tDouble&gt;() + rhs.As&lt;tDouble&gt;();</span><br><span class="line">    Return(TValue::Create&lt;tDouble&gt;(res));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The <code>GetMMForAdd</code> is some arbitrary runtime function call that gets the metamethod. Deegen does not care about its implementation: the bytecode semantic description is just a normal C++ function, so it can do anything allowed by C++, of course including calling other C++ functions. The interesting part is the <code>MakeCall</code> API. It allows you to call other Lua functions with the specified parameters, and most importantly, a <em>return continuation</em>. The <code>MakeCall</code> API does not return. Instead, when the called function returns, control will be returned to the return continuation (the <code>AddContinuation</code> function). The return continuation function is similar to the bytecode function: it has access to all the bytecode operands, and additionally, it has access to all the values returned from the call. In our case, the semantics for Lua <code>__add</code> is to simply return the first value returned by the call as the result of the bytecode, so we use <code>GetReturnValueAtOrd(0)</code> to get that value, and use the <code>Return</code> API we have covered earlier to complete the <code>Add</code> bytecode and dispatch to the next bytecode.</p>
<p>Again, notice how much nasty work that we have abstracted away: all the details of creating the new Lua frame, adjusting the parameters and return values (overflowing arguments needs to go to variadic arg if callee accepts it, insufficient arguments need to get <code>nil</code>), transferring control to the callee functions, etc., are all hidden by a mere <code>MakeCall</code> API. Furthermore, all of these are language-neutral: if we were to target some other languages (e.g., Python), most of the Deegen code that implements the <code>MakeCall</code> could be reused.</p>
<p>The use of return continuation is designed to support Lua coroutines. Since Lua coroutines are stackful, and <code>yield</code> can happen anywhere (as <code>yield</code> is not a Lua keyword, but a library function), we need to make sure that the C stack is empty at any bytecode boundary, so we can simply tail call to the other continuation to accomplish a coroutine switch. This design also has a few advantages compared with PUC Lua’s coroutine implementation:</p>
<ol>
<li>We have no fragile <code>longjmp</code>s.</li>
<li>We can easily make any library function that calls into VM yieldable using this mechanism. In fact, the error message <code>cannot yield across C call frames</code> is gone completely in LJR: all Lua standard library functions, including exotic ones like <code>table.sort</code>, are redesigned to be yieldable using this mechanism.</li>
</ol>
<h3 id="Automation-Automation-and-More-Automation">Automation, Automation, and More Automation!</h3>
<p>The bytecode semantic function specifies the execution semantics of the bytecode, but one still needs to specify the definition of the bytecode. For example, one needs to know that <code>AddVN</code> takes two operands where LHS is a bytecode slot and RHS is a number value in the constant table, and that <code>AddVN</code> returns one value, and that it always fallthroughs to the next bytecode and cannot branch to anywhere else. In Deegen, this is achieved by a <em>bytecode specification language</em>.</p>
<p>Again, let’s use the <code>Add</code> as the example:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">DEEGEN_DEFINE_BYTECODE(Add) &#123;</span><br><span class="line">  Operands(</span><br><span class="line">    BytecodeSlotOrConstant(<span class="string">"lhs"</span>),</span><br><span class="line">    BytecodeSlotOrConstant(<span class="string">"rhs"</span>)</span><br><span class="line">  );</span><br><span class="line">  Result(BytecodeValue);</span><br><span class="line">  Implementation(Add);</span><br><span class="line">  Variant(</span><br><span class="line">    Op(<span class="string">"lhs"</span>).IsBytecodeSlot(),</span><br><span class="line">    Op(<span class="string">"rhs"</span>).IsBytecodeSlot()</span><br><span class="line">  );</span><br><span class="line">  Variant(</span><br><span class="line">    Op(<span class="string">"lhs"</span>).IsConstant&lt;tDoubleNotNaN&gt;(),</span><br><span class="line">    Op(<span class="string">"rhs"</span>).IsBytecodeSlot()</span><br><span class="line">  );</span><br><span class="line">  Variant(</span><br><span class="line">    Op(<span class="string">"lhs"</span>).IsBytecodeSlot(),</span><br><span class="line">    Op(<span class="string">"rhs"</span>).IsConstant&lt;tDoubleNotNaN&gt;()</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>There are a few things going on here so we will go through them one by one. First of all, the <code>DEEGEN_DEFINE_BYTECODE</code> is a macro that tells us that you are defining a bytecode.</p>
<p>The <code>Operands(...)</code> API call tells us that the bytecode has two operands, with each can be either a bytecode slot (a slot in the call frame) or a constant in the constant table. Besides <code>BytecodeSlotOrConstant</code>, one can also use <code>Literal</code> to define literal operands, and <code>BytecodeRange</code> to define a range of bytecode values in the call frame.</p>
<p>The <code>Result(BytecodeValue)</code> API call tells us that the bytecode returns one value and does not branch. The enum key <code>BytecodeValue</code> means the bytecode returns one <code>TValue</code>. One can also use enum key <code>CondBr</code> to specify that the bytecode can branch, or just no argument to specify that the bytecode doesn’t return anything.</p>
<p>The <code>Implementation(...)</code> API specifies the execution semantics of the bytecode, which is the <code>Add</code> function we just covered.</p>
<p>The interesting part is the <code>Variant</code> API calls. It allows one to create different variants of the bytecode. For example, in Lua, we have the <code>AddVV</code> bytecode to add two bytecode values, or the <code>AddVN</code> bytecode to add a bytecode value with a constant <code>double</code>, or the <code>ADDNV</code> bytecode to add a constant <code>double</code> with a bytecode value. In a traditional interpreter implementation, the implementation of all of these bytecodes must be written by hand, which is not only laborious, but also error prone. However, in Deegen’s framework, all you need to do is to specify them as <code>Variant</code>s, and we will do all the work for you!</p>
<p>The <code>IsConstant</code> API allows optionally further specifying the type of the constant, as shown in the <code>IsConstant&lt;tDoubleNotNaN&gt;()</code> usage in the snippet. Deegen implemented special LLVM optimization pass to simplify the execution semantics function based on the known and speculated type information of the operands. For example, for the bytecode variant where <code>rhs</code> is marked as <code>IsConstant&lt;tDoubleNotNaN&gt;()</code>, Deegen will realize that the <code>rhs.Is&lt;tDouble&gt;()</code> check in the bytecode function must be <code>true</code>, and optimize it out. This allows us to automatically generate efficient specialized bytecode implementation, without adding engineering cost to the user. (And by the way, the <code>tDouble</code> and <code>tDoubleNotNaN</code> things, or more formally, the type lattice of the language, is also user-defined. Deegen is designed to be a generic meta-compiler: it is not welded to Lua).</p>
<p>Finally, Deegen will generate a user-friendly <code>CreateAdd</code> function for the user frontend parser to emit a <code>Add</code> bytecode. For example, the frontend parser can write the following code to generate an <code>Add</code> bytecode that adds bytecode slot <code>1</code> with constant <code>123.4</code>, and stores the output into slot <code>2</code>:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bytecodeBuilder.CreateAdd(&#123;</span><br><span class="line">  .lhs = Local(<span class="number">1</span>),</span><br><span class="line">  .rhs = Cst&lt;tDouble&gt;(<span class="number">123.4</span>),</span><br><span class="line">  .output = Local(<span class="number">2</span>)</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>The implementation of <code>CreateAdd</code> will automatically insert constants into the constant table, select the most suitable variant based in the input types (or throwing out an error if no satisfying variant can be found), and append the bytecode into the bytecode stream. The concrete layout of the bytecode in the bytecode stream is fully hidden from the user. This provides a maximally user-friendly and robust API for the user parser logic to build the bytecode stream.</p>
<p><a href="https://github.com/luajit-remake/luajit-remake/blob/f8fb972ec91c28b849bd263f164832f0ff434d1f/annotated/bytecodes/arithmetic_bytecodes.cpp" target="_blank" rel="noopener">This link</a> is the real implementation of all the Lua arithemtic bytecodes in LuaJIT Remake. It used a few features that we haven’t covered yet: the <code>DEEGEN_DEFINE_BYTECODE_TEMPLATE</code> macro allows defining a template of bytecodes, so <code>Add</code>, <code>Sub</code>, <code>Mul</code>, etc., can all be defined at once, minimizing engineering cost. The <code>EnableHotColdSplitting</code> API allows automatically hot-cold-splitting based on speculated and proven input operand types, and splits out the cold path into a dedicated function, which improves the final code quality (recall the earlier discussion on the importance of hot-cold code splitting?).</p>
<p>And below is the actual disassembly of the interpreter generated by Deegen for Lua’s <code>AddVV</code> bytecode. Comments are manually added by me for exposition purposes:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">__deegen_interpreter_op_Add_0:</span><br><span class="line">    <span class="comment"># decode 'lhs' from bytecode stream</span></span><br><span class="line">    movzwl      2(%r12), %eax</span><br><span class="line">    <span class="comment"># decode 'rhs' from bytecode stream</span></span><br><span class="line">    movzwl      4(%r12), %ecx</span><br><span class="line">    <span class="comment"># load the bytecode value at slot 'lhs'</span></span><br><span class="line">    movsd       (%rbp,%rax,8), %xmm1</span><br><span class="line">    <span class="comment"># load the bytecode value at slot 'rhs'</span></span><br><span class="line">    movsd       (%rbp,%rcx,8), %xmm2</span><br><span class="line">    <span class="comment"># check if either value is NaN</span></span><br><span class="line">    <span class="comment"># Note that due to our boxing scheme, </span></span><br><span class="line">    <span class="comment"># non-double value will exhibit as NaN when viewed as double</span></span><br><span class="line">    <span class="comment"># so this checks if input has double NaN or non-double value</span></span><br><span class="line">    ucomisd     %xmm2, %xmm1</span><br><span class="line">    <span class="comment"># branch if input has double NaN or non-double values</span></span><br><span class="line">    jp          .LBB0_1</span><br><span class="line">    <span class="comment"># decode the destination slot from bytecode stream</span></span><br><span class="line">    movzwl      6(%r12), %eax</span><br><span class="line">    <span class="comment"># execute the add</span></span><br><span class="line">    addsd       %xmm2, %xmm1</span><br><span class="line">    <span class="comment"># store result to destination slot</span></span><br><span class="line">    movsd       %xmm1, (%rbp,%rax,8)</span><br><span class="line">    <span class="comment"># decode next bytecode opcode</span></span><br><span class="line">    movzwl      8(%r12), %eax</span><br><span class="line">    <span class="comment"># advance bytecode pointer to next bytecode</span></span><br><span class="line">    addq        <span class="variable">$8</span>, %r12</span><br><span class="line">    <span class="comment"># load the interpreter function for next bytecode</span></span><br><span class="line">    movq        __deegen_interpreter_dispatch_table(,%rax,8), %rax</span><br><span class="line">    <span class="comment"># dispatch to next bytecode</span></span><br><span class="line">    jmpq        *%rax</span><br><span class="line">.LBB0_1:</span><br><span class="line">    <span class="comment"># branch to automatically generated slowpath (omitted)</span></span><br><span class="line">    jmp         __deegen_interpreter_op_Add_0_quickening_slowpath</span><br></pre></td></tr></table></figure>
<p>As one can see, thanks to all of our optimizations, the quality of the assembly generated by Deegen has no problem rivalling hand-written assembly.</p>
<h3 id="Inline-Caching-API-The-Tricks-of-the-Trade-a-name-deegen-generic-inline-caching-api-a">Inline Caching API: The Tricks of the Trade<a name="deegen_generic_inline_caching_api"></a></h3>
<p>A lot of LJR’s speedup over LuaJIT interpreter comes from our support of inline caching. We have rewritten the Lua runtime from scratch. In LJR, table objects are not stored as a plain hash table with an array part. Instead, our table implementation employed hidden classes, using a design mostly mirroring the hidden class design <a href="https://webkit.org/blog/10308/speculation-in-javascriptcore/" target="_blank" rel="noopener">in JavaScriptCore</a>.</p>
<p>Hidden class allows efficient <em>inline caching</em>, a technique that drastically speeds up table operations. Briefly speaking, one can think of a hidden class as a hash-consed metadata object that describes the layout of a table object, or (simplified for the purpose of exposition), a hash map from string key to the storage slot in the table storing the value of this string key.</p>
<p>Let’s use the <code>TableGetById</code> bytecode (aka, <code>TGETS</code> in LuaJIT) as example. <code>TableGetById</code> takes a table <code>T</code> and a fixed constant string <code>k</code> as input, and outputs <code>T[k]</code>.</p>
<p>Due to the natural use case of dynamic languages, for a fixed <code>TableGetById</code> bytecode, the tables it operates on are likely to have the same hidden class, or only a few different kinds of hidden classes. So <code>TableGetById</code> will cache the most recent hidden class <code>H</code> it saw, as well as <code>H[k]</code>, the storage slot in the table for the constant string key <code>k</code>. When <code>TableGetById</code> is executed on input <code>T</code>, it first check if the hidden class of <code>T</code> is just its cached hidden class <code>H</code>. If so (which is likely), it knows that the result must be stored in slot <code>H[k]</code> of <code>T</code>, so the expensive hash-lookup work (which queries hidden class <code>H</code> to obtain <code>H[k]</code>) can be elided.</p>
<p>In general, one can characterize the inline caching optimization as the following: there are some generic computation <code>λ : input -&gt; output</code> that can be split into two steps:</p>
<ol>
<li>An expensive but idempotent step <code>λ_i : icKey -&gt; ic</code> where <code>icKey</code> is a subset of the <code>input</code> data, and <code>ic</code> is an opaque result.</li>
<li>A cheap but effectful step <code>λ_e : &lt;input, ic&gt; -&gt; output</code>, that takes the <code>input</code> and the idempotent result <code>ic</code> for <code>input</code> in step 1, and outputs the final output.</li>
</ol>
<p><img src="/images/2022-11-22/ic.png" alt="Computation eligible for inline caching can be characterized as above."></p>
<p>If the computation satisfies such constraint, then one can cache <code>icKey</code> and the corresponding <code>ic</code>. Then on new inputs, if the <code>icKey</code> matches, the expensive idempotent step of computing <code>ic</code> can be safely elided.</p>
<p>Deegen provided <em>generic inline caching APIs</em> to allow easy employment of inline caching optimization. Specifically:</p>
<ol>
<li>The full computation <code>λ</code> is specified as a C++ lambda (called the <code>body</code> lambda).</li>
<li>The effectful step <code>λ_e</code> is specified as C++ lambdas defined inside the <code>body</code> lambda (called the <code>effect</code> lambdas).</li>
</ol>
<p>We allow specifying multiple possible <code>effect</code> lambdas in the <code>body</code> lambda, since the <code>λ_e</code> to execute can often be dependent on the outcome of the idempotent step. However, we require that at most one <code>effect</code> lambda can be executed in each run of the <code>body</code> lambda.</p>
<p>For example, for <code>TableGetById</code>, the code that employs inline caching would look like the following (simplified for the purpose of exposition):</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TableGetById</span><span class="params">(TValue tab, TValue key)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Let's assume 'tab' is indeed a table for simplicity.</span></span><br><span class="line">  HeapPtr&lt;TableObject&gt; t = tab.As&lt;tTable&gt;();</span><br><span class="line">  <span class="comment">// And we know 'key' must be string since the index of</span></span><br><span class="line">  <span class="comment">// TableGetById is required to be a constant string</span></span><br><span class="line">  HeapPtr&lt;String&gt; k = key.As&lt;tString&gt;();</span><br><span class="line">  <span class="comment">// Call API to create an inline cache</span></span><br><span class="line">  ICHandler* ic = MakeInlineCache();</span><br><span class="line">  HiddenClassPtr hc = t.m_hiddenClass;</span><br><span class="line">  <span class="comment">// Make the IC cache on key 'hc'</span></span><br><span class="line">  ic-&gt;Key(hc);</span><br><span class="line">  <span class="comment">// Specify the IC body (the function 'λ')</span></span><br><span class="line">  Return(ic-&gt;Body([=] &#123;</span><br><span class="line">    <span class="comment">// Query hidden class to get value slot in the table</span></span><br><span class="line">    <span class="comment">// This step is idempotent due to the design of hidden class </span></span><br><span class="line">    <span class="keyword">int32_t</span> slot = hc-&gt;Query(k);</span><br><span class="line">    <span class="comment">// Specify the effectful step (the function 'λ_e')</span></span><br><span class="line">    <span class="keyword">if</span> (slot == <span class="number">-1</span>) &#123;     <span class="comment">// not found</span></span><br><span class="line">      <span class="keyword">return</span> ic-&gt;Effect([] &#123; <span class="keyword">return</span> NilValue(); &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> ic-&gt;Effect([=] &#123; <span class="keyword">return</span> t-&gt;storage[slot]; &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The precise semantic of the inline caching APIs is the following:</p>
<ol>
<li>When <code>ic-&gt;Body()</code> executes for the first time, it will honestly execute the <code>body</code> lambda. However, during the execution, when a <code>ic-&gt;Effect</code> API call is executed, it will create an inline cache<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> for this bytecode that records the IC key (defined by the <code>ic-&gt;Key()</code> API), as well as all captures of this <code>effect</code> lambda that are <em>defined within</em> the <code>body</code> lambda. These variables are treated as constants (the <code>ic</code> state).</li>
<li>Next time the <code>ic-&gt;Body</code> executes, compare the cached key against the actual key.</li>
<li>If the key matches, it will directly execute the previously recorded <code>effect</code> lambda. For each capture of the <code>effect</code> lambda, if the capture is defined inside the <code>body</code> lambda, it will see the cached value recorded in step 1. Otherwise (i.e., the capture is defined as a capture of the <code>body</code> lambda), it will see the fresh value.</li>
<li>If the key does not match, just execute step 1.</li>
</ol>
<p>The precise semantic might look a bit bewildering at first glance. A more intuitive way to understand is that one is only allowed to do idempotent computation inside the <code>body</code> lambda (idempotent is with respect to the cached key and other values known to be constants to this bytecode). All the non-idempotent computations must go to the <code>effect</code> lambda. As long as this rule is followed, Deegen will automatically generate correct implementation that employs the inline caching optimization.</p>
<p>Deegen also performs exotic optimizations that fuses the ordinal of the <code>effect</code> lambda into the opcode, to save an expensive indirect branch that branches to the correct <code>effect</code> implementation when the inline cache hits. Such optimizations would have required a lot of engineering efforts in a hand-written interpreter. But in Deegen, it is enabled by merely one line: <code>ic-&gt;FuseICIntoInterpreterOpcode()</code>.</p>
<p>Below is the actual disassembly of the interpreter generated by Deegen, for <code>TableGetById</code> bytecode. The assembly is for a “fused-IC” quickened variant (see above) where the table is known to have no metatable, and the property exists in the inline storage of the table. As before, comments are manually added by me for exposition purposes.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">__deegen_interpreter_op_TableGetById_0_fused_ic_1: </span><br><span class="line">    pushq         %rax</span><br><span class="line">    <span class="comment"># decode bytecode slot for the 'table' operand </span></span><br><span class="line">    movzwl        2(%r12), %eax</span><br><span class="line">    <span class="comment"># decode bytecode slot for the 'index' operand</span></span><br><span class="line">    movswq        4(%r12), %rcx</span><br><span class="line">    <span class="comment"># load the bytecode value of 'table'</span></span><br><span class="line">    movq          (%rbp,%rax,8), %r9</span><br><span class="line">    <span class="comment"># load the constant value of 'index' (must be string)</span></span><br><span class="line">    movq          (%rbx,%rcx,8), %rsi</span><br><span class="line">    <span class="comment"># check that 'table' is a heap object value (a pointer)</span></span><br><span class="line">    cmpq          %r15, %r9</span><br><span class="line">    <span class="comment"># if not, branch to slow path (omitted)</span></span><br><span class="line">    jbe           .LBB5_8</span><br><span class="line">    <span class="comment"># decode the destination slot from the bytecode</span></span><br><span class="line">    movzwl        6(%r12), %r10d</span><br><span class="line">    <span class="comment"># load the metadata struct offset for this bytecode</span></span><br><span class="line">    <span class="comment"># the contents of the inline cache is stored there</span></span><br><span class="line">    movl          8(%r12), %edi</span><br><span class="line">    <span class="comment"># compute the pointer to the metadata struct</span></span><br><span class="line">    addq          %rbx, %rdi</span><br><span class="line">    <span class="comment"># load the hidden class of the heap object</span></span><br><span class="line">    movl          %gs:(%r9), %ecx</span><br><span class="line">    <span class="comment"># check if hidden class matches</span></span><br><span class="line">    cmpl          %ecx, (%rdi)</span><br><span class="line">    <span class="comment"># branch to code that calls the IC body if the hidden</span></span><br><span class="line">    <span class="comment"># class does not match (omitted)</span></span><br><span class="line">    jne	          .LBB5_4</span><br><span class="line">    <span class="comment"># The hidden class matched, we know the heap object is</span></span><br><span class="line">    <span class="comment"># a table without metatable, and the value for 'index' </span></span><br><span class="line">    <span class="comment"># is stored in the inline storage of the table, with the</span></span><br><span class="line">    <span class="comment"># slot ordinal recorded in the inline cache</span></span><br><span class="line">    <span class="comment"># Load the slot ordinal from the inline cache</span></span><br><span class="line">    movslq        5(%rdi), %rax</span><br><span class="line">    <span class="comment"># load the value from the inline storage of the table</span></span><br><span class="line">    movq          %gs:16(%r9,%rax,8), %rax</span><br><span class="line">.LBB5_3:</span><br><span class="line">    <span class="comment"># store the value into the destination slot</span></span><br><span class="line">    movq          %rax, (%rbp,%r10,8)</span><br><span class="line">    <span class="comment"># decode next bytecode and dispatch</span></span><br><span class="line">    movzwl        12(%r12), %eax</span><br><span class="line">    addq          <span class="variable">$12</span>, %r12</span><br><span class="line">    movq	__deegen_interpreter_dispatch_table(,%rax,8), %rax</span><br><span class="line">    popq          %rcx</span><br><span class="line">    jmpq          *%rax</span><br></pre></td></tr></table></figure>
<p>As one can see, in the good case of an IC hit, a <code>TableGetById</code> is executed with a mere 2 branches (one that checks the operand is a heap object, and one that checks the hidden class of the heap object matches the inline-cached value).</p>
<p>LuaJIT’s hand-written assembly interpreter is highly optimized already. Our interpreter generated by Deegen is also highly optimized, and in many cases, slightly better-optimized than LuaJIT. However, the gain from those low-level optimizations are simply not enough to beat LuaJIT by a significant margin, especially on a modern CPU with very good instruction-level parallelism, where having a few more instructions, a few longer instructions, or even a few more L1-hitting loads have negligible impact on performance. The support of inline caching is one of the most important high-level optimizations we employed that contributes to our performance advantage over LuaJIT.</p>
<h3 id="Conclusion-Thoughts-and-Future-Works">Conclusion Thoughts and Future Works</h3>
<p>In this post, we demonstrated how we built the fastest interpreter for Lua (to date) through a novel meta-compiler framework.</p>
<p>However, automatically generating the fastest Lua interpreter is only the beginning of our story. <a href="https://github.com/luajit-remake/luajit-remake" target="_blank" rel="noopener">LuaJIT Remake</a> is designed to be a multi-tier method-based JIT compiler generated by the Deegen framework, and we will generate the baseline JIT, the optimizing JIT, the tiering-up/OSR-exit logic, and even a fourth-tier heavyweight optimizing JIT in the future.</p>
<p>Finally, Deegen is never designed to be welded to Lua, and maybe in the very far future, we can employ Deegen to generate high-performance VMs at a low engineering cost for other languages as well.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>The benchmarks are run on my laptop with Intel i7-12700H CPU and 32GB DDR4 memory. All benchmarks are repeated 5 times and the average performance is recorded. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>As a side note, two of the three benchmarks where we lost to LuaJIT are string processing benchmarks. LuaJIT seems to have some advanced string-handling strategy, yielding the speedup. However, the strategy is not perfect: it failed badly on the <code>life</code> benchmark, and as a result, LuaJIT got stomped 3.6x by PUC Lua (and 16x by us) on that benchmark. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Some of these poor code come from insufficiently-optimized calling convention handling logic (e.g., LLVM often just pours all the spills at function entry for simplicity), and some comes from the register allocator that doesn’t have enough understanding of hot/cold path (so that it believes that hoisting a register move or a stack spill from the cold path into the fast path is an optimization while it actually isn’t). Compilers are always evolving and get better, but at least in this case it isn’t enough. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>One can also imagine an optimization that makes each “case” directly jumps to the next “case”, instead of the switch dispatcher. This is known as “<a href="https://dl.acm.org/doi/abs/10.1145/362248.362270" target="_blank" rel="noopener">direct threading</a>” in the literature for continuation-passing-style-based interpreter, or more widely known as a “computed-goto interpreter” for switch-case-based interpreter (since GCC computed-goto extension is the most straightforward way to implement such an optimization). <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>If one looks at the problem globally, clearly the better solution is to only save all the callee-saved registers once when one enters the interpreter, and restores it when the interpreter finishes, instead of having each bytecode function doing the same work again and again. But it’s impossible to tell the C/C++ compiler that “this function doesn’t need to abide to the calling convention, because by high-level design someone else will do the job for it”. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>In the current implementation, for the interpreter, each bytecode is only allowed to keep one inline cache entry, so the newly-created entry always overwrites the existing entry. However, for JIT compilers, each inline cache entry will be a piece of JIT-generated code, so there can be multiple IC entries for each bytecode. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/11/22/2022-11-22/" data-id="clhkntofw000hdsp021qm5j13" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-10-02" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/10/02/2022-10-02/">Pitfalls of using C++ Global Variable Constructor as a Registration Mechanism</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/10/02/2022-10-02/" class="article-date"><time datetime="2022-10-02T00:00:00.000Z" itemprop="datePublished">2022-10-02</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>I recently hit the following use case in my project: I have a function <code>RunAllPasses(obj)</code>, which runs a list of transformation passes on <code>obj</code>. All passes are independent from each other, so one can run them in any order. The problem is, I want to easily add new passes to the list of passes.</p>
<p>Of course one can manually maintain the list of passes, and call each of them. But this results in quite a bit of boilerplate code needed for each pass, and a lot of header files with each file merely having one function declaration for the pass.</p>
<p>Can we have less boilerplate code?</p>
<p>One intuitive direction is to have each pass “register” itself into a pass list at program initialization time, through the help of a global variable. For example, if one writes</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// WARNING: It's probably not a good idea to use this...</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">RegisterMyPass</span> &#123;</span></span><br><span class="line">  RegisterMyPass() &#123;</span><br><span class="line">    g_allPasses.push_back(MyPass);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">RegisterMyPass g_registerMyPass;</span><br></pre></td></tr></table></figure>
<p>Then the constructor of <code>g_registerMyPass</code> would automatically run when the program starts, and push the pass into a global pass list. The <code>RunAllPasses</code> function can then simply run each pass in the pass list.</p>
<p>However, this approach turns out to be the source of a stream of problems, which ultimately forced me to give up this approach. Long story short, let’s start with the experiment that led me to my conclusion.</p>
<h4 id="Linker-The-Deal-Breaker">Linker: The Deal-Breaker</h4>
<p>Create a mini project with two C++ files, <code>a.cpp</code> and <code>b.cpp</code>.</p>
<p><code>a.cpp</code> simply declares a global variable that has a constructor, which prints a message:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">  S() &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"In constructor S\n"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// Declare global variable 's'</span></span><br><span class="line"><span class="keyword">inline</span> S s;</span><br></pre></td></tr></table></figure>
<p><code>b.cpp</code> is just the <code>main()</code> function:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"In main\n"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Now, run the program (the compiler and linker doesn’t matter, at least for the few I tried):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">clang++ a.cpp -c -std=c++17</span><br><span class="line">clang++ b.cpp -c -std=c++17</span><br><span class="line">clang++ a.o b.o</span><br><span class="line">./a.out</span><br></pre></td></tr></table></figure>
<p>and we get the expected output of <code>In constructor S</code> followed by <code>In main</code>. This shows that the C++ compiler indeed took care to preserve the global variable <code>s</code> from being pruned by the linker even if it is unused, which is good.</p>
<p>But if we make <code>a.cpp</code> a library, things break!</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">clang++ a.cpp -c -std=c++17</span><br><span class="line">ar r mylib.a a.o</span><br><span class="line">clang++ b.cpp -c -std=c++17</span><br><span class="line">clang++ b.o mylib.a</span><br><span class="line">./a.out</span><br><span class="line"><span class="comment"># The 'In constructor S' line won't be printed!</span></span><br></pre></td></tr></table></figure>
<p>After further investigation, it turns out that the erratic behavior depends on whether the <em>file</em> <code>a.cpp</code> contains any symbols that are being used by the main program. For example, adding another file <code>c.cpp</code> into the static library won’t help, even if <code>c.cpp</code> contains a function used by the main program. But if we change the code a bit, so that <code>a.cpp</code> contains a function used by the main program, like the following:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// a.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">  S() &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"In constructor S\n"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// Declare global variable 's'</span></span><br><span class="line"><span class="keyword">inline</span> S s;</span><br><span class="line"><span class="comment">// Declare a function used by b.cpp</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123; <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"In function f\n"</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// b.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"In main\n"</span>);</span><br><span class="line">  f();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Then, magically, the <code>In constructor S</code> line would be printed out again.</p>
<p>What’s the problem? As it turns out, if none of the symbols in some <em>file</em> <code>X</code> of a static library is directly referenced by the main program, then the file <code>X</code> won’t be linked into the main program at all. And this “file-level pruning” ignores whatever “do-not-prune” annotation emitted by the C++ compiler in the file, since the file is not linked in altogether.</p>
<p>So I reached the conclusion that this approach is fundamentally fragile:</p>
<ol>
<li>The irratic behavior won’t show up if the global variable is defined in an object file, only when it is defined in static libraries.</li>
<li>The irratic behavior won’t show up if the C++ file defining the global variable contains other declarations that is used by the main program.</li>
<li>There is no way (AFAIK) to fix this problem other than the <code>-Wl,--whole-archive</code> linker flag, which is not only fragile, but also a bad option because it unnecessarily bloats the final executable by often a lot.</li>
</ol>
<p>The strict triggering condition means that the irratic behavior can hide undiscovered for a long time, until it is exposed by some completely irrelevant changes (e.g., moving a file to a static library, or moving some code around) and cause a debugging nightmare.</p>
<p>During the process, I also learned a number of C++-standard-imposed pitfalls about global variable constructor. I will only note one interesting example below.</p>
<p>The following code has undefined behavior, can you see why?</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="keyword">int</span>&gt; g_list;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">S</span> &#123;</span></span><br><span class="line">  S() &#123;</span><br><span class="line">    g_list.insert(<span class="number">123</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">inline</span> S r;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// Instantiate, say, S&lt;int&gt;</span></span><br></pre></td></tr></table></figure>
<p>Answer: at the time the constructor of <code>r</code> runs, the constructor of <code>g_list</code> may not have run.</p>
<p>This is because <a href="https://timsong-cpp.github.io/cppwp/basic.start#dynamic-3.1" target="_blank" rel="noopener">according to C++ standard</a>, “dynamic initialization of a non-block variable with static storage duration is unordered if the variable is an implicitly or explicitly instantiated specialization” (in our case, any instantiation of the variable <code>r</code>). Since <code>std::map</code> does not have a <code>constexpr</code> constructor, <code>g_list</code> is also dynamically initialized, so <code>r</code> may be initialized before <code>g_list</code>, even if <code>g_list</code> “appears” to be defined before <code>r</code>.</p>
<h4 id="But-isn’t-Google-Test-using-the-same-global-variable-trick">But isn’t Google Test using the same global variable trick?</h4>
<p>The above question comes to my mind soon after I uploaded this post, so I gave it a try. The result is as expected: if I move my Google test files to a static library linked against the final unit test executable, all the tests are gone. Of course, for unit tests, there is absolutely no reason to make them a static library, so I would say Google Test made the completely correct design decision. However, for the general use cases, it seems unreasonable to silently introduce bugs when the code is linked as a static library.</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/10/02/2022-10-02/" data-id="clhkntofv000gdsp05rke8e17" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-07-18" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/07/18/2022-07-18/">How to check if a real number is an integer in C++?</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/07/18/2022-07-18/" class="article-date"><time datetime="2022-07-18T00:00:00.000Z" itemprop="datePublished">2022-07-18</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>I have a <code>double</code>, and I want to know if its value is an integer that fits in a <code>int64_t</code>. How can I do it in C++?</p>
<p>Ask any C++ newbie, and you will get an obvious “answer”: cast your <code>double</code> to <code>int64_t</code>, then cast it back to <code>double</code>, and compare if it equals your original number.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsInt64</span><span class="params">(<span class="keyword">double</span> d)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> d == <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">int64_t</span>&gt;(d));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>But is it really correct? Let’s test it:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%s"</span>, IsInt64(<span class="number">1e100</span>) ? <span class="string">"1"</span> : <span class="string">"0"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>and <a href="https://godbolt.org/z/r8j98rKqd" target="_blank" rel="noopener">here’s the output</a> under <code>clang -O3</code> (latest version 14.0.0):</p>
<p><img src="/images/2022-07-18/output1.png" alt="(a bunch of junk characters that varies from run to run)"></p>
<p>!@#$%^&amp;… Why? Shouldn’t it at least print either a <code>1</code> or a <code>0</code>?</p>
<h3 id="The-Undefined-Behavior">The Undefined Behavior</h3>
<p>Here’s the reason: when you cast a floating-point value to an integer type, <a href="https://en.cppreference.com/w/cpp/language/implicit_conversion#Floating.E2.80.93integral_conversions" target="_blank" rel="noopener">according to C/C++ standard</a>, if the integral part of the value does not fit into the integer type, the behavior is undefined (by the way, casting special floating-point values <code>NaN</code>, <code>INF</code>, <code>-INF</code> to integer is also undefined behavior).</p>
<p>And unfortunately, Clang did the least helpful thing in this case:</p>
<ol>
<li>It inlined the function <code>IsInt64</code>, so <code>IsInt64(1e100)</code> becomes expression <code>1e100 == (double)(int64_t)1e100</code>.</li>
<li>It deduces that <code>(int64_t)1e100</code> incurs undefined behavior since <code>1e100</code> does not fit into <code>int64_t</code>, so it evaluates to a special <code>poison</code> value (i.e., undefined).</li>
<li>Any expression on a <code>poison</code> value also produces <code>poison</code>. So Clang deduces that expression <code>IsInt64(1e100) ? &quot;1&quot; : &quot;0&quot;</code> ultimately evaluates to <code>posion</code>.</li>
<li>As a result, Clang deduces that the second parameter to <code>printf</code> is an undefined value. So in machine code, the whole expression is “optimized out”, and whatever junk stored in that register gets passed to <code>printf</code>. <code>printf</code> will interpret that junk value as a pointer and prints out whatever content at that address, yielding the junk output.</li>
</ol>
<p>Note that even though <code>gcc</code> happens to produce the expected output in this case, the undefined behavior is still there (as all C/C++ compilers conform to the same C/C++ Standard), so there is no guarantee that the <code>IsInt64</code> function above will work on <code>gcc</code> or any compiler.</p>
<p>So how to implement this innocent function in a standard-compliant way?</p>
<h3 id="The-Bad-Fix-Attempt-1">The Bad Fix Attempt #1</h3>
<p>To avoid the undefined behavior, we must check that the <code>double</code> fits in the range of the <code>int64_t</code> before doing the casting. However, there’s a few tricky problems involved:</p>
<ol>
<li>While <code>-2^63</code> (the smallest <code>int64_t</code>) has an exact representation in <code>double</code>, <code>2^63-1</code> (the largest <code>int64_t</code>) doesn’t. So we must be careful about the rounding problems when doing the comparison.</li>
<li>Comparing the special floating-point value <code>NaN</code> with any number will yield <code>false</code>, so we must write our check in a way that <code>NaN</code> won’t pass the check.</li>
<li>There is another weird thing called <a href="https://en.wikipedia.org/wiki/Signed_zero" target="_blank" rel="noopener">negative zero</a> (<code>-0</code>). For the purpose of this post, we treat <code>-0</code> same as <code>0</code>. If not, you will need another special check.</li>
</ol>
<p>With these in mind, here’s the updated version:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsInt64</span><span class="params">(<span class="keyword">double</span> d)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="number">-9223372036854775808.0</span> &lt;= d &amp;&amp; d &lt; <span class="number">9223372036854775808.0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> d == <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">int64_t</span>&gt;(d));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>However, unfortunately, while the above version is correct, it results in some unnecessarily terrible code on x86-64:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">.LCPI0_0:</span><br><span class="line">  .quad   0xc3e0000000000000     # double -9.2233720368547758E+18</span><br><span class="line">.LCPI0_1:</span><br><span class="line">  .quad   0x43e0000000000000     # double 9.2233720368547758E+18</span><br><span class="line">IsInt64(double):                            # @IsInt64(double)</span><br><span class="line">  xor        eax,  eax</span><br><span class="line">  ucomisd    xmm0, qword ptr [rip + .LCPI0_0]</span><br><span class="line">  jb         .LBB0_3</span><br><span class="line">  movsd      xmm1, qword ptr [rip + .LCPI0_1] </span><br><span class="line">  ucomisd    xmm1, xmm0</span><br><span class="line">  jbe        .LBB0_3</span><br><span class="line">  cvttsd2si  rax,  xmm0</span><br><span class="line">  xorps      xmm1, xmm1</span><br><span class="line">  cvtsi2sd   xmm1, rax</span><br><span class="line">  cmpeqsd    xmm1, xmm0</span><br><span class="line">  movq       rax,  xmm1</span><br><span class="line">  and        eax,  1</span><br><span class="line">.LBB0_3:</span><br><span class="line">  ret</span><br></pre></td></tr></table></figure>
<p>In fact, despite that out-of-range floating-point-to-integer cast is undefined behavior in C/C++, the x86-64 instruction <code>cvttsd2si</code> used above to perform the cast is <a href="https://www.felixcloutier.com/x86/cvttsd2si" target="_blank" rel="noopener">well-defined on all inputs</a>: if the input doesn’t fit in <code>int64_t</code>, then the output is <code>0x80000000 00000000</code>. And since <code>0x80000000 00000000</code> has an exact representation in <code>double</code>, casting it back to <code>double</code> will yield <code>-2^63</code>, which won’t compare equal to any <code>double</code> value but <code>-2^63</code>.</p>
<p>So the range-check is actually unnecessary for the code to behave correctly on x86-64: it is only there to keep the C++ compiler happy, but unfortunately, the C++ compiler is unable to realize that such check is unnecessary on x86-64, thus cannot optimize it out on x86-64.</p>
<p>To summarize, on x86-64, all we need to generate is the last few lines of the above code.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">IsInt64(double):                           # @IsInt64(double)</span><br><span class="line">  cvttsd2si  rax,  xmm0</span><br><span class="line">  cvtsi2sd   xmm1, rax</span><br><span class="line">  cmpeqsd    xmm1, xmm0</span><br><span class="line">  movq       rax,  xmm1</span><br><span class="line">  and        eax,  1</span><br><span class="line">  ret</span><br></pre></td></tr></table></figure>
<p>But is there any way we can teach the compiler to generate such assembly?</p>
<h3 id="The-Bad-Fix-Attempt-2">The Bad Fix Attempt #2</h3>
<p>In fact, our original buggy implementation</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsInt64</span><span class="params">(<span class="keyword">double</span> d)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> d == <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">int64_t</span>&gt;(d));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>produces <a href="https://godbolt.org/z/66Y4nKc1b" target="_blank" rel="noopener">exactly the above assembly</a>. The problem is, whenever the optimizer of the C++ compiler inlines this function and figures out that the input is a compile-time constant, it will do constant propagation according to C++ rule – and as a result, generate the <code>poison</code> value. So can we stop the optimizer from this unwanted optimization, while still having it doing optimizations properly for the rest of the program?</p>
<p>In fact, I have posted this question on LLVM forum months ago, and didn’t get an answer. But recently I suddenly had an idea. <code>gcc</code> and <code>clang</code> all support a <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html" target="_blank" rel="noopener">crazy builtin</a> named <code>__builtin_constant_p</code>. Basically this builtin takes one parameter, and returns <code>true</code> if the parameter can be proven by the compiler to be a compile-time constant<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. Yes, the result of this function is dependent on the optimization level!</p>
<p>This builtin has a very good use case: to implement <code>constexpr</code> <code>offsetof</code>. If you are certain that some expression <code>p</code> is a compile-time constant, you can do <code>constexpr SomeType foo = __builtin_constant_p(p) ? p : p;</code> to forcefully make <code>p</code> a <code>constexpr</code>, even if <code>p</code> is not <code>constexpr</code> by C++ standard, and the compiler won’t complain anything! This allows one to perform <code>constexpr</code> <code>reinterpret_cast</code> between <code>uintptr_t</code> and pointers, thus implement a <code>constexpr</code>-version <code>offsetof</code> operator.</p>
<p>However, what I realized is that, this builtin can also be used to prevent the unwanted constant propagation. Specifically, we will check <code>if (__builtin_constant_p(d))</code>. If yes, we run the slow-but-correct code – this doesn’t matter as the optimizer is going to constant-fold the code anyway. If not, we execute the fast-but-UB-prone code, which is also fine because we already know the compiler can’t constant-fold anything to trigger the undefined behavior.</p>
<p>The new version of the code is below:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DON'T USE IT!</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsInt64</span><span class="params">(<span class="keyword">double</span> d)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (__builtin_constant_p(d)) &#123;</span><br><span class="line">    <span class="comment">// Run UB-free version, knowing that it's going to </span></span><br><span class="line">    <span class="comment">// be constant-folded by the compiler any way</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="number">-9223372036854775808.0</span> &lt;= d &amp;&amp; d &lt; <span class="number">9223372036854775808.0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> d == <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">int64_t</span>&gt;(d));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> d == <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">int64_t</span>&gt;(d));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>I tried the above code on a bunch of constants and non-constant cases, and the result seems good. Either the input is correctly constant-folded, or the good-version assembly is generated.</p>
<p>So I thought I outsmarted the compiler in this stupid Human-vs-Compiler game. But am I…?</p>
<h3 id="Don’t-Fight-the-Tool">Don’t Fight the Tool!</h3>
<p>Why does C/C++ have this undefined behavior after all? Once I start to think about this problem, I begin to realize that something must be wrong…</p>
<p>The root reason that C/C++ Standard specifies that an out-of-range floating-point-to-integer cast is undefined behavior is because on different architectures, the instruction that performs the float-to-int cast exhibits different behavior when the floating-point value doesn’t fit in the integer type. On x86-64, the behavior of the <code>cvttsd2si</code> instruction in such cases is to produce <code>0x80000000 00000000</code>, which is fine for our use case. But what about the other architectures?</p>
<p>As it turns out, on ARM64, the semantics of the <code>fcvtzs</code> instruction (analogue of x86-64’s <code>cvttsd2si</code>) is saturation: if the floating-point value is larger than the max value of the integer type, the max value is produced; similarly, if the floating-point value is too small, the minimum integer value is produced. So if the <code>double</code> is larger than <code>2^63-1</code>, <code>fcvtzs</code> will produce <code>2^63-1</code>, not <code>-2^63</code> like in x86-64.</p>
<p>Now, recall that <code>2^63-1</code> doesn’t have an exact representation in <code>double</code>. When <code>2^63-1</code> is cast to <code>double</code>, it becomes <code>2^63</code>. So if the input <code>double</code> value is <code>2^63</code>, casting it to <code>int64_t</code> (<code>fcvtzs x8, d0</code>) will yield <code>2^63-1</code>, and then casting it back to <code>double</code> (<code>scvtf d1, x8</code>) will yield <code>2^63</code> again. So on ARM64, our code will determine that the <code>double</code> value <code>2^63</code> fits in <code>int64_t</code>, despite that it actually does not.</p>
<p>I don’t own a ARM64 machine like Apple M1, so I created a virtual machine using <code>QEMU</code> to validate this. Without surprise, on ARM64, our function fails when it is fed the input <code>2^63</code>.</p>
<p>So clearly, the undefined behavior <em>is</em> there for a reason…</p>
<h3 id="Pick-the-Right-Tool-Instead">Pick the Right Tool Instead!</h3>
<p>As it turns out, I really should not have tried to outsmart the compiler with weird tricks. If performance is not a concern, then the UB-free version is actually the only portable and correct version:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsInt64</span><span class="params">(<span class="keyword">double</span> d)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="number">-9223372036854775808.0</span> &lt;= d &amp;&amp; d &lt; <span class="number">9223372036854775808.0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> d == <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(<span class="keyword">static_cast</span>&lt;<span class="keyword">int64_t</span>&gt;(d));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>And if performance <em>is</em> a concern, then it’s better to simply resort to architecture-dependent inline assembly. Yes, now a different implementation is needed for every architecture, but at least it’s better than dealing with hard-to-debug edge case failures.</p>
<p>Of course, the ideal solution is to improve the compiler, so that the portable version generates optimal code on every architecture. But given that neither <code>gcc</code> nor <code>clang</code> had supported this, I assume it’s not an easy thing to do.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Note that this builtin is different from the C++20 <code>std::is_constant_evaluated()</code>. The <code>is_constant_evaluated</code> only concerns whether a <code>constexpr</code> function is being evaluated constexpr-ly. However, <code>__builtin_constant_p</code> tells you whether a (maybe non-constexpr) expression can be deduced to a compile-time known constant under the current optimization level, so it has nothing to do with <code>constexpr</code>. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/07/18/2022-07-18/" data-id="clhkntofu000fdsp0ae5229st" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-11" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/06/11/2022-06-11/">Bizarre Performance Characteristics of Alder Lake CPU</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/06/11/2022-06-11/" class="article-date"><time datetime="2022-06-11T00:00:00.000Z" itemprop="datePublished">2022-06-11</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>TL;DR: Some of the P-cores in Alder Lake CPU can exhibit highly unstable performance behavior, resulting in large noise for any benchmark running on it.</p>
<p>UPDATE: A colleague of mine reported that the behavior can be observed on his i9-9980HK as well, and observed ~25% end-performance fluctuations on short-running benchmarks. So it seems like this behavior as been around for quite a while – dating back to at least the 9th-gen Intel CPU<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>.</p>
<p>As a performance engineer, it’s routine to evaluate the performance before and after a code commit. This is why I’ve been faintly feeling that something is unusual about my new Intel Alder Lake i7-12700H laptop CPU.</p>
<p>Today I dug into the problem. As I discovered, this CPU indeed exhibits some highly unusual and surprising performance characteristics, which can easily cause pitfalls for benchmarks.</p>
<p>For background, Alder Lake features a <em>hybrid architecture</em> of the powerful P-cores and the weaker E-cores. i7-12700H has 6 P-cores and 8 E-cores. Of course, we want to have the P-cores run our time-sensitive tasks, such as our benchmarks. This can be done easily by <code>taskset</code> the process to only P-cores.</p>
<p>This is where the story begins. I noticed two problems with the P-cores:</p>
<ol>
<li>Sometimes it cannot turbo-boost to 4.7GHz, the <a href="https://ark.intel.com/content/www/us/en/ark/products/132228/intel-core-i712700h-processor-24m-cache-up-to-4-70-ghz.html" target="_blank" rel="noopener">Intel-specified</a> max turbo boost frequency (for the one-active-core case) for i7-12700H.</li>
<li>Sometimes it cannot stay at the highest CPU frequency it can boost to.</li>
</ol>
<p>Point 1 implies that we cannot enjoy the full performance promoted by Intel. Point 2 implies that the core cannot deliver <em>consistent</em> performance, which is problematic for performance engineering, as the noise would make two benchmark runs less comparable.</p>
<h3 id="Test-Setup">Test Setup</h3>
<p>To expose the problem, I wrote a dumb program that increments a variable in a dead loop, so that the frequency of the CPU running the program is maxed out. Then I use <code>taskset</code> to pin the program to one CPU, have it run for 60 seconds, and run <code>cpufreq</code> every second to record the frequency of that CPU in the duration<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>.</p>
<p>I took the following precautions to ensure nothing outside the CPU chip is limiting the CPU from boosting to its max frequency:</p>
<ol>
<li>Use <code>isolcpus</code> Linux kernel boot parameter to exclusively dedicate the tested CPU core to our test program. This removes any noise caused by the OS.</li>
<li>Confirm the CPU is not throttled by power limit: with only one active core (running our test program), the CPU package power consumption is less than <code>25W</code>, far less than the base <code>45W</code> TDP of i7-12700H.</li>
<li>Confirm the CPU is not temperature-throttled (by monitoring sensors). To be paranoid, I also set a <code>20s</code> gap between each test so the temperature goes back to idle state.</li>
<li>Confirm the machine is in idle state, and stop unnecessary background services.</li>
<li>The CPU <a href="https://wiki.archlinux.org/title/CPU_frequency_scaling#Scaling_governors" target="_blank" rel="noopener">frequency governer</a> is set to <code>performance</code>, and I confirmed that the governer is not limiting the turbo boost frequency.</li>
<li>Everything is at stock setting: nothing is overclocked or undervolted, etc.</li>
<li>All tests are repeated 3 times, and consistent behavior is observed for every core.</li>
</ol>
<h3 id="Not-All-P-cores-Are-Born-Equal">Not All P-cores Are Born Equal</h3>
<p>The test confirmed my hypothesis that the 6 P-cores in my i7-12700H do not have a uniform quality. Specifically, my 6 P-cores exhibit three different performance characteriscs!</p>
<p>I dubbed them as “gold core”, “B-grade core”, and “wild core”:</p>
<ol>
<li>Gold core: the core can boost to and stay at 4.7GHz, just as Intel claimed.</li>
<li>B-grade core: the core can boost to and stay at a frequency lower than 4.7GHz.</li>
<li>Wild core: the core cannot boost to 4.7GHz, and cannot stay at any stable frequency: it will fluctuate wildly between a range of frequencies, and the degree of turbulence also varies per core.</li>
</ol>
<p>We will explain their performance characteristics below.</p>
<h3 id="The-“Wild-Cores”">The “Wild Cores”</h3>
<p>Let’s start with the most bizarre cores: the wild ones. As it turns out, 3 out of my 6 P-cores are wild (a whopping 50%!), and among those three cores, one of them is particularly wild, as shown in the plot below<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>:</p>
<p><img src="/images/2022-06-11/P-Core-3.png" alt="x-axis: CPU frequency in GHz, y-axis: time (60 seconds), each line is one run"></p>
<p>As you can see, the CPU frequency turbulents violently from 4.05GHz to 4.55GHz, and each run exhibits a completely different pattern. Clearly, if any benchmark were run on this core, such a large noise would be a headache to deal with.</p>
<p>The other two wild cores I got were less turbulent. Even though, the noise introduced by the frequency instability still make them not ideal for benchmark comparison:</p>
<p><img src="/images/2022-06-11/P-Core-1.png" alt="x-axis: CPU frequency in GHz, y-axis: time (60 seconds), each line is one run"><br>
<img src="/images/2022-06-11/P-Core-5.png" alt="x-axis: CPU frequency in GHz, y-axis: time (60 seconds), each line is one run"></p>
<h3 id="The-“B-grade-Cores”">The “B-grade Cores”</h3>
<p>The B-grade cores (as I dubbed) are better: while they cannot boost to 4.7GHz as promoted by Intel, at least they can operate at a consistent frequency, so benchmark results are comparable as long as they are run on the same core.</p>
<p>It turns out that my i7-12700H has two B-grade cores, both capable of operating at 4.5GHz:</p>
<p><img src="/images/2022-06-11/P-Core-0.png" alt="x-axis: CPU frequency in GHz, y-axis: time (60 seconds), each line is one run"><br>
<img src="/images/2022-06-11/P-Core-4.png" alt="x-axis: CPU frequency in GHz, y-axis: time (60 seconds), each line is one run"></p>
<p>As one can see, the core for the second graph has slightly higher frequency variations. Nevertheless, they are much stabler than the three wild cores.</p>
<h3 id="The-“Gold-Core”">The “Gold Core”</h3>
<p>Only 1 out of the 6 P-cores of my i7-12700H matches Intel’s marketing<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>:</p>
<p><img src="/images/2022-06-11/P-Core-2.png" alt="x-axis: CPU frequency in GHz, y-axis: time (60 seconds), each line is one run"></p>
<p>As one can see, it operates stably at about 4.68GHz, just as Intel claimed.</p>
<h3 id="The-Behavior-of-the-E-cores">The Behavior of the E-cores</h3>
<p>Unlike the P-cores, it turns out that the E-cores have extremely stable behavior. All the eight E-cores can boost to and stay at 3.5GHz, just as the Intel specification said. There is not even a single outlier point: as you can see in the figure, it’s a completely straight line.</p>
<p><img src="/images/2022-06-11/E-Core.png" alt="All E-cores can stay perfectly at 3.5GHz, as they are supposed to"></p>
<h3 id="Conclusion-Thoughts">Conclusion Thoughts</h3>
<p>Given Intel’s tight testing and binning quality-control process, it seems very unlikely that I’m seeing all of these only because I got a defective. So I conjecture the “wild core” behavior can likely be observed on many i7-12700H CPUs.</p>
<p>Additionally, since i7-12700H is just the same i9-12900 chip with two below-quality P-cores disabled, it is also interesting to know if the behavior shows up on higher-end Alder Lake models, like the i9-12900K, as those presumably come from the better silicons, but I don’t have the ability to validate it.</p>
<p>Nevertheless, from a practicalist’s perspective, the action to take is clear: run the benchmark to identify the best cores and the performance-unstable cores on your chip, avoid running benchmarks on the performance-unstable cores, and use the best cores for the most latency-sensitive application.</p>
<p>For example, for my particular chip, physical core 2 (logical core 4-5) turns out to be the only “gold core”, so <code>taskset -c 4</code> for single-threaded benchmark is a good idea. Similarly, for latency-sensitive multi-threaded application (like the <code>QtCreator</code> IDE, where UX is heavily affected by auto-completion latency), it is reasonable to modify the startup command in the desktop link to pin it to the good cores (logical core <code>0,1,4,5,8,9</code> in my particular chip).</p>
<h4 id="But-why">But why?</h4>
<p>I’m not expert at all, but my conjecture is that the increase in clock frequency and # of cores in recent CPUs <em>might</em> be the cause: due to <a href="https://www.makeuseof.com/silicon-lottery-why-no-two-processors-are-the-same/" target="_blank" rel="noopener">silicon lottery</a>, the max stable clock frequency is inherently different for each core. So as the chip gets more cores, it becomes exponentially harder to find chips where <em>all</em> cores in the chip match the spec frequency criteria – so maybe that’s why Intel loosened their criteria?</p>
<p>On the other hand, boost frequency is <em>designed</em> to go down as more cores become active. So in theory, having one golden core is actually enough, as long as the OS is aware of which core is golden, and assigns performance-demanding task to that core. However, it doesn’t seem to be the case yet, at least for my Ubuntu running Linux kernel 5.15.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>On the other hand, my 7-th generation i7-7700HQ CPU does not have the problem described in this post. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>The full bash script for the test can be found <a href="https://sillycross.github.io/assets/2022-06-11/i7_12700h_cpu_test.txt">here</a>. For least noise, you should use <code>isolcpus</code> boot parameter to isolate a subset of CPUs, reboot, modify the script to only test the isolated subset, then change <code>isolcpus</code> to isolate the opposite set of CPUs, reboot, and modify the script to test the opposite set. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>The two logical CPUs of the physical core exhibit the same behavior, so I only show one of them. Same for other figures in this post. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Though if you take a closer look at their specification, you’ll see what Intel claimed is “up to 4.7GHz”, so technically they did not lie, as they never claimed all cores can meet their specification – though, I guess, two cores 0.2GHz slower, two cores 0.35GHz slower and turbulent, one core 0.5GHz slower and highly turbulent is still, hmm. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/06/11/2022-06-11/" data-id="clhkntoft000edsp0c6oz36sd" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-06-02" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/06/02/2022-06-02/">Understanding GC in JSC From Scratch</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/06/02/2022-06-02/" class="article-date"><time datetime="2022-06-02T00:00:00.000Z" itemprop="datePublished">2022-06-02</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>Javascript relies on garbage collection (GC) to reclaim memory. In this post, we will dig a little bit into JSC (the Javascript engine of <a href="https://webkit.org/" target="_blank" rel="noopener">WebKit</a>)'s garbage collection system.</p>
<p>WebKit’s <a href="https://webkit.org/blog/7122/introducing-riptide-webkits-retreating-wavefront-concurrent-garbage-collector/" target="_blank" rel="noopener">blog post on GC</a> is a great post that explained the novelties of JSC’s GC and also positioned it within the context of various GC schemes in academia and industry. However, as someone with little GC background, I found WebKit’s blog post too hard to understand, and also too vague to understand the specific design used by JSC. So this blog post attempts to add in some more details, and aims to be understandable even by someone with little prior background on GC.</p>
<p>The garbage collector in JSC is <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection#Moving_vs._non-moving" target="_blank" rel="noopener">non-compacting</a>, <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection#Generational_GC_(ephemeral_GC)" target="_blank" rel="noopener">generational</a> and mostly<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>-<a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection#Stop-the-world_vs._incremental_vs._concurrent" target="_blank" rel="noopener">concurrent</a>. On top of being concurrent, JSC’s GC heavily employs lock-free programming for better performance.</p>
<p>As you can imagine, the design used by JSC is quite complex. So instead of diving into the complex invariants and protocols, we will start with the simplest design, and improve it step by step to converge at JSC’s design in the end. This way, we not only understand <em>why</em> JSC’s design works, but also <em>how</em> JSC’s design is reached.</p>
<p>But first of all, let’s get into some background.</p>
<h3 id="Memory-Allocation-in-JSC">Memory Allocation in JSC</h3>
<p>Memory allocator and GC are tightly coupled by nature – the allocator allocates memory to be reclaimed by the GC, and the GC frees memory to be reused by the allocator. In this section, we will briefly introduce JSC’s memory allocators.</p>
<p>At the core of the memory allocation scheme in JSC is the data structure <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/BlockDirectory.h.html#JSC::BlockDirectory">BlockDirectory</a><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>. It implements a fixed-sized allocator, that is, an allocator that only allocates memory chunks of some fixed size <code>S</code>. The allocator keeps tracks of a list of fixed-sized (in current code, 16KB) memory pages (“blocks”) it owns, and a free list. Each block is divided into cells of size <code>S</code>, and has a footer at its end<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>, which contains various metadata information needed for GC and allocator, e.g., which cells are free. By aggregating and sharing metadata at the footer, it both saves memory and improves performance of related operations: we will go into details later.</p>
<p>When a <code>BlockDirectory</code> needs to make an allocation, it tries to allocate from its free list. If the free list is empty, it tries to iterate through the blocks it owns<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>, to see if it can find a block containing free cells (which are marked free by GC). If yes, it <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlock.cpp.html#_ZN3JSC11MarkedBlock6Handle5sweepEPNS_8FreeListE">scans the block footer metadata</a> to find out all the free cells<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> in this block, and put into the free list. Otherwise, it allocates a new block from the OS<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>. Note that this implies a <code>BlockDirectory</code>’s free list only contains cells in one block: this is called <code>m_currentBlock</code> in the code, and we will revisit this later.</p>
<p>The <code>BlockDirectory</code> is used as the building block to build the memory allocators in JSC. JSC employs three kinds of allocators:</p>
<ol>
<li><a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/CompleteSubspace.h.html#32">CompleteSubspace</a>: this is a segregated allocator responsible for allocating small objects (max size about 8KB). Specifically, there is a pre-defined list of exponentially-growing size-classes<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>, and one <code>BlockDirectory</code> is used to handle allocation for each size class. So to allocate an object, you find the smallest size class large enough to hold the object, and allocate from that size class.</li>
<li><a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/PreciseAllocation.h.html#JSC::PreciseAllocation">PreciseAllocation</a>: this is used to handle large allocations that cannot be handled by <code>CompleteSubspace</code> allocator<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>. It simply relies on the standard (malloc-like) memory allocator, though in JSC a custom malloc implementation called <code>libpas</code> is used. The downside is that since <code>PreciseAllocation</code> is done on a per-object basis, it cannot aggregate and share metadata information of multiple objects together to save memory and improve performance (as <code>CompleteSubspace</code>’s block footer did). Therefore, every <code>PreciseAllocation</code> comes with a whopping overhead of a <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/PreciseAllocation.h.html#JSC::PreciseAllocation">96-byte GC header</a> to store the various metadata information needed for GC for this object (though this overhead is justified since each allocation is already at least 8KB).</li>
<li><a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/IsoSubspace.h.html#JSC::IsoSubspace">IsoSubspace</a>: each <code>IsoSubspace</code> is used to allocate objects of a fixed type with a fixed size. So each <code>IsoSubspace</code> simply holds a <code>BlockDirectory</code> to do allocation (though JSC also has an optimization for small <code>IsoSubspace</code> by making them backed by <code>PreciseAllocation</code><sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>). This is mainly a security hardening feature that makes use-after-free-based attacks harder<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>.</li>
</ol>
<p>As you can see, <code>IsoSubspace</code> is mostly a simplified <code>CompleteSubspace</code>, so we will ignore it for the purpose of this post. <code>CompleteSubspace</code> is the one that handles the common case: small allocations, and <code>PreciseAllocation</code> is mostly the rare slow path for large allocations.</p>
<h3 id="Generational-GC-Basics">Generational GC Basics</h3>
<p>In JSC’s generational GC model, the heap consists of a small “new space” (eden), holding the newly allocated objects, and a large “old space” holding the older objects that have survived one GC cycle. Each GC cycle is either an <em>eden GC</em> or a <em>full GC</em>. New objects are allocated in the eden. When the eden is full, an eden GC is invoked to garbage-collect the unreachable objects in eden. All the surviving objects in eden are then considered to be in the old space<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>. To reclaim objects in the old space, a full GC is needed.</p>
<p>The effectiveness of the above scheme relies on the so-called “generational hypothesis”:</p>
<ol>
<li>Most objects collected by the GC are young objects (died when they are still in eden), so eden GC (which only collects the eden) is sufficient to reclaim most of the memory.</li>
<li>Pointers from old space to eden is much rarer than pointers from eden to old space or pointers from eden to eden, so an eden GC’s runtime is approximately linear to the size of the eden, as it only needs to start from a small subset of the old space. This implies that the cost of GC can be amortized by the cost of allocation.</li>
</ol>
<h4 id="Inlined-vs-Outlined-Metadata-Why">Inlined vs. Outlined Metadata: Why?</h4>
<p>Practically every GC scheme uses some kind of metadata to track which objects are alive. In this section, we will explain how those metadata are stored in JSC, and the motivation behind such design.</p>
<p>In JSC, every object managed by the GC carries the following metadata:</p>
<ol>
<li>Every object managed by GC inherit the <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/runtime/JSCell.h.html#JSC::JSCell">JSCell</a> class, which contains a 1-byte member <code>cellState</code>. This <code>cellState</code> is a color marker with two colors: white and black<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>.</li>
<li>Every object also has two out-of-object metadata bits: <code>isNew</code><sup class="footnote-ref"><a href="#fn13" id="fnref13">[13]</a></sup> and <code>isMarked</code>. For objects allocated by <code>PreciseAllocation</code>, the bits reside in the GC header. For objects allocated by <code>CompleteSubspace</code>, the bits reside in the block footer.</li>
</ol>
<p>This may seem odd at first glance since <code>isNew</code> and <code>isMarked</code> could have been stored in the unused bits of <code>cellState</code>. However, this is intentional.</p>
<p>The inlined metadata <code>cellState</code> is easy to access for the mutator thread (the thread executing Javascript code), since it is just a field in the object. However, it has bad memory locality for GC and allocators, which need to quickly traverse through all the metadata of all objects in some block owned by <code>CompleteSubspace</code> (which is the common case). Outlined metadata have the opposite performance characteristics: they are more expensive to access for the mutator thread, but since they are aggregated into bitvectors and stored in the block footer of each block, GC and allocators can traverse them really fast.</p>
<p>So JSC keeps both inlined and outlined metadata to get the better of both worlds: the mutator thread’s fast path will only concern the inlined <code>cellState</code>, while the GC and allocator logic can also take advantage of the memory locality of the outlined bits <code>isNew</code> and <code>isMarked</code>.</p>
<p>Of course, the cost of this is a more complex design… so we have to unfold it bit by bit.</p>
<h3 id="A-Really-Naive-Stop-the-World-Generational-GC">A Really Naive Stop-the-World Generational GC</h3>
<p>Let’s start with a really naive design just to understand what is needed. We will design a generational, but stop-the-world (i.e. not incremental or concurrent) GC, with no performance optimizations at all. In this design, the mutator side transfers control to the GC subsystem at a “safe point”<sup class="footnote-ref"><a href="#fn14" id="fnref14">[14]</a></sup> to start a GC cycle (eden or full). The GC subsystem performs the GC cycle from the beginning to the end (as a result, the application cannot run during this potentially long period, thus “stop-the-world”), and then transfer control back to the mutator side.</p>
<p>For this purpose, let’s temporarily forget about <code>CompleteSubspace</code>: it is an optimized version of <code>PrecisionAllocation</code> for small allocations, and while it is an important optimization, it’s easier to understand the GC algorithm without it.</p>
<p>It turns out that in this design, all we need is one <code>isMarked</code> bit. The <code>isMarked</code> bit will indicate if the object is reachable at the end of the last GC cycle (and consequently, is in the old space, since any object that survived a GC cycle is in old space). All objects are born with <code>isMarked = false</code>.</p>
<p>The GC will use a breadth-first search to scan and mark objects. For full GC, we want to reset all <code>isMarked</code> bit to <code>false</code> at the beginnning, and do a BFS to scan and mark all objects reachable from GC roots. Then all the unmarked objects are known to be dead. For eden GC, we only want to scan the eden space. Fortunately, all objects in the old space are already marked at the end of the previous GC cycle, so they are naturally ignored by the BFS, so we can simply reuse the same BFS algorithm in full GC. In pseudo-code:</p>
<p>Eden GC preparation phase: no work is needed.</p>
<p>Full GC preparation phase<sup class="footnote-ref"><a href="#fn15" id="fnref15">[15]</a></sup>:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (JSCell* obj : heap) </span><br><span class="line">  obj-&gt;isMarked = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure>
<p>Eden/Full GC marking phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!<span class="built_in">queue</span>.empty()) &#123;</span><br><span class="line">  JSCell* obj = <span class="built_in">queue</span>.pop();</span><br><span class="line">  obj-&gt;ForEachChild([&amp;](JSCell* child) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!child-&gt;isMarked) &#123;   </span><br><span class="line">      child-&gt;isMarked = <span class="literal">true</span>; </span><br><span class="line">      <span class="built_in">queue</span>.push(child);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Eden/Full GC collection phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// One can easily imagine optimization to make eden collection </span></span><br><span class="line"><span class="comment">// traverse only the eden space. We ignore it for simplicity.</span></span><br><span class="line"><span class="keyword">for</span> (JSCell* obj : heap) </span><br><span class="line">  <span class="keyword">if</span> (!obj-&gt;isMarked) </span><br><span class="line">    <span class="built_in">free</span>(obj);</span><br></pre></td></tr></table></figure>
<p>But where does the scan start, so that we can scan through every reachable object? For full GC, the answer is clear: we just start the scan from all <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection#Reachability_of_an_object" target="_blank" rel="noopener">GC roots</a><sup class="footnote-ref"><a href="#fn16" id="fnref16">[16]</a></sup>. However, for eden GC, in order to reliably scan through all reachable objects, the situation is slightly more complex:</p>
<ol>
<li>Of course, we still need to push the GC roots to the initial queue.</li>
<li>If an object in the old space contains a pointer to an object in eden, we need to put the old space object to the initial queue<sup class="footnote-ref"><a href="#fn17" id="fnref17">[17]</a></sup>.</li>
</ol>
<p>The invariant for the second case is maintained by the mutator side. Specifically, whenever one writes a pointer slot of some object <code>A</code> in the heap to point to another object <code>B</code>, one needs to check if <code>A.isMarked</code> is <code>true</code> and <code>B.isMarked</code> is <code>false</code>. If so, one needs to put <code>A</code> into a “remembered set”. Eden GC must treat the objects in the remembered set as if they were GC roots. This is called a <code>WriteBarrier</code>. In pseudo-code:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Executed after writing a pointer to 'dst' into a field of 'obj'</span></span><br><span class="line"><span class="keyword">if</span> (obj-&gt;isMarked &amp;&amp; !dst-&gt;isMarked) </span><br><span class="line">  addToRememberedSet(obj);</span><br></pre></td></tr></table></figure>
<h3 id="Getting-Incremental">Getting Incremental</h3>
<p>The stop-the-world GC isn’t feasible for production use. A GC cycle (especially a full GC cycle) can take a long time. Since the mutator (application logic) cannot run during the period, the application would appear irresponsive to the user, which is very bad user experience.</p>
<p>A natural way to shorten this irresponsive period is to run GC incrementally: at safe points, the mutator transfers control to the GC. The GC only runs for a short time, doing a portion of the work for the current GC cycle (eden or full), then return control to the mutator. This way, each GC cycle is splitted into many small steps, so the irresponsive periods are less noticeable for the user.</p>
<p>Incremental GC poses a few new challenges to the GC scheme.</p>
<p>The first challenge is the extra interference between GC and mutator: the mutator side, namely the allocator and the <code>WriteBarrier</code>, must be prepared to see states arisen from a partially-completed GC cycle. And the GC side must correctly mark all reachable objects despite changes made by the mutator side in between.</p>
<p>Specifically, our full GC must change: imagine that the full GC scanned some object <code>o</code> and handed back control to mutator, then the mutator changed a field of <code>o</code> to point to some other object <code>dst</code>. The object <code>dst</code> must not be missed from scanning. Fortunately, in such case <code>o</code> will be <code>isMarked</code> and <code>dst</code> will be <code>!isMarked</code> (if <code>dst</code> has <code>isMarked</code> then it has been scanned, so there’s nothing to worry about), so <code>o</code> will be put into the remembered set.</p>
<p>Therefore, for full GC to function correctly in the incremental GC scheme, it must consider the remembered set as GC root as well, just like the eden GC.</p>
<p>The other parts of the algorithm as of now can remain unchanged (we leave the proof of correctness as an excerise for the reader). Nevertheless, “what happens if a GC cycle is run partially?” is something that we must keep in mind as we add more optimizations.</p>
<p>The second challenge is that the mutator side can repeatedly put an old space object into the remembered set, and result in redundant work for the GC: for example, the GC popped some object <code>o</code> in the remembered set, traversed from it, and handed over control to mutator. The mutator modified <code>o</code> again, putting it back to the remembered set. If this happens too often, the incremental GC could do a lot more work than a stop-the-world GC.</p>
<p>The obvious mitigation is to have the GC scan the remembered set last: only when the queue has otherwise been empty do we start popping from the remembered set. However, it turns out that this is not enough. JSC employs a technique called <em>Space-Time Scheduler</em> to further mitigate this problem. In short, if it obverves that the mutator was allocating too fast, the mutator would get decreasingly less time quota to run so the GC can catch up (and in the extreme case, the mutator would get zero time quota to run, so it falls back to the stop-the-world approach). The <a href="https://webkit.org/blog/7122/introducing-riptide-webkits-retreating-wavefront-concurrent-garbage-collector/" target="_blank" rel="noopener">WebKit blog post</a> has explained it very clearly, so feel free to take a look if you are interested.</p>
<p>Anyway, let’s update the pseudo-code for the eden/full GC marking phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!<span class="built_in">queue</span>.empty() || !rmbSet.empty()) &#123;</span><br><span class="line">  <span class="comment">// Both eden GC and full GC needs to consider remembered set</span></span><br><span class="line">  <span class="comment">// Prioritize popping from queue, pop remembered set last</span></span><br><span class="line">  JSCell* obj = !<span class="built_in">queue</span>.empty() ? <span class="built_in">queue</span>.pop() : rmbSet.pop();</span><br><span class="line">  obj-&gt;ForEachChild([&amp;](JSCell* child) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!child-&gt;isMarked) &#123;   </span><br><span class="line">      child-&gt;isMarked = <span class="literal">true</span>; </span><br><span class="line">      <span class="built_in">queue</span>.push(child);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Incorporate-in-CompleteSubspace">Incorporate in CompleteSubspace</h3>
<p>It’s time to get our <code>CompleteSubspace</code> allocator back so we don’t have to suffer the huge per-object GC header overhead incurred by <code>PreciseAllocation</code>.</p>
<p>For <code>PreciseAllocation</code>, the actual memory management work is done by <code>malloc</code>: when the mutator wants to allocate an object, it just <code>malloc</code> it, and when the GC discovers a dead object, it just <code>free</code> it.</p>
<p><code>CompleteSubspace</code> introduces another complexity, as it only allocate/deallocate memory from the OS at 16KB-block level, and does memory management itself to divide the blocks into cells that it serves to the application. Therefore, it has to track whether each of its cells is available for allocation. The mutator allocates from the available cells, and the GC marks dead cells as available for allocation again.</p>
<p>The <code>isMarked</code> bit is not enough for the <code>CompleteSubspace</code> allocator to determine if a cell contains a live object or not: newly allocated objects have <code>isMarked = false</code> but are clearly live objects. Therefore, we need another bit.</p>
<p>In fact, there are other good reasons that we need to support checking if a cell contains a live object or not. A canonical example is the conservative stack scanning: JSC cannot precisely understand the layout of the stack, so it needs to treat everything on the stack that could be pointers and pointing to live objects as GC root, and this involves checking if a heap pointer points to a live object or not.</p>
<p>One can easily imagine some kind of <code>isLive</code> bit that is <code>true</code> for all live objects, which is only flipped to <code>false</code> by GC when the object is dead. However, JSC employed a slightly different scheme, which is needed to facilitate optimizations that we will mention later.</p>
<p>As you have seen earlier, the bit used by JSC is called <code>isNew</code>.</p>
<p><a name="purposeOfIsNewBit"></a>However, keep in mind: you should <strong>not</strong> think of <code>isNew</code> as a bit that tells you <strong>anything</strong> related to its name, or indicates anything by itself. You should think of it as a helper bit, which sole purpose is that, when working togther with <code>isMarked</code>, they tell you if a cell contains a live object or not. This thinking mode will be more important in the next section when we introduce logical versioning.</p>
<p>The core invariant around <code>isNew</code> and <code>isMarked</code> is:</p>
<ol>
<li>At <strong>any</strong> moment, an object is dead iff its <code>isNew = false</code> and <code>isMarked = false</code>.</li>
</ol>
<p>If we were a stop-the-world GC, then to maintain this invariant, we only need the following:</p>
<ol>
<li>When an object is born, it has <code>isNew = true</code> and <code>isMarked = false</code>.</li>
<li>At the end of each eden or full GC cycle, we set <code>isNew</code> of all objects to <code>false</code>.</li>
</ol>
<p>Then, all newly-allocated objects are live because its <code>isNew</code> is <code>true</code>. At the end of each GC cycle, an object is live iff its <code>isMarked</code> is <code>true</code>, so after we set <code>isNew</code> to <code>false</code> (due to rule 2), the invariant on dead object is maintained, as desired.</p>
<p>However, in an incremental GC, since the state of a partially-run GC cycle can be exposed to mutator, we need to be careful that the invariant holds in this case as well.</p>
<p>Specifically, in full GC, we reset all <code>isMarked</code> to <code>false</code> at the beginning. Then, during a partially-run GC cycle, the mutator may see a live object with both <code>isMarked = false</code> (beacuse it has not been marked by GC yet), and <code>isNew = false</code> (because it has survived one prior GC cycle). This violates our invariant.</p>
<p>To fix this, at the beginning of a full GC, we additionally do <code>isNew |= isMarked</code> before clearing <code>isMarked</code>. Now, during the whole full GC cycle, all live objects must have <code>isNew = true</code><sup class="footnote-ref"><a href="#fn18" id="fnref18">[18]</a></sup>, so our invariant is maintained. At the end of the cycle, all <code>isNew</code> bits are cleared, and as a result, all the unmarked objects become dead, so our invariant is still maintained as desired. So let’s update our pseudo-code:</p>
<p>Eden GC preparation phase: no work is needed.</p>
<p>Full GC preparation phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Do 'isNew |= isMarked, isMarked = false' for all </span></span><br><span class="line"><span class="comment">// PreciseAllocation and all cells in CompleteSubspace</span></span><br><span class="line"><span class="keyword">for</span> (PreciseAllocation* pa : allPreciseAllocations) &#123;</span><br><span class="line">  pa-&gt;isNew |= pa-&gt;isMarked;</span><br><span class="line">  pa-&gt;isMarked = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (BlockFooter* block : allCompleteSubspaceBlocks) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> cellId = <span class="number">0</span>; cellId &lt; block-&gt;numCells; cellId++) &#123;</span><br><span class="line">    block-&gt;isNew[cellId] |= block-&gt;isMarked[cellId];</span><br><span class="line">    block-&gt;isMarked[cellId] = <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Eden/Full GC collection phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Update 'isNew = false' for CompleteSubspace cells </span></span><br><span class="line"><span class="keyword">for</span> (BlockFooter* block : allCompleteSubspaceBlocks) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> cellId = <span class="number">0</span>; cellId &lt; block-&gt;numCells; cellId++) &#123;</span><br><span class="line">    block-&gt;isNew[cellId] = <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// For PreciseAllocation, in addition to updating 'isNew = false',</span></span><br><span class="line"><span class="comment">// we also need to free the dead objects</span></span><br><span class="line"><span class="keyword">for</span> (PreciseAllocation* pa : allPreciseAllocations) &#123;</span><br><span class="line">  pa-&gt;isNew = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">if</span> (!pa-&gt;isMarked) </span><br><span class="line">    <span class="built_in">free</span>(pa);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In <code>CompleteSubspace</code> allocator, to check if a cell in a block contains a live object (if not, then the cell is available for allocation):</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cellContainsLiveObject</span><span class="params">(BlockFooter* block, <span class="keyword">size_t</span> cellId)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> block-&gt;isMarked[cellId] || block-&gt;isNew[cellId];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Logical-Versioning-Do-Not-Sweep">Logical Versioning: Do Not Sweep!</h3>
<p>We are doing a lot of work at the beginning of a full GC cycle and at the end of any GC cycle, since we have to iterate through all the blocks in <code>CompleteSubspace</code> and update their <code>isMarked</code> and <code>isNew</code> bits. Despite that the bits in one block are clustered into bitvectors thus have good memory locality, this could still be an expensive operation, especially after we have a concurrent GC (as this stage cannot be made concurrent). So we want something better.</p>
<p>The optimization JSC employs is logical versioning. Instead of physically clearing all bits in all blocks for every GC cycle, we only bump a global “logical version”, indicating that all the bits are logically cleared (or updated). Only when we actually need to mark a cell in a block during the marking phase do we then physically clear (or update) the bitvectors in this block.</p>
<p>You may ask: why bother with logical versioning, if in the future we still have to update the bitvectors physically anyway? There are two good reasons:</p>
<ol>
<li>If all cells in a block are dead (either died out during this GC cycle<sup class="footnote-ref"><a href="#fn19" id="fnref19">[19]</a></sup>, or already dead before this GC cycle), then we will never mark anything in the block, so logical versioning enabled us to avoid the work altogether. This also implies that at the end of each GC cycle, it’s unnecessary to figure out which blocks become completely empty, as logical versioning makes sure that these empty blocks will not cause overhead to future GC cycles.</li>
<li>The marking phase can be done concurrently with multiple threads <em>and</em> while the mutator thread is running (our scheme isn’t concurrent now, but we will do it soon), while the preparation / collection phase must be performed single-threadedly <em>and</em> with the mutator stopped. Therefore, shifting the work to marking phase reduces GC latency in a concurrent setting.</li>
</ol>
<p>There are two global version number <code>g_markVersion</code> and <code>g_newVersion</code><sup class="footnote-ref"><a href="#fn20" id="fnref20">[20]</a></sup>. Each block footer also stores its local version number <code>l_markVersion</code> and <code>l_newVersion</code>.</p>
<p>Let’s start with the easier case: the logical versioning for the <code>isNew</code> bit.</p>
<p>If you revisit the pseudo-code above, in GC there is only one place where we write <code>isNew</code>: at the end of each GC cycle, we set all the <code>isNew</code> bits to <code>false</code>. Therefore, we simply <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedSpace.cpp.html#446">bump</a> <code>g_newVersion</code> there instead. A local version <code>l_newVersion</code> smaller than <code>g_newVersion</code> means that all the <code>isNew</code> bits in this block have been logically cleared to <code>false</code>.</p>
<p>When the <code>CompleteSubspace</code> allocator allocates a new object, it needs to start with <code>isNew = true</code>. One can clearly do this directly, but JSC did it in a trickier way that involves a block-level bit named <code>allocated</code> for slightly better performance. This is not too interesting, so I deferred it to <a href="#isNewAndAllocateBit">the end of the post</a>, and our scheme described here right now will not employ this optimization (but is otherwise intentionally kept semantically equivalent as JSC):</p>
<ol>
<li>When a <code>BlockDirectory</code> starts allocating from a new block, it update the the block’s <code>l_newVersion</code> to <code>g_newVersion</code>, and set <code>isNew</code> to <code>true</code> for all already-allocated cells (as the block may not be fully empty), and <code>false</code> for all available cells.</li>
<li>Whenever it allocates a cell, it sets its <code>isNew</code> to true.</li>
</ol>
<p>Why do we want to bother setting <code>isNew</code> to <code>true</code> for all already-allocated cells in the block? This is to provide a good property. Since we bump <code>g_newVersion</code> at the end of every GC cycle, due to the scheme above, for any block with latest <code>l_newVersion</code>, a cell is live if and only if its <code>isNew</code> bit is set. Now, when checking if a cell is live, if its <code>l_newVersion</code> is latest, then we can just return <code>isNew</code> without looking at <code>isMarked</code>, so our logic is simpler.</p>
<p>The logical versioning for the <code>isMarked</code> bit is similar. At the beginning of a full GC cycle, we bump the <code>g_markVersion</code> to indicate that all mark bits are logically cleared. Note that the global version is not bumped for eden GC, since eden GC does not clear <code>isMark</code> bits.</p>
<p>There is one extra complexity: the above scheme would break down in incremental GC. Specifically, <em>during</em> a full GC cycle, we have logically cleared the <code>isMarked</code> bit, but we also didn’t do anything to the <code>isNew</code> bit, so all cells in the old space would appear dead to the allocator. In our old scheme without logical versioning, this case is prevented by doing <code>isNew |= isMarked</code> at the start of the full GC, but we cannot do it now with logical versioning.</p>
<p>JSC solves this problem with the following clever trick: <em>during</em> a full GC, we should also accept <code>l_markVersion</code> that is off-by-one. In that case, we know the <code>isMarked</code> bit accurately reflect whether or not a cell is live, since that is the result of the last GC cycle. If you are a bit confused, take a look at footnote<sup class="footnote-ref"><a href="#fn21" id="fnref21">[21]</a></sup> for a more elaborated case discussion. It might also help to take a look at the comments in the pseudo-code below:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cellContainsLiveObject</span><span class="params">(BlockFooter* block, <span class="keyword">size_t</span> cellId)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (block-&gt;l_newVersion == g_newVersion) &#123;</span><br><span class="line">    <span class="comment">// A latest l_newVersion indicates that the cell is live if</span></span><br><span class="line">    <span class="comment">// and only if its 'isNew' bit is set, so we don't need to</span></span><br><span class="line">    <span class="comment">// look at the 'isMarked' bit even if 'isNew' is false</span></span><br><span class="line">    <span class="keyword">return</span> block-&gt;isNew[cellId];</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Now we know isNew bit is logically false, so we should</span></span><br><span class="line">  <span class="comment">// look at the isMarked bit to determine if the object is live</span></span><br><span class="line">  <span class="keyword">if</span> (isMarkBitLogicallyCleared(block)) &#123;</span><br><span class="line">    <span class="comment">// The isMarked bit is logically false</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="comment">// The isMarked bit is valid and accurately tells us if </span></span><br><span class="line">  <span class="comment">// the object is live or not</span></span><br><span class="line">  <span class="keyword">return</span> block-&gt;isMarked[cellId];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Return true if the isMarked bitvector is logically cleared</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isMarkBitLogicallyCleared</span><span class="params">(BlockFooter* block)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (block-&gt;l_markVersion == g_markVersion) &#123;</span><br><span class="line">    <span class="comment">// The mark version is up-to-date, so not cleared</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (IsFullGcRunning() &amp;&amp; IsGcInMarkingPhase() &amp;&amp; </span><br><span class="line">      block-&gt;l_markVersion == g_markVersion - <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="comment">// We are halfway inside a full GC cycle's marking phase,</span></span><br><span class="line">    <span class="comment">// and the mark version is off-by-one, so the isMarked bit</span></span><br><span class="line">    <span class="comment">// should be accepted, and it accurately tells us if the </span></span><br><span class="line">    <span class="comment">// object is live or not</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Before we mark an object in <code>CompleteSubspace</code>, we need to update the <code>l_markVersion</code> of the block holding the cell to latest, and materialize the <code>isMarked</code> bits of all cells in the block. That is, we need to run the logic at the full GC preparation phase in our old scheme: <code>isNew |= isMarked</code>, <code>isMarked = false</code> for all cells in the block. This is shown below.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Used by GC marking phase to mark an object in CompleteSubspace</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">markObject</span><span class="params">(BlockFooter* block, <span class="keyword">size_t</span> cellId)</span> </span>&#123;</span><br><span class="line">  aboutToMark(block);</span><br><span class="line">  block-&gt;isMarked[cellId] = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Materialize 'isMarked' bits if needed</span></span><br><span class="line"><span class="comment">// To do this, we need to execute the operation at full GC </span></span><br><span class="line"><span class="comment">// prepare phase: isNew |= isMarked, isMarked = false</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aboutToMark</span><span class="params">(BlockFooter* block)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (block-&gt;l_markVersion == g_markVersion) &#123;</span><br><span class="line">    <span class="comment">// Our mark version is already up-to-date,</span></span><br><span class="line">    <span class="comment">// which means it has been materialized before</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Check if the isMarked bit is logically cleared to false.</span></span><br><span class="line">  <span class="comment">// The function is defined in the previous snippet.</span></span><br><span class="line">  <span class="keyword">if</span> (isMarkBitLogicallyCleared(block)) &#123;</span><br><span class="line">    <span class="comment">// This means that the isMarked bitvector should </span></span><br><span class="line">    <span class="comment">// be treated as all false. So operation isNew |= isMarked </span></span><br><span class="line">    <span class="comment">// is no-op, so all we need to do is isMarked = false</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> cellId = <span class="number">0</span>; cellId &lt; block-&gt;numCells; cellId++) &#123;</span><br><span class="line">      block-&gt;isMarked[cellId] = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// The 'isMarked' bit is not logically cleared. Now let's </span></span><br><span class="line">    <span class="comment">// check if the 'isNew' bit is logically cleared.</span></span><br><span class="line">    <span class="keyword">if</span> (block-&gt;l_newVersion &lt; g_newVersion) &#123;</span><br><span class="line">      <span class="comment">// The isNew bitvector is logically cleared and should be </span></span><br><span class="line">      <span class="comment">// treated as false. So operation isNew |= isMarked becomes</span></span><br><span class="line">      <span class="comment">// isNew = isMarked (note that executing |= is incorrect </span></span><br><span class="line">      <span class="comment">// beacuse isNew could physically contain true!)</span></span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">size_t</span> cellId = <span class="number">0</span>; cellId &lt; block-&gt;numCells; cellId++) &#123;</span><br><span class="line">        block-&gt;isNew[cellId] = block-&gt;isMarked[cellId];</span><br><span class="line">        block-&gt;isMarked[cellId] = <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// We materialized isNew, so update it to latest version</span></span><br><span class="line">      block-&gt;l_newVersion = g_newVersion;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">      <span class="comment">// The l_newVersion is latest, which means that the cell is </span></span><br><span class="line">      <span class="comment">// live if and only if its isNew bit is set. </span></span><br><span class="line">      <span class="comment">// Since isNew already reflects liveness, we do not have to</span></span><br><span class="line">      <span class="comment">// perform the operation isNew |= isMarked (and in fact, it </span></span><br><span class="line">      <span class="comment">// must be a no-op since no dead cell can have isMarked = </span></span><br><span class="line">      <span class="comment">// true). So we only need to do isMarked = false</span></span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">size_t</span> cellId = <span class="number">0</span>; cellId &lt; block-&gt;numCells; cellId++) &#123;</span><br><span class="line">        block-&gt;isMarked[cellId] = <span class="literal">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// We finished materializing isMarked, so update the version</span></span><br><span class="line">  block-&gt;l_markVersion = g_markVersion;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>A fun fact: despite that what we conceptually want to do above is <code>isNew |= isMarked</code>, the above code never performs a <code>|=</code> at all :)</p>
<p>And also, let’s update the pseudo-code for relavent GC logic:</p>
<p>Eden GC preparation phase: no work is needed.</p>
<p>Full GC preparation phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// For PreciseAllocation, we still need to manually do </span></span><br><span class="line"><span class="comment">// 'isNew |= isMarked, isMarked = false' for every allocation</span></span><br><span class="line"><span class="keyword">for</span> (PreciseAllocation* pa : allPreciseAllocations) &#123;</span><br><span class="line">  pa-&gt;isNew |= pa-&gt;isMarked;</span><br><span class="line">  pa-&gt;isMarked = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// For CompleteSubspace, all we need to do is bumping the </span></span><br><span class="line"><span class="comment">// global version for 'isMarked' bit</span></span><br><span class="line">g_markVersion++;</span><br></pre></td></tr></table></figure>
<p>Eden/Full GC collection phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// For PreciseAllocation, we still need to manually </span></span><br><span class="line"><span class="comment">// update 'isNew = false' for each allocation, and also</span></span><br><span class="line"><span class="comment">// free the object if it is dead</span></span><br><span class="line"><span class="keyword">for</span> (PreciseAllocation* pa : allPreciseAllocations) &#123;</span><br><span class="line">  pa-&gt;isNew = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">if</span> (!pa-&gt;isMarked) </span><br><span class="line">    <span class="built_in">free</span>(pa);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// For CompleteSubspace, all we need to do is bumping the</span></span><br><span class="line"><span class="comment">// global version for 'isNew' bit</span></span><br><span class="line">g_newVersion++;</span><br></pre></td></tr></table></figure>
<p>With logical versioning, GC no longer sweeps the <code>CompleteSubspace</code> blocks to reclaim dead objects: the reclamation happens lazily, when the allocator starts to allocate from the block. This, however, introduces an unwanted side-effect. Some objects use manual memory management internally: they own additional memory that are not managed by GC, and have C++ destructors to free those memory when the object is dead. This improves performance as it reduces the work of GC. However, now we do not immediately sweep dead objects and run destructor, so the memory that are supposed to be freed by the destructor could be kept around indefinitely longer, if the block is never allocated from. To mitigate this issue, JSC will also periodically sweep the blocks and run the destructors of the dead objects. This is <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/IncrementalSweeper.h.html#JSC::IncrementalSweeper">implemented</a> by <code>IncrementalSweeper</code>, but we will not go into details.</p>
<p>To conclude, logical versioning provided two important optimizations to the GC scheme:</p>
<ol>
<li>The so-called “sweep” phase of the GC (to find out and reclaim dead objects) is removed for <code>CompleteSubspace</code> objects. The reclamation is done lazily. This is clearly better than sweeping through the block again and again in every GC cycle.</li>
<li>The full GC does not need to reset all <code>isMarked</code> bit in the preparation phase, but only lazily reset them in the marking phase by <code>aboutToMark</code>: this not only reduces work, but also allows the work to be done parallelized and while the mutator is running, after we make our GC scheme concurrent.</li>
</ol>
<h3 id="Optimizing-WriteBarrier-The-cellState-Bit">Optimizing WriteBarrier: The cellState Bit</h3>
<p>As we have explained earlier, whenever the mutator modified a pointer of a marked object <code>o</code> to point to an unmarked object, it needs to add <code>o</code> to the “remembered set”, and this is called the <code>WriteBarrier</code>. In this section, we will dig a bit deeper into the <code>WriteBarrier</code> and explain the optimizations around it.</p>
<p>The first problem with our current <code>WriteBarrier</code> is that the <code>isMarked</code> bit resides in the block footer, so retrieving its value requires quite a few computations from the object pointer. Also it doesn’t sit in the same CPU cache line as the object, which makes the access even slower. This is undesirable as the cost is paid for every <code>WriteBarrier</code>, no matter if we actually added the object to remembered set in the end or not.</p>
<p>The second problem is, our <code>WriteBarrier</code> will repeatedly add the same object <code>o</code> to the remembered set every time it is run. The obvious solution is to make <code>rememberedSet</code> a hash set to de-duplicate the objects it contains, but doing a hash lookup to check if the object already exists is still too expensive.</p>
<p>This is where the last metadata bit that we haven’t explained yet: the <code>cellState</code> bit comes in, which solves both problems.</p>
<p>Instead of making <code>rememberedSet</code> a hash table, we reserve a byte (though we only use 1 bit of it) named <code>cellState</code> in every object’s object header, to indicate if we might need to put the object into the remembered set in a <code>WriteBarrier</code>. Since this bit resides in the object header as an object field (instead of in the block footer), it’s trivially accessible to the mutator who has the object pointer.</p>
<p><code>cellState</code> has two possible values: <code>black</code> and <code>white</code>. The most important two invariants around <code>cellState</code> are the following:</p>
<ol>
<li>For any object with <code>cellState = white</code>, it is guaranteed that the object does not need to be added to remembered set.</li>
<li>Unless <em>during</em> a full GC cycle, all <code>black</code> (live) objects have <code>isMarked = true</code>.</li>
</ol>
<p>Invariant 1 serves as a fast-path: <code>WriteBarrier</code> can return immediately if our object is <code>white</code>, and checking it only requires one load instruction (to load <code>cellState</code>) and one comparison instruction to validate it is <code>white</code>.</p>
<p>However, if the object is <code>black</code>, a slow-path is needed to check whether it is actually needed to add the object to remembered set.</p>
<p>Let’s look at our new <code>WriteBarrier</code>:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Executed after writing a pointer to 'dst' into a field of 'obj'</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">WriteBarrier</span><span class="params">(JSCell* obj)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (obj-&gt;cellState == black) </span><br><span class="line">    WriteBarrierSlowPath(obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The first thing to notice is that the <code>WriteBarrier</code> is no longer checking if <code>dst</code> (the object that the pointer points to) is marked or not. Clearly this does not affect the correctness: we are just making the criteria less restrictive. However, it is unclear to me if we can improve performance while maintaining correctness by making some kind of check on <code>dst</code> as well, like the original <code>WriteBarrier</code> did.</p>
<p>I wasn’t able to get a definite answer on this even from JSC developer. They have two <em>conjectures</em> on why they are doing this: first, by not checking <code>dst</code>, more objects are put into the remembered set and need to be scanned by GC, so the total amount of work increased. However, the mutator’s work probably decreased, as it does less checks and touches less cache lines (by not touching the outlined <code>isMarked</code> bit). Of course, the benefit is offsetted by that the mutator is adding more objects into the remembered set, but this isn’t too expensive either, as the remembered set is only a segmented vector. GC has to do more work, as it needs to scan and mark more objects. However, after we make our scheme concurrent, the marking phase of GC can be done concurrently as the mutator is running, so the latency is probably<sup class="footnote-ref"><a href="#fn22" id="fnref22">[22]</a></sup> hidden. Second, JSC’s DFG compiler has <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/dfg/DFGStoreBarrierInsertionPhase.cpp.html">optimization pass</a> that coalesces barriers on the same object together, and the barrier emitted this way naturally cannot check <code>dst</code>. Therefore, to make things easier, they simply made all the barriers to not check <code>dst</code>. Although these are all conjectures, and it is unclear if adding back the <code>dst</code> check can improve performance, this is how JSC works, so let’s stick to it.</p>
<p>The interesting part is how the invariants above are maintained by the relavent parties. As always, there are three actors: the mutator (<code>WriteBarrier</code>), the allocator, and the GC.</p>
<p>The interaction with the allocator is the simplest. All objects are born <code>white</code>. This is correct because newly-born objects are not marked, so have no reason to be remembered.</p>
<p>The interaction with GC is during the GC marking phase:</p>
<ol>
<li>When we mark an object and push it into the queue, we set its <code>cellState</code> to <code>white</code>.</li>
<li>When we pop an object from the queue, before we start to scan its children, we set its <code>cellState</code> to <code>black</code>.</li>
</ol>
<p>In pseudo-code, the Eden/Full GC marking phase now looks like the following (Line 5 and Line 9 are the newly-added logic to handle <code>cellState</code>, other lines unchanged):</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!<span class="built_in">queue</span>.empty() || !rmbSet.empty()) &#123;</span><br><span class="line">  <span class="comment">// Both eden GC and full GC needs to consider remembered set</span></span><br><span class="line">  <span class="comment">// Prioritize popping from queue, pop remembered set last</span></span><br><span class="line">  JSCell* obj = !<span class="built_in">queue</span>.empty() ? <span class="built_in">queue</span>.pop() : rmbSet.pop();</span><br><span class="line">  obj-&gt;cellState = black;       <span class="comment">// &lt;----------------- newly added</span></span><br><span class="line">  obj-&gt;ForEachChild([&amp;](JSCell* child) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!child-&gt;isMarked) &#123;   </span><br><span class="line">      markObject(child);</span><br><span class="line">      child-&gt;cellState = white; <span class="comment">// &lt;----------------- newly added</span></span><br><span class="line">      <span class="built_in">queue</span>.push(child);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Let’s argue why the invariant is maintained by the above code.</p>
<ol>
<li>For invariant 1, note that in the above code, an object is <code>white</code> only if it is inside the queue (as once it’s popped out, it becomes <code>black</code> again), pending scanning of its children. Therefore, it is guaranteed that the object will still be scanned by the GC later, so we don’t need to add the object to remembered set, as desired.</li>
<li>For invariant 2, at the end of any GC cycle, any live object is marked, which means it has been scanned, so it is <code>black</code>, as desired.</li>
</ol>
<p>Now let’s look at what <code>WriteBarrierSlowPath</code> should do. Clearly, it’s correct if it simply unconditionally add the object to remembered set, but that also defeats most of the purpose of <code>cellState</code> as an optimization mechanism: we want something better.</p>
<p>A top business of <code>cellState</code> is to prevent adding an object into the remembered set if it is already there. Therefore, after we put the object into the remembered set, we will set its <code>cellState</code> to <code>white</code>, like shown below.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">WriteBarrierSlowPath</span><span class="params">(JSCell* obj)</span> </span>&#123; </span><br><span class="line">  obj-&gt;cellState = white;</span><br><span class="line">  addToRememberedSet(obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Let’s prove why the above code works. Once we added an object to remembered set, we set it to <code>white</code>. We don’t need to add the same object into the remembered set until it gets popped out from the set by GC. But when GC pops out the object, it would set its <code>cellState</code> back to <code>black</code>, so we are good.</p>
<p>JSC employed one more optimization. During a full GC, we might see <code>black</code> objects that has <code>isMarked = false</code> (note that this is the only possible case that the object is unmarked, due to invariant 2). In this case, it’s unnecessary to add the object to remembered set, since the object will eventually be scanned in the future (or it becomes dead some time later before it was scanned, in which case we are good as well). Furthermore, we can flip it back to <code>white</code>, so we don’t have to go into this slow path the next time a <code>WriteBarrier</code> on this object runs. To sum up, the optimized version is as below:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">WriteBarrierSlowPath</span><span class="params">(JSCell* obj)</span> </span>&#123; </span><br><span class="line">  <span class="keyword">if</span> (IsFullGcRunning()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isMarked(obj)) &#123;</span><br><span class="line">      <span class="comment">// Do not add the object to remembered set</span></span><br><span class="line">      <span class="comment">// In addition, set cellState to white so this </span></span><br><span class="line">      <span class="comment">// slow path is not triggered on the next run</span></span><br><span class="line">      obj-&gt;cellState = white;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    assert(isMarked(obj));    <span class="comment">// due to invariant 2</span></span><br><span class="line">  &#125;</span><br><span class="line">  obj-&gt;cellState = white;</span><br><span class="line">  addToRememberedSet(obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Getting-Concurrent-and-Getting-Wild">Getting Concurrent and Getting Wild</h3>
<p>At this point, we already have a very good incremental and generational garbage collector: the mutator, allocator and GC all have their respective fast-paths for the common cases, and with logical versioning, we avoided redundant work as much as possible. In my humble opinion, this is a good balance point between performance and engineering complexity.</p>
<p>However, obviously, “engineering complexity” is not a word inside JSC’s dictionary: after all, they have the most talented engineers, to the point that they even <a href="https://webkit.org/blog/5852/introducing-the-b3-jit-compiler/" target="_blank" rel="noopener">engineered their own purpose-built LLVM from scratch</a>!</p>
<p>To squeeze out every bit of performance, JSC proceeded to make the GC scheme concurrent. However, due to the nature of GC, it’s often infeasible to use locks to protect against race conditions for performance reasons, so extensive lock-free programming is employed.</p>
<p>But once lock-free programming is involved, one starts to get into all sorts of architecture-dependent memory reordering problems. x86-64 is the more sane architecture: it only requires <code>StoreLoadFence()</code>, and it provides somewhat-TSO-like semantics, but JSC also needs ARM64 support for their Apple Sillicon devices. ARM64 has even fewer guarantees: load-load, load-store, store-load, and store-store can all be reordered by the CPU, so any innocent operation could actually need a fence. As if things were not bad enough, for performance reasons, JSC does not want to use too many memory fences on ARM64. So they have the so-called <code>Dependency</code> <a href="https://sillycross.github.io/r/WebKit/Source/WTF/wtf/Atomics.h.html#_ZN3WTF10DependencyC1Ev">class</a>, which creates an implicit CPU data dependency on ARM64 through some scary assembly hacks, so they can get the desired memory ordering for a specific data-flow without paying the cost of a memory fence. As you can imagine, with all of these complications and optimizations, the code can easily become horrifying.</p>
<p>So due to my limited expertise, it’s unsurprising if I missed to explain or mis-explained some important race conditions in the code, especially some ARM64-specific ones: if you spotted any issue in this post, please definitely let me know.</p>
<p>Let’s go through the concurrency assumptions first. Javascript is a single-threaded language, so there is always only one mutator thread<sup class="footnote-ref"><a href="#fn23" id="fnref23">[23]</a></sup>. Apart from the mutator thread, JSC has a bunch of compilation threads, a GC thread, and a bunch of marking threads. Only the GC marking phase is concurrent: during which the mutator thread, the compiler threads, and a bunch of marking threads are concurrently running (yes, the marking itself is also done in parallel). However, all the other GC phases are run with the mutator thread and compilation threads stopped.</p>
<h4 id="Some-Less-Interesting-Issues">Some Less Interesting Issues</h4>
<p>First of all, clearly the <code>isMarked</code> and <code>isNew</code> bitvector must be made safe for concurrent access, since multiple threads (including marking threads and mutator) may concurrently update it. Using CAS with appropriate retry/bail mechanism is enough for the bitvector itself.</p>
<p><code>BlockFooter</code> is harder, and needs to be protected with a lock: multiple threads could be simutanuously calling <code>aboutToMark()</code>, so <code>aboutToMark()</code> must be guarded. For the reader side (the <code>isMarked()</code> function, which involves first checking if <code>l_markVersion</code> is latest, then reading the <code>isMarked</code> bitvector), in x86-64 thanks to x86-TSO, one does not need a lock or any memory fence (as long as <code>aboutToMark</code> takes care to update <code>l_markVersion</code> after the bitvector). In ARM64, since load-load reordering is allowed, a <code>Dependency</code> is required.</p>
<p>Making the <code>cellContainsLiveObject</code> (or in JSC jargon, <code>isLive</code>) check lock-free is harder, since it involves potentially reading both the <code>isMarked</code> bit and the <code>isNew</code> bit. JSC <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlockInlines.h.html#_ZN3JSC11MarkedBlock6Handle6isLiveEjjbPKNS_8HeapCellE">employs optimistic locking</a> to provide a fast-path. This is not very different from an optimistic locking scheme you can find in a textbook, so I won’t dive into the details.</p>
<p>Of course, there are a lot more subtle issues to change. Almost all the pseudo-code above needs to be adapted for concurrency, either by using a lock or CAS, or by using some sort of memory barriers and concurrency protocol to ensure that the code works correctly under concurrency settings. But now let’s turn to some more important and tricky issues.</p>
<h4 id="The-Race-Between-WriteBarrier-and-Marking">The Race Between WriteBarrier and Marking</h4>
<p>One of the most important race is the race between <code>WriteBarrier</code> and GC’s marking threads. The marking threads and the mutator thread can access the <code>cellState</code> of an object concurrently. For performance reasons, a lock is infeasible, so race condition arises.</p>
<p>It’s important to note that we call <code>WriteBarrier</code> <strong>after</strong> we have written the pointer into the object. This is not only more convenient to use (especially for JIT-generated code), but also allows a few optimizations: for example, <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/dfg/DFGStoreBarrierInsertionPhase.cpp.html">in certain cases</a>, multiple writes to the same object may only call <code>WriteBarrier</code> once at the end.</p>
<p>With this in mind, let’s analyze why our current implementation is buggy. Suppose <code>o</code> is an object, and the mutator wants to store a pointer to another object <code>target</code> into a field <code>f</code> of <code>o</code>. The marking logic of GC wants to scan <code>o</code> and append its children into the queue. We need to make sure that GC will observe the <code>o -&gt; target</code> pointer link.</p>
<p>Let’s first look at the correct logic:</p>
<div>
<div style="float:left; width:50%; border-right: solid 1px; border-bottom: solid 1px; background-color:#FFCB9A">
<div style="margin-left:10px; ">
Mutator (WriteBarrier)
</div>
</div>
<div style="float:left; width:50%; border-bottom: solid 1px; background-color:#A8B545">
<div style="margin-left:10px;">
GC (Marker) 
</div>
</div>
</div>
<div>
<div style="float:left; width:50%; border-right: solid 1px;">
<div style="margin-left:10px; ">
Store(o.f, target)<br>
StoreLoadFence()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// WriteBarrier begin<br>                               
t1 = Load(o.cellState)<br>
if (t1 == black): WriteBarrierSlowPath(o)
</div>
</div>
<div style="float:left; width:50%;">
<div style="margin-left:10px;">
Store(o.cellState, black)<br>
StoreLoadFence()<br>
t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// Load a children of o<br>
Do some check to t2 and push it to queue<br>
</div>
</div>
</div>
<div style="display: table; clear: both;"</div>
<br>
<p>This is mostly just a copy of the pseudocode in the above sections, except that we have two <code>StoreLoadFence()</code>. A <code>StoreLoadFence()</code> guarantees that no <code>LOAD</code> after the fence may be executed by the CPU out-of-order engine until all <code>STORE</code> before the fence have completed. Let’s first analyze what could go wrong without either of the fences.</p>
<p>Just to make things perfectly clear, the precondition is <code>o.cellState = white</code> (because <code>o</code> is in the GC’s queue) and <code>o.f = someOldValue</code>.</p>
<p>What could go wrong if the mutator <code>WriteBarrier</code> doesn’t have the fence? Without the fence, the CPU can execute the <code>LOAD</code> in line 3 before the <code>STORE</code> in line 1. Then, in the following interleaving:</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = white</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = some old value</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
</ol>
<p>Now, the mutator did not add <code>o</code> to remembered set (because <code>t1</code> is <code>white</code>, not <code>black</code>), and <code>t2</code> in GC is the old value in <code>o.f</code> instead of <code>target</code>, so GC did not push <code>target</code> into the queue. So the pointer link from <code>o</code> to <code>target</code> is missed in GC. This can result in <code>target</code> being wrongly reclaimed despite it is live.</p>
<p>And what could go wrong if the GC marking logic doesn’t have the fence? Similarly, without the fence, the CPU can execute the <code>LOAD</code> in line 3 before the <code>STORE</code> in line 1. Then, in the following interleaving:</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = some old value</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = white</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
</ol>
<p>Similar to above, mutator sees <code>t1 = white</code> and GC sees <code>t2 = oldValue</code>. So <code>o</code> is not added to remembered set, and <code>target</code> is not pushed into the queue, the pointer link is missed.</p>
<p>Finally, let’s analyze why the code behaves correctly if both fences are present. Unfortunately there is not a better way than manually enumerating all the interleavings. Thanks to the fences, <code>Mutator Line 1</code> must execute before <code>Mutator Line 3</code>, and <code>GC Line 1</code> must execute before <code>GC Line 3</code>, but the four lines can otherwise be reordered arbitrarily. So there are <code>4! / 2! / 2! = 6</code> possible interleavings. So let’s go!</p>
<p>Interleaving 1:</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = white</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = target</div>
</li>
</ol>
<p>In this interleaving, the mutator did not add <code>o</code> to remembered set, but the GC sees <code>target</code>, so it’s fine.</p>
<p>Interleaving 2:</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = some old value</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = black</div>
</li>
</ol>
<p>In this interleaving, GC saw the old value, but the mutator added <code>o</code> to the remembered set, so GC will eventually drain from the remembered set and scan <code>o</code> again, at which time it will see the correct new value <code>target</code>, so it’s fine.</p>
<p>Interleaving 3:</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = black</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = target</div>
</li>
</ol>
<p>In this interleaving, GC saw the new value <code>target</code>, nevertheless, the mutator saw <code>t1 = black</code> and added <code>o</code> to the remembered set. This is unfortunate since GC will scan <code>o</code> again, but it doesn’t affect correctness.</p>
<p>Interleaving 4:</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = target</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = black</div>
</li>
</ol>
<p>Same as Interleaving 3.</p>
<p>Interleaving 5:</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] store(o.f, target)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = black</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = target</div>
</li>
</ol>
<p>Same as Interleaving 3.</p>
<p>Interleaving 6:</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Line 1] Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 1] Store(o.f, target)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Line 3] t2 = Load(o.f)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t2 = target</div>
</li>
<li>
<div style="background-color:#FFCB9A">[Mutator Line 3] t1 = Load(o.cellState)&nbsp;&nbsp;&nbsp;&nbsp;// t1 = black</div>
</li>
</ol>
<p>Same as Interleaving 3.</p>
<p>This proves that with the two <code>StoreLoadFence()</code>, our code is no longer vulnerable to the above race condition.</p>
<h4 id="Another-Race-Condition-Between-WriteBarrier-and-Marking">Another Race Condition Between WriteBarrier and Marking</h4>
<p>The above fix alone is not enough: there is another race between <code>WriteBarrier</code> and GC marking threads. Recall that in <code>WriteBarrierSlowPath</code>, we attempt to flip the object back to <code>white</code> if we saw it is not marked (this may happen during a full GC), as illustrated below:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">... omitted ...</span><br><span class="line"><span class="keyword">if</span> (!isMarked(obj)) &#123;</span><br><span class="line">  obj-&gt;cellState = white;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">... omitted ...</span><br></pre></td></tr></table></figure>
<p>It turns out that, after setting the object <code>white</code>, we need to do a <code>StoreLoadFence()</code>, and check again if the object is marked. If it becomes marked, we need to set <code>obj-&gt;cellState</code> back to <code>black</code>.</p>
<p>Without the fix, the code is vulnerable to the following race:</p>
<ol>
<li>[Precondition] <code>o.cellState = black</code> and <code>o.isMarked = false</code></li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Check isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// see false</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>[Postcondition] <code>o.cellState = white</code> and <code>o.isMarked = true</code></li>
</ol>
<p>The post-condition is bad because <code>o</code> will not be added to the remembered set in the future, despite that it needs to be (as the GC has already scanned it).</p>
<p>Let’s now prove why the code is correct when the fix is applied. Now the <code>WriteBarrier</code> logic looks like this:</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)</div>
</li>
</ol>
<p>Note that we omitted the first “Check isMarked()” line because it must be the first thing executed in the interleaving, as otherwise the <code>if</code>-check won’t pass at all.</p>
<p>The three lines in <code>WriteBarrier</code> cannot be reordered by CPU: Line 1-2 cannot be reordered because of the <code>StoreLoadFence()</code>, line 2-3 cannot be reordered since line 3 is a store that is only executed if line 2 is true. The two lines in GC cannot be reordered by CPU because line 2 stores to the same field <code>o.cellState</code> as line 1.</p>
<p>In addition, note that it’s fine if at the end of <code>WriteBarrier</code>, the object is <code>black</code> but GC has only executed to line 1: this is unfortunate, because the next <code>WriteBarrier</code> on this object will add the object to the remembered set despite it’s unnecessary. However, it does not affect our correctness. So now, let’s enumerate all the interleavings again!</p>
<p>Interleaving 1.</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = false</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// not executed</div>
</li>
</ol>
<p>Object is not marked and white, OK.</p>
<p>Interleaving 2.</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = false</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// not executed</div>
</li>
</ol>
<p>Object is in queue and white, OK.</p>
<p>Interleaving 3.</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is in queue and black, unfortunate but OK.</p>
<p>Interleaving 4.</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is in queue and black, unfortunate but OK.</p>
<p>Interleaving 5.</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = false</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// not executed</div>
</li>
</ol>
<p>Object is marked and black, OK.</p>
<p>Interleaving 6.</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is marked and black, OK.</p>
<p>Interleaving 7.</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is marked and black, OK.</p>
<p>Interleaving 8.</p>
<ol>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is marked and black, OK.</p>
<p>Interleaving 9.</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is marked and black, OK.</p>
<p>Interleaving 10.</p>
<ol>
<li>
<div style="background-color:#A8B545">[GC Marking] CAS(o.isMarked, true), Store(o.cellState, white), pushed 'o' into queue</div>
</li>
<li>
<div style="background-color:#A8B545">[GC Marking] Popped 'o' from queue, Store(o.cellState, black)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] Store(o.cellState, white)</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] t1 = isMarked()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// t1 = true</div>
</li>
<li>
<div style="background-color:#FFCB9A">[WriteBarrier] if (t1 == true): Store(o.cellState, black)&nbsp;&nbsp;&nbsp;// executed</div>
</li>
</ol>
<p>Object is marked and black, OK.</p>
<p>So let’s update our pseudo-code. However, I would like to note that, in JSC’s implementation, they did not use a <code>StoreLoadFence()</code> after <code>obj-&gt;cellState = white</code>. Instead, they made the <code>obj-&gt;cellState = white</code> a CAS from <code>black</code> to <code>white</code> (with memory ordering <code>memory_order_seq_cst</code>). This is stronger than a <code>StoreLoadFence()</code> so their logic is also correct. Nevertheless, just in case my analysis above missed some other race with other components, our pseudo-code will stick to their logic…</p>
<p>Mutator <code>WriteBarrier</code> pseudo-code:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">WriteBarrier</span><span class="params">(JSCell* obj)</span> </span>&#123;</span><br><span class="line">  StoreLoadFence();            <span class="comment">// Note the fence!</span></span><br><span class="line">  <span class="keyword">if</span> (obj-&gt;cellState == black) </span><br><span class="line">    WriteBarrierSlowPath(obj);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">WriteBarrierSlowPath</span><span class="params">(JSCell* obj)</span> </span>&#123; </span><br><span class="line">  <span class="keyword">if</span> (IsGcRunning()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isMarked(obj)) &#123;</span><br><span class="line">      <span class="keyword">if</span> (CompareAndSwap(</span><br><span class="line">         obj-&gt;cellState, black <span class="comment">/*from*/</span>, white <span class="comment">/*to*/</span>) == SUCCESS)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="keyword">if</span> (isMarked(obj)) &#123;</span><br><span class="line">          obj-&gt;cellState = black;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    assert(isMarked(obj));   </span><br><span class="line">  &#125;</span><br><span class="line">  obj-&gt;cellState = white;</span><br><span class="line">  <span class="comment">// Add 'obj' to remembered set</span></span><br><span class="line">  rmbSet.push(obj);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Eden/Full GC Marking phase:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!<span class="built_in">queue</span>.empty() || !rmbSet.empty()) &#123;</span><br><span class="line">  JSCell* obj = !<span class="built_in">queue</span>.empty() ? <span class="built_in">queue</span>.pop() : rmbSet.pop();</span><br><span class="line">  obj-&gt;cellState = black;       </span><br><span class="line">  StoreLoadFence();           <span class="comment">// Note the fence!</span></span><br><span class="line">  obj-&gt;ForEachChild([&amp;](JSCell* child) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!child-&gt;isMarked) &#123;   </span><br><span class="line">      markObject(child);</span><br><span class="line">      child-&gt;cellState = white; </span><br><span class="line">      <span class="built_in">queue</span>.push(child);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Remove-Unnecessary-Memory-Fence-In-WriteBarrier">Remove Unnecessary Memory Fence In WriteBarrier</h4>
<p>The <code>WriteBarrier</code> is now free of hazardous race conditions. However, we are executing a <code>StoreLoadFence()</code> for every <code>WriteBarrier</code>, which is a very expensive CPU instruction. Can we optimize it?</p>
<p>The idea is the following: the fence is used to protect against race with GC. Therefore, we definitely need the fence if the GC is concurrently running. However, the fence is unnecessary if the GC is not running. Therefore, we can check if the GC is running first, and only execute the fence if the GC is indeed running.</p>
<p>JSC is even smarter: instead of having two checks (one that checks if the GC is running and one that checks if the <code>cellState</code> is <code>black</code>), it combines them into a single check for the fast-path where the GC is not running and the object is <code>white</code>. The trick is the following:</p>
<ol>
<li>Assume <code>black = 0</code> and <code>white = 1</code> in the <code>cellState</code> enum.</li>
<li>Create a global variable called <code>blackThreshold</code>. This <code>blackThreshold</code> is normally <code>0</code>, but at the beginning of a GC cycle, it will be set to <code>1</code>, and it will be reset back to <code>0</code> at the end of the GC cycle.</li>
<li>Now, check if <code>obj-&gt;cellState &gt; blackThreshold</code>.</li>
</ol>
<p>Then, if the check succeeded, we know we can immediately return: the only case this check can succeed is when the GC is not running and we are <code>white</code> (because <code>blackThreshold = 0</code> and <code>cellState = 1</code> is the only situation to pass the check). This way, the fast path only executes one check. If the check fails, then we fallback to the slow path, which performs the full procedure: check if GC is running, execute a fence if needed, then check if <code>cellState</code> is <code>black</code> again. In pseudo-code:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">WriteBarrier</span><span class="params">(JSCell* obj)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (obj-&gt;cellState &gt; g_blackThreshold) &#123;</span><br><span class="line">    <span class="comment">// Fast-path: the only way to reach here is when</span></span><br><span class="line">    <span class="comment">// the GC is not running and the cellState is white</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!IsGcRunning()) &#123;</span><br><span class="line">    <span class="comment">// g_blackThreshold is 0, so our object is</span></span><br><span class="line">    <span class="comment">// actually black, we need to go to WriteBarrierSlowPath</span></span><br><span class="line">    WriteBarrierSlowPath(obj);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// GC is running so we need to execute the fence </span></span><br><span class="line">    <span class="comment">// and check cellState again</span></span><br><span class="line">    StoreLoadFence(); </span><br><span class="line">    <span class="keyword">if</span> (obj-&gt;cellState == black) &#123;</span><br><span class="line">      WriteBarrierSlowPath(obj);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note that there is no race between <code>WriteBarrier</code> and GC setting/clearing <code>IsGcRunning()</code> flag and changing the <code>g_blackThreshold</code> value, because the mutator is always stopped at a safe point (of course, halfway inside <code>WriteBarrier</code> is not a safe point) when the GC starts/finishes.</p>
<h4 id="“Obstruction-Free-Double-Collect-Snapshot”">“Obstruction-Free Double Collect Snapshot”</h4>
<p>Concurrent GC also introduced new complexities for the <code>ForEachChild</code> function used by GC marking phase to scan all objects referenced by a certain object. Each Javascript object has a <code>Structure</code> (aka, hidden class) that describes how the content of this object shall be interpreted into object fields. Since the GC marking phase is run concurrently with the mutator, and the mutator may change the <code>Structure</code> of the object, and may even change the size of the object’s butterfly, GC must be sure that despite the race conditions, it will never crash by dereferencing invalid pointers and never miss to scan a child. Using a lock is clearly infeasible for performance reasons. JSC uses a so-called <em>obstruction-free double collect snapshot</em> to solve this problem. Please refer to the <a href="https://webkit.org/blog/7122/introducing-riptide-webkits-retreating-wavefront-concurrent-garbage-collector/" target="_blank" rel="noopener">Webkit GC blog post</a> to see how it works.</p>
<h3 id="Some-Minor-Design-Details-and-Optimizations">Some Minor Design Details and Optimizations</h3>
<p>You might find this section helpful if you want to actually read and understand the code of JSC, but otherwise feel free to skip it: these details are not centric to the design, and are not particularly interesting either. I mention them only to bridge the gap between the GC scheme explained in this post and the actual implementation in JSC.</p>
<p>As explained earlier, each <code>CompleteSubspace</code> owns a list of <code>BlockDirectory</code> to handle allocations of different sizes; each <code>BlockDirectory</code> has an active block <code>m_currentBlock</code> where it allocates from, and it achieves this by holding a free list of all available cells in the block. But how does it work exactly?</p>
<p>As it turns out, each <code>BlockDirectory</code> has a <code>cursor</code>, which is <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/LocalAllocator.cpp.html#_ZN3JSC14LocalAllocator5resetEv">reset</a> to point at the beginning of the block list at the end of an eden or full GC cycle. Until it is reset, it can only move forward. The <code>BlockDirectory</code> will <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/BlockDirectory.cpp.html#_ZN3JSC14BlockDirectory22findBlockForAllocationERNS_14LocalAllocatorE">move the cursor forward</a>, until it finds a block containing available cells, and allocate from it. If the cursor reaches the end of the list, it will attempt to <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/LocalAllocator.cpp.html#195">steal a 16KB block</a> from another <code>BlockDirectory</code> and allocate from it. If that also failed, it will allocate a new 16KB block from OS and allocate from it.</p>
<p>I also mentioned that a <code>BlockDirectory</code> uses a free list to allocate from the currently active block <code>m_currentBlock</code>. It’s important to note that in the actual implementation of JSC, the cells in <code>m_currentBlock</code> does not respect the rule for <code>isNew</code> bit. Therefore, to check liveness, one either need to do a special-case check to see if the cell is from <code>m_currentBlock</code> (for example, see <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/HeapCell.cpp.html#_ZN3JSC8HeapCell6isLiveEv">HeapCell::isLive</a>), or, for the GC<sup class="footnote-ref"><a href="#fn24" id="fnref24">[24]</a></sup>, stop the mutator, destroy the free list (and populate <code>isNew</code> in the process), do whatever inspection, then rebuild the free list and resume the mutator. The latter is implemented by <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlock.cpp.html#_ZN3JSC11MarkedBlock6Handle14stopAllocatingERKNS_8FreeListE">two</a> <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlock.cpp.html#_ZN3JSC11MarkedBlock6Handle16resumeAllocatingERNS_8FreeListE">functions</a> named <code>stopAllocating()</code> and <code>resumeAllocating()</code>, which are automatically called whenever the world is <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/Heap.cpp.html#_ZN3JSC4Heap16stopThePeripheryENS_11GCConductorE">stopped</a> or <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/Heap.cpp.html#_ZN3JSC4Heap18resumeThePeripheryEv">resumed</a>.</p>
<p><a name="isNewAndAllocateBit"></a>The motivation of allowing <code>m_currentBlock</code> to not respect the rule for <code>isNew</code> is (a tiny bit of) performance. Instead of manually setting <code>isNew</code> to <code>true</code> for every allocation, a block-level bit <code>allocated</code> (aggregated as a bitvector in <code>BlockDirectory</code>) is used to indicate if a block is full of live objects. When the <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlock.cpp.html#_ZN3JSC11MarkedBlock6Handle18didConsumeFreeListEv">free list becomes empty</a> (i.e., the block is fully allocated), we simply set <code>allocated</code> to <code>true</code> for this block. When querying cell liveness, we <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlockInlines.h.html#101">check this bit first</a> and directly return true if it is set. The <code>allocated</code> bitvector is <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/BlockDirectory.cpp.html#252">cleared at the end of each GC cycle</a>, and since the global logical version for <code>isNew</code> is also bumped, this effectively clears all the <code>isNew</code> bits, just as we desired.</p>
<p>JSC’s design also support the so-called <em>constraint solver</em>, which allows specification of implicit reference edges (i.e., edge not represented as pointer in the object). This is mainly used to support Javascript interaction with DOM. This part is not covered in this post.</p>
<p>Weak reference has multiple implementations in JSC. The general (but less efficient) implementation is <code>WeakImpl</code>, denoting a weak reference edge. The data structure managing them is <code>WeakSet</code>, and you can see it in <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/MarkedBlock.h.html#JSC::MarkedBlock::Handle::m_weakSet">every block footer</a>, and in <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/PreciseAllocation.h.html#JSC::PreciseAllocation::m_weakSet">every PreciseAllocation GC header</a>. However, JSC also employs more efficient specialized implementations to handle the weak map feature in Javascript. The details are not covered in this post.</p>
<p>In JSC, objects may also have destructors. There are three ways the destructors are run. First, when we begin allocating from a block, destructors of the dead cells are run. Second, the <code>IncrementalSweeper</code> periodically scans the blocks and runs destructors. Finally, when the VM shuts down, the <code>lastChanceToFinalize()</code> function is called to ensure that all destructors are run at that time. The details of <code>lastChanceToFinalize()</code> are not covered in this post.</p>
<p>JSC employs a conservative approach for pointers on the stack and in registers: the GC uses UNIX signals to suspend the mutator thread, so it can copy its stack contents and CPU register values to search for data that looks like pointers. However, it’s important to note that UNIX signal is <strong>not</strong> used to suspend the execution of the mutator: the mutator always <strong>actively</strong> suspends itself at a safe point. This is critical, as otherwise it could be suspended at weird places, for example, in a <code>HeapCell::isLive</code> check after it has read <code>isNew</code> but before it has read <code>isMarked</code>, and then GC did <code>isNew |= isMarked, isMarked = false</code>, and boom. So it seems like the only reason to suspend the thread is for the GC to get the CPU register values, including the <code>SP</code> register value so the GC knows where the stack ends. It’s unclear to me if it’s possible to do so in a cooperative manner instead of using costly UNIX signals.</p>
<h3 id="Acknowledgements">Acknowledgements</h3>
<p>I thank Saam Barati from JSC team for his enormous help on this blog post. Of course, any mistakes in this post are mine.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Brief stop-the-world pause is still required at the start and end of each GC cycle, and may be intentionally performed if the mutator thread (i.e. the thread running Javascript code) is producing garbage too fast for the GC thread to keep up with. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>The actual allocation logic is implemented in <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/LocalAllocator.h.html#JSC::LocalAllocator">LocalAllocator</a>. Despite that in the code <code>BlockDirectory</code> is holding a linked list of <code>LocalAllocator</code>, (at time of writing, for the codebase version linked in this blog) the linked list always contains exactly one element, so the <code>BlockDirectory</code> and <code>LocalAllocator</code> is one-to-one and can be viewed as an integrated component. This relationship might change in the future, but it doesn’t matter for the purpose of this post anyway. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Since the footer resides at the end of a 16KB block, and the block is also 16KB aligned, one can do a simple bit math from any object pointer to access the footer of the block it resides in. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Similar to that per-cell information is aggregated and stored in the block footer, per-block information is aggregated as bitvectors and stored in <code>BlockDirectory</code> for fast lookup. Specifically, two bitvectors <code>empty</code> and <code>canAllocateButNotEmpty</code> track if a block is empty, or partially empty. The <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/BlockDirectoryBits.h.html#_M/FOR_EACH_BLOCK_DIRECTORY_BIT">code</a> is relatively confusing because the bitvectors are <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/BlockDirectoryBits.h.html#JSC::BlockDirectoryBits::Segment">layouted in a non-standard way</a> to make resizing easier, but conceptually it’s just one bitvector for each boolean per-block property. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>While seemingly straightforward, it is not straightforward at all (as you can see in the code). The free cells are marked free by the GC, and due to concurrency and performance optimization the logic becomes very tricky: we will revisit this later. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>In fact, it also <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/LocalAllocator.cpp.html#195">attempts to steal</a> blocks from other allocators, and the OS memory allocator may have <a href="https://sillycross.github.io/r/WebKit/WTF/Headers/wtf/Gigacage.h.html">some special requirements</a> required for the VM, but we ignore those details for simplicity. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>In the current implementation, the list of sizes (byte) are 16, 32, 48, 64, 80, then <code>80 * 1.4 ^ n</code> for <code>n &gt;= 1</code> up to about 8KB. Exponential growth guarantees that the overhead due to internal fragmentation is at most a fraction (in this case, 40%) of the total allocation size. <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>An interesting implementation detail is that <code>IsoSubspace</code> and <code>CompleteSubspace</code> always return memory aligned to 16 bytes, but <code>PreciseAllocation</code> always return memory address that has reminder 8 module 16. This allows identifying whether an object is allocated by <code>PreciseAllocation</code> with a simple bit math. <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p>JSC has another small optimization here. Sometimes a <code>IsoSubspace</code> contains so few objects that it’s a waste to hold them using a 16KB memory page (the block size of <code>BlockDirectory</code>). So the first few memory pages of <code>IsoSubspace</code> use the so-called “lower-tier”, which are smaller memory pages allocated by <code>PreciseAllocation</code>. In this post, we will ignore this design detail for simplicity. <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn10" class="footnote-item"><p>Memory of an <code>IsoSubspace</code> is only used by this <code>IsoSubspace</code>, never stolen by other allocators. As a result, a memory address in <code>IsoSubspace</code> can only be reused to allocate objects of the same type. So for any type <code>A</code> allocated by <code>IsoSubspace</code>, even if there is a use-after-free bug on type <code>A</code>, it is impossible to allocate <code>A</code>, free it, allocate type <code>B</code> at the same address, and exploit the bug to trick the VM into interpreting an integer field in <code>B</code> controlled by attacker as a pointer field in <code>A</code>. <a href="#fnref10" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn11" class="footnote-item"><p>In some GC schemes, an eden object is required to survive two (instead of one) eden GC to be considered in old space. The purpose of such design is to make sure that any old space object is at least one eden-GC-gap old. In contrast, in JSC’s design, an object created immediately before an eden collection will be considered to be in old space immediately, which then can only be reclaimed via a full GC. The performance difference between the two designs is unclear to me. I conjecture JSC chose its current design because it’s easier to make concurrent. <a href="#fnref11" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn12" class="footnote-item"><p>There is one additional color <code>Grey</code> in <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/heap/CellState.h.html#JSC::CellState">the code</a>. However, it turns out that <code>White</code> and <code>Grey</code> makes no difference (you can verify it by grepping all use of <code>cellState</code> and observe that the only comparison on <code>cellState</code> is checking if it is <code>Black</code>). The comments explaining what the colors mean are also a bit outdated. This is likely a historical artifact. In my opinion JSC should really clean it up and update the comment, as it can easily cause confusion to readers who intend to understand the design. <a href="#fnref12" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn13" class="footnote-item"><p>The bit is actually called <code>isNewlyAllocated</code> in the code. We shorten it to <code>isNew</code> for convenience in this post. <a href="#fnref13" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn14" class="footnote-item"><p><em>Safe point</em> is a terminology in GC. At a <em>safe point</em>, the heap and stack is in a coherent state understandable by the GC, so the GC can correctly trace out which objects are dead or live. <a href="#fnref14" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn15" class="footnote-item"><p>For <code>PreciseAllocation</code>, all allocated objects are chained into a linked list, so we can traverse all objects (live or dead) easily. This is not efficient: we will explain the optimizations for <code>CompleteSubspace</code> later. <a href="#fnref15" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn16" class="footnote-item"><p>Keep in mind that while this is true for now, as we add more optimizations to the design, this will no longer be true. <a href="#fnref16" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn17" class="footnote-item"><p>Note that we push the old space object into the queue, not the eden object, because this pointer could have been overwritten at the start of the GC cycle, making the eden object potentially collectable. <a href="#fnref17" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn18" class="footnote-item"><p>Also note that all objects dead before this GC cycle, i.e. the free cells of a block in <code>CompleteSubspace</code>, still have <code>isNew = false</code> and <code>isMarked = false</code>, as desired. <a href="#fnref18" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn19" class="footnote-item"><p>Recall that under generational hypothesis, most objects die young. Therefore, that “all objects in an eden block are found dead during eden GC” is something completely plausible. <a href="#fnref19" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn20" class="footnote-item"><p>In JSC, the version is stored in a <code>uint32_t</code> and they have a bunch of logic to handle the case that it overflows <code>uint32_t</code>. In my humble opinion, this is an overoptimization that results in very hard-to-test edge cases, especially in a concurrent setting. So we will ignore this complexity: one can easily avoid these by spending 8 more bytes per block footer to have <code>uint64_t</code> version number instead. <a href="#fnref20" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn21" class="footnote-item"><p>Note that any number of eden GC cycles may have run between the last full GC cycle and the current full GC cycle, but eden GC does not bump mark version. So for any object born before the last GC cycle (no matter eden or full), the <code>isMarked</code> bit honestly reflect if it is live, and we will accept the bit as its mark version must be off-by-one. For objects born after the last GC cycle, it must have a latest <code>isNew</code> version, so we can know it’s alive through <code>isNew</code>. In both cases, the scheme correctly determines if an object is alive, just as desired. <a href="#fnref21" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn22" class="footnote-item"><p>And probably not: first, true sharing and false sharing between GC and mutator can cause slowdown. Second, as we have covered before, JSC uses a Time-Space Scheduler to prevent the mutator from allocating too fast while the GC is running. Specifically, the mutator will be intentionally suspended for at least 30% of the duration. So as long as the GC is running, the mutator suffers from an 30%-or-more “performance tax”. <a href="#fnref22" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn23" class="footnote-item"><p>The real story is a bit more complicated. JSC actually reuse the same VM for different Javascript scripts. However, at any moment, at most one of the script can be running. So technically, there are multiple mutually-exclusive mutator threads, but this doesn’t affect our GC story. <a href="#fnref23" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn24" class="footnote-item"><p>The GC needs to inspect a lot of cells, and its logic is already complex enough, so having one less special-case branch is probably beneficial for both engineering and performance. <a href="#fnref24" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/06/02/2022-06-02/" data-id="clhkntog2000idsp05q707yfy" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-05-31" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/05/31/2022-05-31/">NP70PNP + Ubuntu Tweak Notes</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/05/31/2022-05-31/" class="article-date"><time datetime="2022-05-31T00:00:00.000Z" itemprop="datePublished">2022-05-31</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>Recently I decided to get a new laptop to replace my 5-years-old one. I happened to discover something called “barebone laptop”, which are essentially laptops with no RAM or SSD installed and no brand logo painted.</p>
<p>The barebone laptop manufacturers generally only provide bulk sale to OEM manufacturers. Since retail sale is not possible directly, there is a niche market for buying in barebone laptops in bulk and resell them to end customers, and there are small business who live on this niche, which is the easiest way for one to buy a barebone.</p>
<p>Apart from being more environment-friendly (by reusing the RAM and SSD from the old laptop), the main advantage of a barebone is the price. My new <code>Clevo NP70PNP</code> bought from R&amp;J Tech (a barebone reseller business) is $1300, while a <code>Dell</code> laptop with the identical configuration<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> is sold at $2650. It’s surprising that Dell at least doubled the price<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> by simply plugging in the RAM and SSD and painting their logo on top<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>, and their customers are still happily buying it.</p>
<p>Anyway, let’s get back to the topic. My experience is that the <code>Clevo NP70PNP</code> can work very well with Ubuntu, though a few tweaks are needed. The hardest part is that it’s very hard to find the necessary tweaks in Google due to the unpopularity of barebone laptops, which is why I’m taking notes here.</p>
<ol>
<li>It has the Intel AX201 Wifi card, which doesn’t work in Ubuntu 20.04, and the reason is the kernel version, so not fixable by manually installing the firmware. However, Ubuntu 22.04 (just released last month) supports the Wifi card out of the box.</li>
<li>The Ubuntu 22.04 live-USB black screens on regular boot, but can be fixed by selecting <code>safe graphics</code> at boot menu. It’s a pain – for whatever reason it takes 10 minutes to load the desktop, but fortunately this is only needed for live-USB install: after the install, the GPU driver and the graphics work fine.</li>
<li>The touchpad (model <code>FTCS1000:01 2808:0102</code>) is the one that took me the longest to make work. It works initially, but would fail randomly after some time. After a lot of fruitless googling, it turns out that the GPU setting is the problem! (I seriously have no idea why.) As it turns out, the fix is to disable <code>MS Hybrid</code> for GPU. One can do this either in BIOS (in <code>Advanced Chip Settings</code>, switch the option from <code>MS Hybrid</code> to <code>Discrete GPU Only</code>), or in Ubuntu NVIDIA X Server Settings (in <code>PRIME settings</code> choose <code>Performance</code>).</li>
<li>Even after the tweak, there are still some minor issues with touchpad. Specifically, the feature that automatically disables touchpad when external mouse is present or while typing does not work, since for some reason the touchpad cannot be disabled from <code>xinput</code>. However, for some reason, it can still be disabled in GNOME by bash command <code>gsettings set org.gnome.desktop.peripherals.touchpad send-events disabled</code>. So I wrote a <code>udev</code> rule to automatically disable the touchpad on external mouse plugging in and re-enable it when the external mouse is plugged out. Googling any <code>udev</code> rule tutorial should be sufficient. Automatically disabling touchpad on typing seems much harder.</li>
<li>There are some minor issue with Bluetooth. For some reason, with AD2P Sink, there is a 0.5s delay in playing music. The problem doesn’t exist with HSP, though the audio quality of HSP is considerably lower. I haven’t figured out how to fix the problem since I usually use a headset.</li>
<li>For some reason, whenever the GPU is under load, the fan would spin at max speed (even if the GPU temperature is only 40 C or so), and the noise is a bit too loud. And it seems like neither the NVIDIA GPU driver nor <code>fancontrol</code> could even detect the fan, not to mention controlling it, though I haven’t dig into this issue too deep either, since it’s not too problematic for my use case.</li>
</ol>
<p>Other than the issues mentioned above, everything works out of the box under Ubuntu 22.04, including all my external devices and all <code>Fn</code> hotkeys (except the one that disables touchpad).</p>
<p>For the hardware side, IMO the model has only two minor design drawbacks: there are only two USB ports (and one of it is USB 2.0, seriously, why?); and the plastic hull seems relatively fragile and has many very thin parts, so I’m a bit concerned if the hull would break in an accident someday. The weight and the battery life are also not the best on the market, though they are definitely within reasonable range for a 17.3&quot; performance-oriented laptop, and also I’m not too concerned about them for my use case.</p>
<p>Overall, I would recommend it as a great laptop at a great price for Ubuntu users.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>CPU model, GPU model, screen size, screen resolution are all identical. The barebone doesn’t come with RAM or SSD, but the Dell $2650 model has the worst RAM and SSD that is sold at $30 on Amazon. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>In fact, I would conjecture they tripled the price: given that R&amp;J is such a small business and how fast laptop hardware models get outdated, I guess the bulk bought-in price from Clevo is likely much less than $1000. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Of course, they also install Windows, but a Windows license not that expensive either, and also I don’t use Windows… <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/05/31/2022-05-31/" data-id="clhkntofq000cdsp07h935oi7" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-04-30" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/04/30/2022-04-30/">The Watchpoint Mechanism in JSC</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/04/30/2022-04-30/" class="article-date"><time datetime="2022-04-30T00:00:00.000Z" itemprop="datePublished">2022-04-30</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>While Javascript has a simple syntax, what happens behind the scene is far from simple. For example, consider this innocent-looking <code>hypot</code> function below:</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> hypot = <span class="function"><span class="keyword">function</span>(<span class="params">a, b</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Math</span>.sqrt(a * a + b * b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>It is clear what <code>Math.sqrt</code> does: it performs a square root. However, to actually execute <code>Math.sqrt(...)</code>, a lot of steps are needed:</p>
<ol>
<li>First, get the global object, where all global variables reside in.</li>
<li>Then, get the <code>Math</code> property of the global object. Normally the <code>Math</code> property exists (since it is predefined), but we can’t know for sure: if someone had indeed run <code>delete Math;</code> before, we must promptly throw out an error.</li>
<li>Next, get the <code>sqrt</code> property of <code>Math</code>. Note that we cannot even be certain that <code>Math</code> is an object (as someone could have done <code>Math = 123;</code>). So as in (2), we must not omit any check for error.</li>
<li>Finally, similarly, what the <code>sqrt</code> property contains can be anything. Even if it is a function, it could be <em>any</em> function. So as before, we must not omit any check, and if <code>sqrt</code> is indeed a Javascript function, we perform the Javascript function call.</li>
</ol>
<p>So, in order to correctly (as every Javascript engine needs to be) execute this innocently looking <code>Math.sqrt</code>, a ton of stuffs must be done.</p>
<h4 id="How-can-we-make-this-faster">How can we make this faster?</h4>
<p>The crucial observation is that while the programmer is technically allowed to do anything, including insane things like <code>delete Math;</code> or <code>Math = 123</code>, most sane programs will not do it. So for practical purposes, it is enough if we can make sane programs both correct and fast, while running insane programs only correctly.</p>
<p>In JSC (<a href="https://webkit.org/" target="_blank" rel="noopener">WebKit</a>’s Javascript engine), this is achieved by <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/bytecode/Watchpoint.h.html#138">Watchpoint</a>.</p>
<p>Conceptually, a <code>WatchpointSet</code> represents a condition that one expects to be true, or simply put, a <em>watchable condition</em>. For example, we may expect the global object to contain property <code>Math</code>, and its value being equal to the predefined <code>Math</code> object.</p>
<p>One may attach <code>Watchpoint</code>s to the <code>WatchpointSet</code>. A <code>Watchpoint</code> is essentially a callback: after attaching to a <code>WatchpointSet</code>, when the condition represented by the <code>WatchpointSet</code> becomes false, the callback is invoked (“fired”), so the owner who created the <code>Watchpoint</code> can react correspondingly.</p>
<p>While the watchpoint mechanism isn’t necessarily binded to JIT Compilation (for example, <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/bytecode/LLIntPrototypeLoadAdaptiveStructureWatchpoint.h.html#JSC::LLIntPrototypeLoadAdaptiveStructureWatchpoint">LLIntPrototypeLoadAdaptiveStructureWatchpoint</a> works without JIT), it is most powerful when combined with JIT Compilation. We generate code that is optimized assuming the watchpoint condition holds, so inside the generated code, we don’t check for the condition at all. If the condition no longer holds, we must jettison the code – this is expensive, because all the work we did to generate the code is wasted, but the whole point of watchpoint is that such bad cases should happen only rarely.</p>
<h4 id="A-Motivating-Example">A Motivating Example</h4>
<p>Let’s go back to the <code>Math.sqrt</code> example: we want to get notified when a property of an object changes value. Therefore, all logic that writes value into object properties must cooperate with us. For simplicity, let’s assume the object <code>Math</code> has a <a href="https://webkit.org/blog/10308/speculation-in-javascriptcore/" target="_blank" rel="noopener">Structure</a>, say <code>S</code>. Then, there are two kinds of logic that may write to object properties:</p>
<ol>
<li>The C++ code that implements object property writes (the slow paths).</li>
<li>The JIT’ed code that writes to a specific property of a specific structure (the fast paths).</li>
</ol>
<p>The fast paths are known as <a href="https://webkit.org/blog/10308/speculation-in-javascriptcore/" target="_blank" rel="noopener">inline caches</a>. Inline caching is probably the most important optimization in JSC, but I will leave its details to another post. For the purpose of this post, it’s sufficient to think of each inline cache fast-path as a JIT-compiled piece of code that is specialized for a certain structure <code>S</code> and a certain property name <code>prop</code>. Given a <code>value</code> and an object with structure <code>S</code>, it writes <code>value</code> to property <code>prop</code> of the object.</p>
<p>The slow path case is easy to handle: whenever one writes to a property of an object, one checks whether there are Watchpoints watching the condition, and fire them. Of course, we are doing one extra check for every object property write. However, those code are already slow paths, so it doesn’t hurt too much to make them a bit more slower.</p>
<p>The fast path case is trickier. A naive solution is to add a watchpoint check, as how we handled slow-path. However, this is unsatisfactory: now, every fast-path write is doing one extra check! We can afford slowing down the slow-path, but we want to keep the fast-path fast.</p>
<p>So, the fast-path must not check for watchpoint conditions it violates at runtime. Instead, we <em>permenantly</em> invalidate any and all <code>WatchpointSet</code> it could violate as soon as the fast-path code is JIT’ed, no matter if there are watchers or not. As another consequence, since the fast path works on a fixed property (e.g. <code>sqrt</code>) of a fixed Structure (e.g. <code>S</code>), but not on fixed objects, our watchpoints have to be in the form of <code>&lt;Structure, property&gt;</code>: they work on Structure-level but not object-level (they are called <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/runtime/StructureRareData.h.html#JSC::StructureRareData::m_replacementWatchpointSets">ValueReplacementWatchpointSet</a> in JSC). For example,when a fast-path writing the <code>sqrt</code> property of Structure <code>S</code> is built, we have to be conservative and permanently invalidate WatchpointSet <code>&lt;S, sqrt&gt;</code>, since we have no way to know if that fast-path is going to run on our <code>Math</code> object in the future.</p>
<h4 id="The-Design">The Design</h4>
<p>This leads to the following design in JSC. A <code>WatchpointSet</code> has three possible <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/bytecode/Watchpoint.h.html#JSC::WatchpointState">states</a><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>:</p>
<ol>
<li><code>DoesNotExist</code>: The <code>WatchpointSet</code> object does not physically exist (and is implicitly <code>Valid</code>). This is needed because there is an infinite number of watchable conditions, and also that we want to save memory. In this state, there exists no fast-path that rely on or violate the watchpoint. Slowpath executions that violate the watchpoint are not recorded (but doing so wouldn’t break the scheme).</li>
<li><code>Valid</code><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>: The watchpoint is valid: no fast-path that may violate the watched condition has been built, and one may build fast-path relying on the watchpoint condition as long as it adds itself into the watcher list.</li>
<li><code>Invalidated</code>: The watchpoint is permaently invalidated.</li>
</ol>
<p>As one can see from the example in the previous section, the <code>Watchpoint</code> system needs to handle interactions with three components:</p>
<ol>
<li>Slow-path (C++ code) that may violate the watched condition.</li>
<li>Fast-path (JIT’ed code) that may violate the watched condition.</li>
<li>Code (C++ or JIT’ed) that is optimized assuming the watched condition is true.</li>
</ol>
<p>For (1), the slow-path must check in the code any watchable condition it violated, and if the corresponding <code>WatchpointSet</code> exists, fire all watchers. However, in such case, the slow-path have the choice between invalidate the <code>WatchpointSet</code>, or to keep it valid<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>.</p>
<p>For (2), the fast-path code does not check the watchable condition it violates, but we must transit all <code>WatchpointSet</code>s it may violate when executed to <code>Invalidated</code> when such a fast-path is JIT’ed (and we must create such <code>WatchpointSet</code> object if it does not exist yet).</p>
<p>For (3), we must disable the code when the watcher callback is invoked. If the code is C++ code, then disabling the codepath is as easy as flipping a flag. If the code is JIT’ed code, we must jettison the code<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>.</p>
<h4 id="Back-to-Our-Example-and-Adaptive-Watchpoints">Back to Our Example, and Adaptive Watchpoints</h4>
<p>Unfortunately, in our example, it turns out that only watching on <code>&lt;Structure, Property&gt;</code> is not enough. While this handles writes to <em>existing</em> properties correctly, one may create <em>new</em> properties in the object, thus transitioning its <code>Structure</code>. Say, one did a <code>Math.abc = 123;</code>. Since it adds a property to <code>Math</code>, the object <code>Math</code> gets a different structure <code>S2</code>, but our watchpoint is watching on <code>&lt;S, sqrt&gt;</code>, and we are screwed. To fix this issue, we must get notified when our object changes structure as well. However, as before, since an object-property-write fast-path works on a fixed <code>Structure</code> but not a fixed object, we have to put our watchpoint at <code>Structure</code> level. That is, we will have a <code>WachpointSet</code> on each Structure <code>S</code>, asserting that it never makes further transitions to other Structures (this is called a <a href="https://sillycross.github.io/r/WebKit/Source/JavaScriptCore/runtime/Structure.h.html#JSC::Structure::m_transitionWatchpointSet">StructureTransitionWatchpointSet</a> in JSC).</p>
<p>The last interesting piece is what to do when a StructureTransitionWatchpointSet turns to <code>Invalidated</code> state. If the transition happened on another object with the same Structure <code>S</code>, even though our <code>Math</code> object is not modified, we have no choice but to invalidate our code, as the StructureTransitionWatchpointSet for <code>S</code> has been invalidated, so we have no way to get notified if our <code>Math</code> object gets transitioned in the future.</p>
<p>However, if the transition happened on object <code>Math</code> (i.e. <code>Math</code> itself gets a new Structure), then it’s possible to keep our optimized code valid: we just need to start watching <code>&lt;S2, sqrt&gt;</code> instead. So we will move our ValueReplacementWatchpoint to watch <code>&lt;S2, sqrt&gt;</code> and our StructureTransitionWatchpoint to watch <code>S2</code>, and keep our code valid<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>. In JSC, such watchpoints whose action on fire is to move themselves to new places have a terminology <code>AdaptiveWatchpoints</code>.</p>
<h4 id="Ending-Thoughts">Ending Thoughts</h4>
<p>This way, by watching that the <code>Math</code> property of the global object never changes value, and that the <code>sqrt</code> property of the <code>Math</code> object never changes value, the code <code>Math.sqrt</code> is reduced from two object property lookups with a ton of error checks to a constant (not even a branch!) in the JIT’ed code.</p>
<p>The watchpoint mechanism also helps other optimizations to generate better code. For example, the call opcode (which calls whatever is stored in <code>Math.sqrt</code>) has its own inline caching that records which functions it has called. For sane programs that does not mess up with the predefined objects, there will be only one callee recorded: the <code>sqrt</code> intrinsic function. Normally this would allow the compiler to emit a check (that the result of expression <code>Math.sqrt</code> equals the <code>sqrt</code> intrinsic function) and speculatively inline <code>sqrt</code>. However, since the watchpoint already tells us that <code>Math.sqrt</code> <em>must</em> evaluates to the <code>sqrt</code> intrinsic function, the compiler can do better: it may omit the check and inline <code>sqrt</code> directly. Now, for sane programs, all the terrible stuffs listed at the beginning of this post are gone, so the JIT’ed code to evaluate the <code>Math.sqrt</code> part is as efficient as if it were directly written in C++!</p>
<p>Finally, a couple of side notes:</p>
<ol>
<li>If we want to avoid the case that the transition of another object results in invalidation of our code, we can give our object its own unique Structure, though the downside is that we might blow up the inline cache if we do it for too many objects.</li>
<li>The slow-path does not fire the watchpoint if the watchpoint is in <code>DoesNotExist</code> or <code>Clear</code> state. This not only saves memory, but is also an advantage for the use case above: while it’s plausible to assume that sane programs will not change <code>Math.sqrt</code> frequently, it’s also plausible for them to change it at program start (e.g., to log a warning if the input to <code>sqrt</code> is negative). Since such code will execute in slow-path and before any fast-path relying on the <code>WatchpointSet</code> is built, they will not invalidate the <code>WatchpointSet</code>, as desired.</li>
</ol>
<h4 id="Acknowledgements">Acknowledgements</h4>
<p>I thank Saam Barati from JSC team for teaching me all of these (and more) using his precious spare time, and for his valuable comments on this post. Of course, any mistakes in this post are mine.</p>
<hr>
<h4 id="Footnotes">Footnotes</h4>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Note that the <code>DoesNotExist</code> state is not listed in the enum, since in this state the object doesn’t exist at all. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>In fact, JSC further distinguishes <code>Valid</code> state into <code>Clear</code> and <code>Watched</code>, to determine the behavior when a slow-path violation happened (see Footnote 3). However, this is only a design detail, so we put it in footnote for ease of understanding. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>When the <code>WatchpointSet</code> is in <code>Clear</code> state, the slow-path will keep it in <code>Clear</code> state. However, if it is in <code>Watched</code> state, even if there are no watchers, it will be transitioned to <code>Invalidated</code> state. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Things get trickier if the code is already running (e.g., the code being jettisoned is the current function being executed, a function in the call stack, or even a function inlined by the current function), in which case we must OSR Exit to the baseline tier, but we will ignore such complexities in this post. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Of course, if the ValueReplacementWatchpointSet of <code>&lt;S2, sqrt&gt;</code> or the StructureTransitionWatchpointSet of <code>S2</code> is already <code>Invalidated</code>, we will still have to invalidate our code. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/04/30/2022-04-30/" data-id="clhkntofs000ddsp0elvde1o9" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-04-26" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/04/26/2022-04-26/">Note on x86-64 Memory Model</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/04/26/2022-04-26/" class="article-date"><time datetime="2022-04-26T00:00:00.000Z" itemprop="datePublished">2022-04-26</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>In the past years, I have undergone a few cycles of learning the x86-64 memory model, only to eventually forget it again. Today I was fortunate to see <a href="https://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf" target="_blank" rel="noopener">a great paper</a> which explained this matter very clearly, so I’m taking a note here for future reference.</p>
<p>The model in the paper is particularly easy to understand because it is described by standard software lock primitives<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>, as below:</p>
<ol>
<li>There is one global lock <code>G</code>.</li>
<li>There is one background thread <code>T</code>.</li>
<li>Each CPU has a <em>store buffer</em>, which is a queue of items <code>&lt;address, value&gt;</code>. The store buffer is pushed by the owning CPU, and popped by the background thread <code>T</code>.</li>
</ol>
<p>The background thread <code>T</code> does only one thing:</p>
<ol>
<li>Lock global lock <code>G</code>.</li>
<li>Pop an item <code>&lt;addr, value&gt;</code> from the store buffer of a CPU, write the value to main memory: <code>MainMemory[addr] = value</code>.</li>
<li>Unlock global lock <code>G</code>.</li>
</ol>
<p>The procedure for a CPU to execute an instruction is described below.</p>
<h4 id="STORE-instruction">STORE instruction</h4>
<ol>
<li>Push item <code>&lt;addr, value&gt;</code> to its store buffer.</li>
</ol>
<h4 id="LOAD-instruction">LOAD instruction</h4>
<ol>
<li>Lock global lock <code>G</code>.</li>
<li>If <code>addr</code> exists in its store buffer, return corresponding <code>value</code><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>. Otherwise return <code>MainMemory[addr]</code>.</li>
<li>Unlock global lock <code>G</code>.</li>
</ol>
<h4 id="MFENCE-instruction">MFENCE instruction</h4>
<ol>
<li>Wait until its store buffer is eventually emptied by background thread <code>T</code>.</li>
</ol>
<h4 id="ATOMIC-instruction">ATOMIC instruction</h4>
<ol>
<li>Lock global lock <code>G</code>.</li>
<li>Run the atomic instruction, using subroutines described above for <code>LOAD</code> and <code>STORE</code>.</li>
<li>Empty its own store buffer: pop every item <code>&lt;addr, value&gt;</code> from the store buffer and write to main memory: <code>MainMemory[addr] = value</code>, until the store buffer is empty.</li>
<li>Unlock global lock <code>G</code>.</li>
</ol>
<p>Note that the semantics of <code>LOAD</code> and <code>STORE</code> provide the expected consistency on single-threaded programs.</p>
<h4 id="An-Application">An Application</h4>
<p>Let’s analyze why the familiar spinlock implementation below is correct under x86-64 memory model:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Init</span><span class="params">(<span class="keyword">uint8_t</span>* lock)</span> </span>&#123; *lock = <span class="number">0</span>; &#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Lock</span><span class="params">(<span class="keyword">uint8_t</span>* lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!compare_and_swap(lock, <span class="number">0</span> <span class="comment">/*expect*/</span>, <span class="number">1</span> <span class="comment">/*desired*/</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Unlock</span><span class="params">(<span class="keyword">uint8_t</span>* lock)</span> </span>&#123; </span><br><span class="line">    *lock = <span class="number">0</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>We will prove the correctness via a token-counting argument. Each <code>&lt;lock, 0&gt;</code> in a store buffer counts as one token, and if <code>MainMemory[lock] == 0</code>, it also counts as one token. By definition at any moment the number of tokens cannot go below <code>0</code>.</p>
<p>By the abstract machine semantics above, it’s not hard to prove that:</p>
<ol>
<li>The background thread <code>T</code> cannot increase the total number of tokens.</li>
<li>Each <code>Unlock()</code> call creates one token.</li>
<li>Each <code>Lock()</code> call cannot return until it successfully consumes at least one token (If the CAS succeeded by seeing a <code>0</code> in its store buffer, that token is lost after the CAS because CAS flushes store buffer and also changes the memory value to 1. If the CAS succeeded by seeing a <code>0</code> in the main memory, that token is also lost because the store buffer item of the new value <code>1</code> is flushed to memory, overwriting the <code>0</code> value).</li>
</ol>
<p>Initially there is one token (by the <code>Init()</code> call). Since <code>Unlock()</code> may only be called after<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> (guaranteed by program order) <code>Lock()</code>, the total number of tokens cannot go above one at any moment. So after a <code>Lock()</code> returns, there must be zero tokens, so no other <code>Lock()</code> can return. The total number of tokens goes back to one only when the <code>Unlock()</code> in that program is called, and only after that other <code>Lock()</code> operation may return. So the <code>Lock() -&gt; Unlock()</code> time intervals are pairwisely non-overlapping, providing the mutual exclusiveness as one would expect.</p>
<hr>
<h5 id="Footnotes">Footnotes</h5>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Therefore, while the description is logically equivalent to the guarantees provided by the hardware, this is not how the hardware physically implements the memory subsystem. The hardware implementation is way more efficient. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Of course, if <code>addr</code> showed up multiple times in the store buffer, we should return the <code>value</code> of the latest version. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Throughout this argument, the time relationship is about wall clock time (or, the relative position in the interleaved event sequence of all CPUs). <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/04/26/2022-04-26/" data-id="clhkntofn000adsp0b3i31e3l" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  
    <article id="post-2022-04-01" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 itemprop="name">
      <a class="article-title" href="2022/04/01/2022-04-01/">From X Macro to FOR_EACH to Cartesian Product Enumeration with C Macro</a>
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="2022/04/01/2022-04-01/" class="article-date"><time datetime="2022-04-01T00:00:00.000Z" itemprop="datePublished">2022-04-01</time></a>
</div>

    
    

  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>Quite a while ago I was implementing an interpreter. A common task in the interpreter is to select the correct interpreter function based on the type of the input. Let’s say we want to implement an addition. We might end up with something like below:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Add</span><span class="params">(T* input1, T* input2, T* output)</span> </span>&#123;</span><br><span class="line">    *output = *input1 + *input2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>to implement the operation. At runtime, we want to dispatch to the right function base on the type of the operands. A natural way to do this is to have a static array holding the mapping from the operand type to the function pointer, similar to below:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Type &#123; Int32, Int64, Double, ... &#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span>* <span class="keyword">const</span> x_addOpPtr[] = &#123;</span><br><span class="line">    (<span class="keyword">void</span>*)Add&lt;<span class="keyword">int32_t</span>&gt;, </span><br><span class="line">    (<span class="keyword">void</span>*)Add&lt;<span class="keyword">int64_t</span>&gt;, </span><br><span class="line">    (<span class="keyword">void</span>*)Add&lt;<span class="keyword">double_t</span>&gt;, ...</span><br><span class="line">&#125;; </span><br></pre></td></tr></table></figure>
<p>so at runtime we can just read <code>x_addOpPtr[operandType]</code> to obtain the function pointer we want to call.</p>
<h4 id="The-X-Macro">The X Macro</h4>
<p>Although the code above can work, it is clearly too error prone. If we accidentally made a mistake in the order of the list, we are screwed. A better way is the <a href="https://en.wikipedia.org/wiki/X_Macro" target="_blank" rel="noopener">X Macro</a> pattern. We define a “X macro” for all the types:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FOR_EACH_TYPE(X) \</span></span><br><span class="line">    X(Int32, <span class="keyword">int32_t</span>)    \</span><br><span class="line">    X(Int64, <span class="keyword">int64_t</span>)    \</span><br><span class="line">    X(Double, <span class="keyword">double_t</span>) ...</span><br></pre></td></tr></table></figure>
<p>Then, by defining what <code>X(EnumType, CppType)</code> expands to, we can create logic based on our needs. For example, the following code would reproduce the <code>x_addOpPtr</code> array we want:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> X(EnumType, CppType) (void*)Add<span class="meta-string">&lt;CppType&gt; , </span></span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span>* <span class="keyword">const</span> x_addOpPtr[] = &#123; </span><br><span class="line">    FOR_EACH_TYPE(X) </span><br><span class="line">    <span class="literal">nullptr</span> </span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> X	<span class="comment">// hygiene </span></span></span><br></pre></td></tr></table></figure>
<p>Note that the final <code>nullptr</code> is needed because our expansion <code>(void*)Add&lt;CppType&gt;,</code> would generate an extra comma in the end.</p>
<h4 id="The-New-Challenge">The New Challenge</h4>
<p>X Macro solved the above problem, but what if we want to handle, say, a type cast opcode?</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Src, <span class="keyword">typename</span> Dst&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Cast</span><span class="params">(Src* input, Dst* output)</span> </span>&#123;</span><br><span class="line">    *output = <span class="keyword">static_cast</span>&lt;Dst&gt;(*input);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Unlike the addition operator, now we have two types <code>Src</code> and <code>Dst</code> to enumerate on, so we have to generate a two-dimensional array. While X Macro can easily iterate through one list and perform action on every item, it cannot iterate through the <strong>Cartesian product of two lists</strong>. A worse solution, is of course, to manually define a list containing all the <code>&lt;Src, Dst&gt;</code> pairs, so we can do X macro again. But what if we want to do a three-dimensional Cartesian product in the future?</p>
<p>After some fruitless Googling and home-making attempts to build a “two dimensional X Macro”, I eventually gave up and switched to <a href="https://github.com/sillycross/PochiVM/blob/master/pochivm/ast_type_helper.h#L635" target="_blank" rel="noopener">an ugly solution</a>. Instead of generating a clean static array, we generate a tree of templated dispatching functions. The function at the <code>i-th</code> level use a dispatch array (built by X macro) to dispatch to the next level’s selector function based on the <code>i-th</code> parameter type. We get the function pointer when we reach the leaf. While this approach works, no doubt it is very ugly, and probably also less performant (I didn’t check if the C++ compiler were able to optimize away all the terrible things).</p>
<h4 id="The-FOR-EACH-Macro">The FOR_EACH Macro</h4>
<p>I used to believe my ugly solution is as good as one can get without resorting to manually enumerating the Cartesian product. However, today I learnt <a href="https://www.scs.stanford.edu/~dm/blog/va-opt.html" target="_blank" rel="noopener">an interesting approach</a> from David Mazieres, which he calls the <code>FOR_EACH</code> macro.</p>
<p>The semantics of the <code>FOR_EACH</code> macro is pretty clear. Taking a macro <code>X</code> (similar to the <code>X</code> in X Macro) and a comma-separated list of elements <code>e1, e2, ... , en</code>, the <code>FOR_EACH</code> macro invokes <code>X</code> on each <code>e</code> in the list. For example, the addition example would look like:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Note that the 'X' is gone, and the list is comma-separated</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TYPE_LIST        \</span></span><br><span class="line">    (Int32, <span class="keyword">int32_t</span>) ,   \</span><br><span class="line">    (Int64, <span class="keyword">int64_t</span>) ,   \</span><br><span class="line">    (Double, <span class="keyword">double_t</span>) ...  </span><br><span class="line">    </span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> X(e) (void*)Add<span class="meta-string">&lt;TUPLE_GET_2(e)&gt; ,</span></span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span>* <span class="keyword">const</span> x_addOpPtr[] = &#123; </span><br><span class="line">    FOR_EACH(X, TYPE_LIST) </span><br><span class="line">    <span class="literal">nullptr</span> </span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> X</span></span><br></pre></td></tr></table></figure>
<p>The most important difference between <code>FOR_EACH</code> macro and X Macro is that the <code>FOR_EACH</code> list definition doesn’t take <code>X</code>. Unlike the X Macro, where the macro to call on each element is hardcoded to only pass the element itself, the <code>FOR_EACH</code> macro decoupled “the element to be processed” and “the macro processing the element”. This removes the biggest blocker to implement a macro that can enumerate through Cartesian product of multiple lists.</p>
<p>The core of the trick which allows <code>FOR_EACH</code>’s list definition to get rid of the <code>X</code> lies in the <a href="https://en.cppreference.com/w/cpp/preprocessor/replace#Function-like_macros" target="_blank" rel="noopener">C++20 new feature</a> <code>__VA_OPT__</code>. David Mazieres’ original article is already a good explanation on how the <code>FOR_EACH</code> macro works so I won’t parrot it again. With the main blocker removed, after only a few hours of work, I was able to successfully extend <code>FOR_EACH</code> to support enumerating through the Cartesian product of multiple lists. (By the way, even after implementing it, I still have very little idea on how the C preprocessor works, but <code>clang++ -E</code> is enough to trial-and-error into a working solution).</p>
<h4 id="The-FOR-EACH-CARTESIAN-PRODUCT-Macro">The FOR_EACH_CARTESIAN_PRODUCT Macro</h4>
<p>I call my macro <code>FOR_EACH_CARTESIAN_PRODUCT</code>. As the name suggests, it takes a macro <code>X</code> and one or more lists <code>(L1), ..., (Ln)</code>. Then for each <code>(e1, ..., en)</code> in the Cartesian product <code>L1 x ... x Ln</code> , the macro <code>X(e1, ..., en)</code> is invoked. The elements in the Cartesian product are enumerated in lexical order.</p>
<p>For example, for the type-casting example above, the below code would construct our desired two-dimensional dispatch array:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> X(e1, e2) (void*)Cast<span class="meta-string">&lt;TUPLE_GET_2(e1), TUPLE_GET_2(e2)&gt; ,</span></span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span>* <span class="keyword">const</span> x_castOpPtr[] = &#123; </span><br><span class="line">    FOR_EACH_CARTESIAN_PRODUCT(X, (TYPE_LIST), (TYPE_LIST)) </span><br><span class="line">    <span class="literal">nullptr</span> </span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">undef</span> X</span></span><br></pre></td></tr></table></figure>
<p>Note that the generated array is one-dimensional, but indexing it is pretty simple: <code>x_castOpPtr[opType1 * numTypes + opType2]</code> will give us the desired function pointer for <code>Src=opType1</code> and <code>Dst=opType2</code>.</p>
<p>The code, which contains both the implementation for <code>FOR_EACH_CARTESIAN_PRODUCT</code> and the above examples <a href="https://sillycross.github.io/assets/2022-04-01/for-each-cartesian-product-macro.cpp.txt">can be found here</a>. The code is in public domain so feel free to use.</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
      

    

    <footer class="article-footer">
    <!--
      <a data-url="https://sillycross.github.io/2022/04/01/2022-04-01/" data-id="clhkntofo000bdsp0hl78ae7p" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
    -->
      
      

    </footer>
  </div>
  
</article>



  


  <div id="page-nav">
    <nav><ul class="pagination"><li class="disabled"><span class="page-prev"><i class="fa fa-chevron-left"></i> Prev</a></li><li class="active"><span class="page-number">1</span></li><li><a class="page-number" href="/page/2/">2</a></li><li><a class="page-next" rel="next" href="/page/2/">Next <i class="fa fa-chevron-right"></i></a></li></ul></nav>
  </div>



        </div>
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          
  


  


  

  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="archives/2023/">2023</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="archives/2022/">2022</a><span class="sidebar-module-list-count">9</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="archives/2021/">2021</a><span class="sidebar-module-list-count">7</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list-recent-posts">
      
        <li>
          <a href="2023/05/12/2023-05-12/">Building a baseline JIT for Lua automatically</a>
        </li>
      
        <li>
          <a href="2022/11/22/2022-11-22/">Building the fastest Lua interpreter.. automatically!</a>
        </li>
      
        <li>
          <a href="2022/10/02/2022-10-02/">Pitfalls of using C++ Global Variable Constructor as a Registration Mechanism</a>
        </li>
      
        <li>
          <a href="2022/07/18/2022-07-18/">How to check if a real number is an integer in C++?</a>
        </li>
      
        <li>
          <a href="2022/06/11/2022-06-11/">Bizarre Performance Characteristics of Alder Lake CPU</a>
        </li>
      
    </ul>
  </div>




        </div>
    </div>
  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2023 Haoran Xu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

  

<!--<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>-->

<script src="js/bootstrap/bootstrap.min.js"></script>



  
<link rel="stylesheet" href="fancybox/jquery.fancybox.css">

  
<script src="fancybox/jquery.fancybox.pack.js"></script>




<script src="js/script.js"></script>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    menuSettings: {
      zoom: "None"
    },
    showMathMenu: false,
    jax: ["input/TeX","output/CommonHTML"],
    extensions: ["tex2jax.js"],
    TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js"],
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [["\\(", "\\)"]],
      displayMath: [["\\[", "\\]"]]
    }
  });
</script>

<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.1/MathJax.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
 

</body>
</html>
